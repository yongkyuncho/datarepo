구분,title,writer,publisher,year,journal,link,abstracts
0,과학기술데이터를 위한 자연어처리 기술 동향,"정현지 ( Hyun Ji Jeong ),장광선 ( Gwangseon Jang )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=11ea73dc5e87a4ffc85d2949c297615a&keyword=자연어 처리,"연구수행과정에서 발생하는 논문, 특허, 연구보고서 등의 과학기술데이터는 다양한 과학기술지식을 포함한다. 연구자들의 효과적인 연구를 지원하기 위해서는 과학기술데이터 분석을 통한 지식 발견이 필수적이다. 과학기술데이터는 일반 텍스트와는 다르게 다수의 전문용어를 포함하고 있으며, 고유의 양식이 정해져 있고, 텍스트 길이가 대체로 길다는 특징이 있다. 본 고에서는 이러한 과학기술데이터 만의 고유한 특징을 반영한 인공지능 기반 자연어처리 기술들을 소개함으로써 과학기술데이터 분석에 대한 이해를 돕고자 한다."
1,악성 댓글에 사용된 문자의 형태를 고려한 한국어 자연어처리를 위한 전처리 기법,"김해수 ( Hae-soo Kim ),김미희 ( Mi-hui Kim )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=c40a0e5db96c3eebc85d2949c297615a&keyword=자연어 처리,"최근 악플에 대한 논란이 끊이지 않고 있어 이것을 해결하기위한 방법으로 자연어 처리를 이용하고 있다. 특히 소셜 미디어, 온라인 커뮤니티에서 많이 발생하고 있고 해당 매체에서는 한글을 그대로 사용하지 않고 그들의 은어를 섞어서 사용하며 그중에서 한글이 아닌 문자를 섞어서 만들어낸 문장도 있다. 이러한 문장은 기존의 모델에 학습된 데이터의 형태와 다르며 한글이 아닌 문장이 많을수록 모델의 예측이 부정확해진다는 단점이 있어 본 논문에서는 인공지능을 이용한 이미지 분류와 띄어쓰기, 오타 교정을 이용한 전처리 기법을 제안한다."
2,챗봇 환경에서 데이터 시각화 인터랙션을 위한 자연어처리 모델,"오상헌,허수진,김성희,Oh, Sang Heon,Hur, Su Jin,Kim, Sung-Hee",한국정보처리학회,2020,정보처리학회논문지. 컴퓨터 및 통신시스템,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=995e194bc7faeb164884a65323211ff0&keyword=자연어 처리,"스마트폰의 보급으로 인해 개인화된 데이터를 활용하고자 하는 서비스들이 증가하고 있다. 특히, 헬스케어와 관련된 서비스들은 다양한 데이터를 다루며, 이를 효과적으로 보여주기 위해 데이터 시각화 기법을 활용하고 있다. 데이터 시각화 기법이 활용되면서 자연스럽게 시각화에서의 인터랙션 또한 함께 강조되고 있다. PC 환경에서 데이터 시각화에 대한 인터랙션은 마우스로 이루어지기 때문에, 데이터에 대한 필터링이 다양하게 제공되고 있다. 반면, 모바일 환경에서의 인터랙션은 화면의 크기가 작고, 인터랙션 가능 여부를 인지하기 어려워 버튼 터치 방식으로 앱에서 제공하는 제한된 시각화만을 제공받을 수 있다. 이러한 모바일 환경에서의 인터랙션 한계를 극복하기 위해, 챗봇과의 대화를 통해 데이터 시각화 인터랙션을 가능하게 하여 사용자들에게 개개인의 데이터를 다양한 시각화를 통해 확인할 수 있도록 하고자 한다. 이를 위해서는 사용자의 질의를 쿼리로 변환하여, 주기적으로 데이터를 축적하고 있는 데이터베이스에서 변환된 쿼리를 통해 결과 데이터를 불러올 수 있어야 한다. 자연어를 쿼리로 변환하는 연구는 현재 많이 이루어지고 있지만, 시각화를 기반으로 하여 사용자의 질의를 쿼리로 변환하는 연구에 대해서는 아직 이루어지지 않았다. 따라서, 본 논문에서는 사전에 데이터 시각화 기법이 정해진 상황에서의 쿼리 생성에 초점을 맞추고자 한다. 지원하는 인터랙션은 태스크 x-축 값에 대한 필터링 및 두 그룹 간 비교이다. 테스트 시나리오는 걸음 수에 대한 데이터를 활용하였으며, x-축 기간에 대한 필터링은 바 그래프, 두 그룹간 비교는 라인 그래프로 나타내었다. 시각화를 통해 요청한 정보를 제공받을 수 있는 자연어처리 모델을 개발하기 위해 1,000명을 대상으로 한 설문조사를 통해 약 15,800개의 학습 데이터를 수집하였다. 알고리즘 개발 및 성능 평가를 진행한 결과, 분류 모델에서는 약 89%, 쿼리 생성 모델에서는 약 99% 정확도를 보였다. With the spread of smartphones, services that want to use personalized data are increasing. In particular, healthcare-related services deal with a variety of data, and data visualization techniques are used to effectively show this. As data visualization techniques are used, interactions in visualization are also naturally emphasized. In the PC environment, since the interaction for data visualization is performed with a mouse, various filtering for data is provided. On the other hand, in the case of interaction in a mobile environment, the screen size is small and it is difficult to recognize whether or not the interaction is possible, so that only limited visualization provided by the app can be provided through a button touch method. In order to overcome the limitation of interaction in such a mobile environment, we intend to enable data visualization interactions through conversations with chatbots so that users can check individual data through various visualizations. To do this, it is necessary to convert the user's query into a query and retrieve the result data through the converted query in the database that is storing data periodically. There are many studies currently being done to convert natural language into queries, but research on converting user queries into queries based on visualization has not been done yet. Therefore, in this paper, we will focus on query generation in a situation where a data visualization technique has been determined in advance. Supported interactions are filtering on task x-axis values and comparison between two groups. The test scenario utilized data on the number of steps, and filtering for the x-axis period was shown as a bar graph, and a comparison between the two groups was shown as a line graph. In order to develop a natural language processing model that can receive requested information through visualization, about 15,800 training data were collected through a survey of 1,000 people. As a result of algorithm development and performance evaluation, about 89% accuracy in classification model and 99% accuracy in query generation model was obtained."
3,클라우드 환경에서 자연어처리 기법을 활용한 취약점 분석 시스템 설계,"송진수 ( Jin-su Song ),이필원 ( Pil-won Lee ),신용태 ( Young-tea Shin )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=b3d6b0147136f61d7ecd42904f0c5d65&keyword=자연어 처리,최근 4차 산업혁명의 기술이 발전하며 인공지능과 클라우드 컴퓨팅의 융합에 대한 연구가 활발하게 진행되고 있으며 클라우드 컴퓨팅에 컨테이너 기술을 접목한 새로운 컴퓨팅 환경이 주목받고 있다. 그러나 현재 사용되고 있는 컨테이너 기반의 가상화 기술은 컨테이너 실행에 필요한 파일과 설정 값을 포함하고 있는 컨테이너 이미지를 통해 배포하는 방식을 사용하고 다수의 컨테이너가 하나의 커널을 공유하기 때문에 취약한 패키지를 사용하는 컨테이너 이미지가 다수의 사용자와 공유 되어 시스템 보안이 매우 취약하다 이에 본 논문에서는 자연어처리 기법을 활용한 취약점 분석 시스템을 통해 컨테이너를 실행에 필요한 파일과 설정 값을 포함하고 있는 컨테이너 이미지에서 취약점을 분석하는 시스템을 제안한다.
4,자연어처리를 기반으로 한 코로나 정보 제공 챗봇 시스템,"송호연 ( Ho-yeon Song ),곽찬우 ( Chan-woo Gwak ),이동원 ( Dong-won Lee ),이윤수 ( Yun-soo Lee )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=76ba9d4a68dcf9056aae8a972f9116fb&keyword=자연어 처리,"본 논문에서는 코로나 바이러스로 인한 불편함을 겪는 사람들에게 코로나 관련 정보를 편리하게 제공하기 위해 인공지능 기반의 챗봇을 개발하였다. 인공지능 기술이 도입됨에 따라 챗봇이 여러 기관에서 고객 응대를 포함한 다양한 업무를 수행하고 있다는 점에 착안하여 IBM Watson Assistant 를 활용한다. Watson Assistant는 사용자가 입력한 말을 자연어 처리를 통해 분석하여 문장을 생성한 후 사용자에게 전달한다. Intent와 Entitiy를 통해 질의의 행위와 주체를 입력한 후 높은 빈도가 예상되는 질문을 작성하고, Dialog를 통해 대화 흐름을 파악한다. 사용자는 Axure로 설계된 사용자 인터페이스를 통해 대화 전송, 정보 수신 등 동작을 취할 수 있으며, 각 언어에 맞는 SDK 라이브러리를 제공한다는 이점을 활용하여 Node.js로 화면에서 발생하는 액션과 데이터 전달을 처리한다."
5,119 신고 데이터를 이용한 자연어처리 기반 재난안전 상황 분류 알고리즘 분석,"권수정,강윤희,이용학,이민호,박성호,강명주",한국정보처리학회,2020,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=6ea7d8ef2d6ca8d447de9c1710b0298d&keyword=자연어 처리,"Due to the development of artificial intelligence, it is used as a disaster response support system in the field of disaster. Disasters can occur anywhere, anytime. In the event of a disaster, there are four types of reports: fire, rescue, emergency, and other call. Disaster response according to the 119 call also responds differently depending on the type and situation. In this paper, 1280 data set of 119 calls were tested with 3 classes of SVM, NB, k-NN, DT, SGD, and RF situation classification algorithms using a training data set. Classification performance showed the highest performance of 92% and minimum of 77%. In the future, it is necessary to secure an effective data set by disaster in various fields to study disaster response. 인공지능의 발달로 인하여 재난 분야에서는 재난대응 지원 시스템으로 이용되고 있다. 재난은 언제 어디서든지 발생할 수 있으며, 재난 발생 시 소방청 119 신고접수대에 접수되는 신고는 크게 화재, 구조, 구급, 기타 신고 등 4가지로 구분된다. 119 신고에 따른 재난 대응도 그 종류 및 상황에 따라 다르게 대응된다. 본 논문에서는 119 신고 데이터 1280개 문서를 학습 데이터 셋을 이용하여 SVM, NB, k-NN, DT, SGD, RF 상황 분류 기계학습 알고리즘을 3 클래스로 테스트한 분류 성능은 최고 92%, 최소 77%의 성능을 보였다. 인공지능의 발달로 인하여 재난 분야에서는 재난 대응 지원 시스템으로 이용되고 있다. 재난은 언제 어디서든지 발생할 수 있으며, 재난 발생 시 소방청 119 신고접수대에 접수되는 신고는 크게 화재, 구조, 구급, 기타 신고 등 4가지로 구분된다. 119 신고에 따른 재난대응도 그 종류 및 상황에 따라 다르게 대응된다. 본 논문에서는 119 신고 데이터 1280개 문서를 학습 데이터 셋을 이용하여 SVM, NB, k-NN, DT, SGD, RF 상황 분류 알고리즘을 3 클래스로 테스트한 분류 성능은 최고 92%, 최소 77%의 성능을 보였다. 앞으로 다양한 분야의 재난별 데이터 셋을 확보하여 효율적인 재난 대응 연구가 필요하다."
6,‘홀로:HolLaw’ 자연어처리(NLP)와 SBERT를 사용한 판례 분석 서비스,"윤승현 ( Seung-hyeon Yoon ),김상윤 ( Sang-yoon Kim ),이정민 ( Jeong-min Lee ),오지민 ( Ji-min Oh ),김나연 ( Na-yeon Kim )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=27ef89972f9487b4e9810257f7042666&keyword=자연어 처리,"본 서비스는 문서 내의 가중치를 분석하여 키워드와 관련된 순서대로 정렬하여 판례/법률 검색의 정확도를 향상할 것을 제안한다. 상용화된 다른 판례/법률 관련 서비스의 경우, 키워드 검색을 통해 자신의 사례를 검색할 때, 요약된 정보가 없거나 너무 짧아 사용자가 원하는 판례/법률 결과를 얻을 수가 없어 본 서비스를 기획하게 되었다."
7,단문 텍스트의 자연어 처리 기법을 통한 크라우드 펀딩 추천 시스템 개발,"이영아 ( Yeong-ah Lee ),이선명 ( Sun-myung Lee ),이주연 ( Ju-yon Lee ),이기용 ( Ki Yong Lee )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=a5508041a41a02e96aae8a972f9116fb&keyword=자연어 처리,"최근 자연어 처리에 대한 관심이 증가함에 따라 자연어 처리 기술을 활용한 다양한 추천 시스템이 등장하고 있다. 본 논문에서는 자연어 처리를 이용한 서비스를 개발한다. 본 논문에서 개발한 서비스는 KoNLPy 와 Word2Vec 을 이용하여 크라우드 펀딩 프로젝트 창작자 및 후원자에게 키워드 및 키워드와 유사한 단어가 제목에 포함되는 프로젝트를 추천해준다. 단문 텍스트로서 프로젝트 제목을 사용하여 데이터를 자연어 처리 한 후, 딥러닝 모델에 적용시켜 추출한 데이터를 기반으로 창작자와 후원자에게 추천해주는 방식이다. 따라서 본 서비스는 프로젝트 제목 정보를 통한 추천 시스템의 개발로, 나아가 영화, 도서와 같은 콘텐츠 추천 분야에도 적용할 수 있을 것으로 기대한다."
8,자연어 처리를 위한 조건부 게이트 다층 퍼셉트론 모델 개발 및 구현,"손규진 ( Guijin Son ),김승원 ( Seungone Kim ),주세준 ( Se June Joo ),조우진 ( Woojin Cho ),나정은 ( Jeongeun Nah )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=6b4d00c6ad4ffc977f7a54760bb41745&keyword=자연어 처리,"2018 년 Google 사의 사전 학습된 언어 인공지능 BERT 를 기점으로, 자연어 처리 학계는 주요 구조를 유지한 채 경쟁적으로 모델을 대형화하는 방향으로 발전했다. 그 결과, 오늘날 자연어 인공지능은 거대 사기업과 그에 준하는 컴퓨팅 자원을 소유한 연구단체만의 전유물이 되었다. 본 논문에서는 다층 퍼셉트론을 병렬적으로 배열해 자연어 인공지능을 제작하는 기법의 모델을 제안하고, 이를 적용한‘조건부 게이트 다층 퍼셉트론 모델(SG-MLP)’을 구현하고 그 결과를 비교 관찰하였다. SG-MLP 는 BERT 의 20%에 해당하는 사전 학습량만으로 다수의 지표에서 그것과 준하는 성능을 보였고, 동일한 과제에 대해 더 적은 연산 비용을 소요한다."
9,컴퓨터비전과 자연어 처리를 활용한 표정 인식 디지털 미디어아트 구현에 관한 연구,"한재상 ( Han Jae-sang ),강윤서 ( Kang Yoon-seo ),권채연 ( Kwon Chae Yeon ),허원제 ( Heo Won-jae ),김영종 ( Youngjong Kim )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=797af60460375c337f7a54760bb41745&keyword=자연어 처리,"본 논문은 자연어 처리와 Face Detection 기술을 활용하여 사용자의 현재 감정 상태에 따른 디지털 미디어 아트를 구현하는 방법을 기술한다. 사용자의 현재 표정과 감정을 분석하고, 감정에 따라 다양한 시각 효과 및 다른 성격의 텍스트를 화면에 송출하는 방식으로 사용자와 상호작용한다."
10,자연어 처리를 활용한 전세계 전염병 알림 사이트,"곽찬우 ( Chan-woo Gwak ),김예찬 ( Ye-chan Kim ),최진황 ( Jin-hwang Choi )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=c28e34aac1323545b36097776a77e665&keyword=자연어 처리,"본 논문에서는 글로벌화가 진행됨에 따라 전 세계의 재난 경보시스템의 중요성을 인지하고, 현재 유행하고 있는 코로나 바이러스를 중점으로 알림 사이트를 개발하였다. 기존의 정보 제공 사이트들과 차별성을 두고자, 기존의 정보들을 분석하고 재분류하여 새로운 형태의 사이트의 형태를 가진다. 이를 위해 인공지능의 한 분야인 자연어처리를 활용하여 기존의 정보를 수집하고 가공하여, 보다 투명하고, 효율적이고, 가치 있는 정보를 게시한다. 정보의 정확성과 데이터 절감을 위하여 여러 조건을 통해 기존의 정보들을 재분류 작업 이후 WATSON NLU(Natural Language Understanding)를 통해 분석하여, 필요한 정보들을 각 대시보드에 게시한다. 각 대시보드는 NLU분석에서 얻을 수 있는 정보들을 기반으로 구성되어 있으며, 간결성과 가시성을 기반으로 정보를 확인할 수 있는 알림 사이트이다."
11,자연어 처리를 위한 트위터 감정 분석,"이앙 ( Ang Li ),조인휘 ( Inwhee Joe )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=b58d77a3cf0d966ee9810257f7042666&keyword=자연어 처리,"인터넷 시대에 소셜 미디어는 사람들의 삶에 완전히 침투했다. 많은 사용자 기반을 보유한 성숙한 온라인 플랫폼 중 하나인 Twitter를 통해 사용자는 최신 뉴스, 삶의 경험 및 흥미로운 삶의 이야기를 독립적으로 게시할 수 있다. 하지만 때론 부정적인 뉘앙스를 풍기며 기업이나 개인의 브랜드에 영향을 미치며 이익을 훼손하는 경우가 있기 때문에 욕설을 식별해 트위터 발신을 차단할 필요가 있다. 이 기사의 가장 큰 혁신은 Twitter 데이터를 사용하여 다양한 방법을 동시에 비교한다는 것입니다. 더 많은 데이터를 처리할수록 딥 러닝을 시도하면 좋은 결과를 얻을 수 있다. Transformer 분류기를 통합하여 최상의 결과를 얻었다"
12,자연어 처리 기술을 활용한 비대면 한국어 회화 연습 애플리케이션 설계 및 구현,"김수연 ( Soo-yeon Kim ),김지현 ( Ji-hyun Kim ),송나은 ( Na-eun Song ),윤서하 ( Seo-ha Yoon ),홍민영 ( Min-young Hong )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=1e9628a2a6fdd3bcb36097776a77e665&keyword=자연어 처리,"본 논문은 비대면 한국어 회화 시험 연습용 안드로이드 애플리케이션을 제안한다. 한국어 학습에 대한 수요가 증가함에 따라 효과적인 한국어 회화 학습을 위해선 시·공간의 제약이 없는 학습 환경에서 사용자에게 구체적인 평가 지표를 제공할 필요성이 있다. 본 연구는 자연어 처리 기술을 활용하여 사용자의 한국어 회화 능력을 평가하는 알고리즘과 개인의 취약점을 보완할 수 있는 비대면 학습 플랫폼을 제시하였다는데 의의가 있다. 본 논문의 결과를 통해 회화 학습의 비용을 절감하고, 효율적인 언택트 학습 지원이 가능할 것으로 기대한다."
13,검색환경 개선을 위한 자연어 처리 기반 맞춤형 추천 검색시스템,"승현수 ( Hyeon-su Seung ),박지윤 ( Ji-yun Park ),우다현 ( Da-hyun Woo ),오승민 ( Seung-min Oh )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=38092a35d945cb2b6aae8a972f9116fb&keyword=자연어 처리,"일반적인 검색엔진을 가진 포털 환경에서 정보검색 시 사용자가 원치 않는 수많은 검색결과가 동반되기도 하고 자신의 취향에 맞는 글을 검색하지 않았다는 이유만으로 원하는 정보를 놓치는 상황도 일어난다. 이러한 검색환경의 문제를 개선하기 위해 본 논문에서는 사용자들의 검색환경 개선을 위한 맞춤형 검색결과 정렬, 검색어 추천, 게시글 추천의 추천 시스템을 설계하고 제작한다. 이러한 추천 시스템은 워드 임베딩 모델과 추천 시스템 모델을 포함한다. 기존에 존재하던 워드 임베딩 모델의 성능을 실험을 통해 비교 및 분석하고, 크롤링을 통해 모은 데이터로 성능을 24.98%P 개선하였다. 추천 시스템 모델은 RMSE 비교를 통해 최적이 알고리즘을 제안한다. 해당 기술을 통해 사용자 스스로 자신의 검색환경을 개선할 수 있도록 구현하는 것이 이 시스템의 목표이다."
14,자연어처리의 교육적 활용 연구동향 분석,진성희,한국교육정보미디어학회,2022,교육정보미디어연구,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=4c39adf5d641d97b6aae8a972f9116fb&keyword=자연어 처리,"The purpose of this study is to explore the users, purposes, and educational effects of natural language processing (NLP) by analyzing research trends using NLP, a representative AI technology, in education. Text mining techniques and systematic literature review methods were applied to explore research trends. The literature to apply the text mining technique was 44 papers published in KCI journals over the past 10 years (2012-2021), containing similar keywords to “natural language processing,” including the word “education” in the abstract. As a result of topic modeling using text mining techniques, four research topics were classified on the educational use of NLP, followed by intelligent teaching & learning support, exploring the educational use of NLP, Korean language learning support, and descriptive-type evaluation automation. As for the topic trend by period, intelligent teaching & learning support and descriptive-type evaluation automation research were conducted in the 1st (2012-2015) and 2nd (2016-2018) periods, and exploring the educational use of NLP and Korean language learning support emerged as a new topic in the 3rd (2019-2021). Among the papers subject to text mining technique analysis, a systematic literature review was conducted on 25 papers that specifically reported on the analysis criteria with a high probability of topic allocation in topic modeling. The analysis contents were the first author's affiliation, academic field, school level, and research method, focusing on the subject of use, purpose of use, and educational effect of NLP. As a result of the analysis, learners (80%), instructors (28%), and institutions (20%) were the subjects of NLP, and the purpose of use was intelligent learning support (44%), instructional communication (20%), Korean language learning support (16%), descriptive-type evaluation automation (16%), and learning success and failure prediction (4%). In the early period, research was conducted by IT engineers to develop technologies or systems for educational use of NLP, and recently, many studies were conducted by (subject-matter) educators to analyze the effects of developing tools and applying them to actual classes. Accordingly, there were many studies conducted with the development research method (68%), and the educational effects were analyzed in terms of effectiveness (28%), usability (24%), satisfaction (16%), efficiency (4%), and functionality (24%). Based on the research results, implications and future studies were proposed. 인공지능 기술이 발전하면서 교육의 다양한 맥락에서 인공지능 기술을 적용하려는 시도들이 이루어지고 있다. 이 연구에서는 대표적인 인공지능 기술인 자연어처리를 교육에 활용한 연구동향을 분석함으로써 자연어처리 기술의 교육적 활용주체, 활용목적, 교육적 효과 등에 대해 탐색하고자 하였다. 연구동향을 탐색하기 위한 방법으로는 텍스트 마이닝 기법과 체계적 문헌고찰 방법을 적용하였다. 텍스트 마이닝 기법을 적용하기 위한 문헌은 지난 10년간(2012년∼2021년) KCI 등재(후보)지에 게재된 논문에서 키워드 중 자연어처리를 포함한 유사 핵심어를 포함하면서 초록에 “교육”이라는 단어를 포함한 논문 중 한국어를 대상으로 자연어처리 기술을 교육적으로 활용한 논문 44편을 분석 대상으로 하였다. 텍스트 마이닝 기법에 의한 토픽모델링 결과, 자연어처리의 교육적 활용 연구주제는 4개로 분류되었고 지능형 교수학습지원, 자연어처리 기술의 교육적 활용 탐색, 한국어 학습지원, 서술형 평가 자동화 순으로 수행 논문의 비율이 높게 나타났다. 시기별 주제 트렌드와 관련하여 1기(2012년∼2015년)와 2기(2016년∼2018년)에는 지능형 교수학습지원과 서술형 평가 자동화 연구가 이루어졌고 3기(2019년∼2021년)에 자연어처리 기술의 교육적 활용 탐색과 한국어 학습지원 연구가 새로운 주제로 등장하였다. 텍스트 마이닝 기법 분석 대상의 논문 중 토픽모델링에서 토픽할당 확률이 높으면서 분석기준에 대해 구체적으로 보고한 논문 25편을 대상으로 체계적 문헌고찰을 수행하였다. 분석내용은 자연어처리 기술의 활용주체, 활용목적, 교육적 효과를 중심으로 첫 번째 저자 소속, 학문분야, 학교급, 연구방법이었다. 분석결과 자연어처리 기술의 활용주체는 학습자(80%), 교수자(28%), 기관(20%) 순으로 나타났고, 활용목적은 지능형 학습지원(44%), 교수적 대화(20%), 한국어 학습지원(16%), 서술형 평가 자동화(16%), 학습성공 및 실패 예측(4%)으로 나타났다. 시기적으로 초기에는 IT공학자에 의해 자연어처리 기술을 교육적으로 활용하기 위한 기술이나 시스템을 개발하는 연구가 수행되었고 최근에는 (교과)교육학자들에 의해 관련 도구를 개발하고 실제 수업에 적용함으로써 그 효과를 분석하는 연구들이 수행되었다. 대부분의 연구는 개발연구방법(68%)으로 수행되었고 그 효과는 효과성(28%), 사용성(24%), 만족도(16%), 효율성(4%), 기능성(24%)측면에서 분석되었다. 연구결과에 기반하여 시사점과 추후연구에 대해 제안하였다."
15,한국어 연구의 융합적 가치와 과제 언어병리학과 - 자연어처리 분야와의 관계를 중심으로-,이봉원 ( Yi Bong-won ),한국어문학국제학술포럼,2023,Journal of Korean Culture,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=fd98257f0d14a2bf6aae8a972f9116fb&keyword=자연어 처리,"한국어 연구는 20세기 후반부터 다른 분야의 학문과 적극적으로 교류하여 왔으며, 최근 들어 융합적 연구가 일반화되면서 다시 그 중요성이 강조되고 있다. 한국어학은 한국어에 내재한 본질적 구조를 밝히고 구체적인 한국어 사용 양상을 통해 그 특성을 이론화한다. 언어병리학은 인간의 의사소통 특성에 기반해서 한국어 의사소통의 문제를 발견하고 해결 방법을 모색한다. 자연어처리는 한국어를 컴퓨터로 분석하고 새로운 지식을 생성해서 응용하는 여러 방법을 실현하고 있다. 한국어학, 언어병리학, 자연어처리 분야의 융합 연구는 융합 학문의 가치와 방향성을 가장 잘 보여주는 사례 중 하나이다. 딥러닝 중심의 자연어처리 기술의 발전은 자연어처리에 대한 다른 영역의 접근 가능성을 높여 주었다. 그리고 이 과정에 필수적인 언어자료의 구축은 한국어학 분야가 적극적인 역할을 해야 하는 영역이다. Korean language research has actively engaged with other fields since the late 20th century, and its significance has been highlighted once again as convergent research has become prevalent in recent times. Korean linguistics explores the fundamental structure inherent in the Korean language and theorizes its characteristics through specific aspects of its use. Speech-language pathology identifies issues in Korean communication based on human communication traits and seeks solutions. Natural language processing implements various methods for computer analysis of the Korean language and generates and applies new knowledge. Convergence research in the fields of Korean language, speech-language pathology, and natural language processing is a prime example of the value and direction of convergence studies. The advancement of deep learning-based natural language processing technology has increased the accessibility of other domains to natural language processing, and the creation of language corpora crucial for this process is a sphere where the field of Korean linguistics should actively participate."
16,전화금융사기 수사 정보 자동 추출 연구: 자연어처리 딥러닝 모델을 중심으로,김혜진,대한범죄학회,2022,한국범죄학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=7e0469200615b0a5b36097776a77e665&keyword=자연어 처리,"A telephone scam is a serious crime that not only causes financial damage to an individual but also raises a question about the credibility of financial infrastructure. This study attempts to extract 14 types of case information (i.e., pretended person, pretended institution, amount of financial damage, phone number used in crime, police station in charge of the investigation, case reception date, SNS type, victim’s name, victim’s phone number, victim’s occupation, and victim’s residence, etc) through deep learning method in the context of Natural Language Processing(NLP). Specifically, 12 types of information are pre-extracted using regular expression and customized dictionary method, and the other two types of information are extracted through the KO-BERT deep learning model. As a result of applying the NLP model to victim testimony records(n=100), which is provided by the Seoul Metropolitan Police Agency, the extraction accuracy of an average of 80-90% is confirmed. Although there is still room for improvement in terms of the accuracy of the NLP model, the outcome of this study is expected to facilitate an effective crime prevention policy and  further  promote  rapid  information  sharing  among  criminal  justice  agencies. 전화금융사기(보이스피싱)는 개인의 금전적 손실뿐만 아니라, 금융 인프라 전반에 대한 신뢰를 손상시켜 불필요한 사회적 비용을 낳는 심각한 범죄다. 최근 한국 정보통신기술의 성장과 코로나 19 예방을 위한 비대면 활동 정책이 맞물려 보이스피싱 범죄의 피해 규모와 범위가 급격히 증가하 고 있어, 혁신적인 수사기법을 활용한 효율적인 범죄 예방⋅수사 활동이 그 어느 때 보다 시급한 시점이라 하겠다. 본 연구는 과거 보이스피싱 사건 수사관들이 직접 기록을 읽고 수기로 작성했던 14종의 사건정보(범행 수법, 피해 금액, 범행 시 사용 전화번호, 사칭 기관, 사칭 인물, 특이사항, SNS유형, 사건접수 번호, 사건접수 관서, 피해자 성명, 피해자 전화번호, 피해자 주민번호, 피해자 직업, 피해자 주거지)를 자연어처리 딥러닝 모델 개발을 통해 자동 인식⋅추출하고자 했다. 광학 문자 인식을 포함한 전처리(Pre-processing) 작업 후 자연어처리 기술인 정규표현식(Regular Expression)을 사용해 12종의 사건정보를 선-추출하였으며, 한국해양대학교의 개체명 인식 데이 터(n=23,962)를 활용하여 학습한 딥러닝 모델을 통해 2종의 사건정보(사칭기관, 사칭인물)를 후-추출하였다. 서울경찰청이 제공한 실제 사건 수사자료(n=100)에 완성된 자연어처리 모델을 적용하여 테스트한 결과 평균 85∼90%에 달하는 추출 정확도를 확인할 수 있었다. 본 연구에서 제 안된 자연어처리 딥러닝 모델과 연구방법 모형이 전화금융사기 범죄자의 신속한 검거와 범부처적 대응방안 수립에 폭넓게 활용되기를 기대한다."
17,자연어처리와 기계학습을 이용한 요구사항 분석기술 비교 연구,"조병선,이석원",한국컴퓨터정보학회,2020,韓國컴퓨터情報學會論文誌,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=16d9305d6984a7a56aae8a972f9116fb&keyword=자연어 처리,"In this paper, we propose the methodology based on data-driven approach using Natural Language Processing and Machine Learning for classifying requirements into functional requirements and non-functional requirements. Through the analysis of the results of the requirements classification, we have learned that the trained models derived from requirements classification with data-preprocessing and classification algorithm based on the characteristics and information of existing requirements that used term weights based on TF and IDF outperformed the results that used stemming and stop words to classify the requirements into functional and non-functional requirements. This observation also shows that the term weight calculated without removal of the stemming and stop words influenced the results positively. Furthermore, we investigate an optimized method for the study of classifying software requirements into functional and non-functional requirements. 본 연구의 목적은 다양한 도메인에 대한 소프트웨어 요구사항 명세서로부터 수집된 요구사항을데이터로 활용하여 데이터 중심적 접근법(Data-driven Approach)의 연구를 통해 요구사항을 분류한다. 이 과정에서 기존 요구사항의 특징과 정보를 바탕으로 다양한 자연어처리를 이용한 데이터전처리와 기계학습 모델을 통해 요구사항을 기능적 요구사항과 비기능적 요구사항으로 분류하고각 조합의 결과를 제시한다. 그 결과로, 요구사항을 분류하는 과정에서, 자연어처리를 이용한 데이터 전처리에서는 어간 추출과 불용어제거와 같은 토큰의 개수와 종류를 감소하여 데이터의 희소성을 좀 더 밀집형태로 변형하는 데이터 전처리보다는 단어 빈도수와 역문서 빈도수를 기반으로 단어의 가중치를 계산하는 데이터 전처리가 다른 전처리보다 좋은 결과를 도출할 수 있었다.
이를 통해, 모든 단어를 고려하여 가중치 값은 기계학습에서 긍정적인 요인을 볼 수 있고 오히려문장에서 의미 없는 단어를 제거하는 불용어 제거는 부정적인 요소로 확인할 수 있었다."
18,기계 번역과 자연어처리를 활용한 튜터링 활동 분석,"윤혜경(Hae-Gyung Yoon),김철민(Chulmin Kim),최승배(Seungbae Choi),김태영(Taeyoung Kim)",한국자료분석학회,2023,Journal of the Korean Data Analysis Society,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=cd97a25132a19af54884a65323211ff0&keyword=자연어 처리,"본 연구는 Yoon, Kim, Choi, Kim(2021)의 후속 연구로서 본 연구에서는 이전 연구와 동일한 텍스트를 영문으로 기계 번역한 다음, 통계 모형을 통해 도출한 토픽과 이전 연구의 국문 텍스트로부터 도출된 범주를 비교하였다. 이를 통해 단순히 기계 번역의 질 만을 평가하기 보다는 텍스트에 적용한 자연어처리 모형 및 모형 적합 후 결과 해석 과정에서 인간 연구자의 역할, 인간 번역과 기계 번역의 조화에 관한 문제에 대해서도 함께 살펴보고자 하였다. 분석 대상인 텍스트는 D 대학의 교양교육튜터링 프로그램으로부터 수집되었으며, 토픽 모델링에 자주 사용되는 잠재디리클레할당 모형에 대한 이론적인 서술과 R ‘topicmodels’ 라이브러리 사용에 관한 설명을 부가하였다. 분석 결과 이전 연구와 다소 상이한 토픽이 도출되었고 이에 대한 연구진의 해석을 제시하였다. 자연어처리의 폭발적인 성장 추세와 자연어처리의 한 갈래로서 기계 번역은 거스를 수 없는 흐름임을 인정하면서도, 인간 번역자의 개입 여지를 함께 논의하였다. 본 연구는 교양교육연구에 있어 자연어 처리를 활용한 데이터 분석 기법과 기계번역 논의를 결합시킴으로써 교양교육연구에 새로운 접근법을 제시하고 있다. This is a follow-up study by Yoon, Kim, Choi, and Kim (2021). In the current study, the same text as the previous study was machine-translated into English, and then the topics derived through a statistical model, which were compared with the categories derived from the Korean text of the previous study. By doing this, rather than simply evaluating the quality of machine translation, the present study examined 1) the natural language processing model applied to text, 2) the role of human researchers in the process of interpreting the results after fitting the model, and 3) the harmony between human and machine translation, The texts to be analyzed were collected from the liberal arts education tutoring program of D university. A theoretical description of the Latent Dirichlet Allocation model, which is often used for topic modeling, and an explanation of the use of the R library ‘topicmodels’ were added. The analyses revealed a somewhat different pattern of topics from the previous study, and the authors’ interpretation was presented. Finally, while acknowledging the explosive growth of natural language processing and machine translation as a branch of it that cannot be reversed, the room for human translators to complement machine translation was suggested. This study presents a new approach to liberal arts education research by combining data analysis techniques using natural language processing and machine translation discussions."
19,국내외 특허데이터 분석을 통한 자연어처리의 의미분석 관련 기술동향 분석에 대한 연구,"현영근,한정현,채우리,이기현,이주연",한국디지털정책학회,2020,디지털융복합연구,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=bde2a8a1980674f4e9810257f7042666&keyword=자연어 처리,"NLP means the technology that mechanically analyzes a language spoken by a human and makes it into a form that can be understood by a computer. This is important because it is a core technology for communication between humans and devices, which is the basis of artificial intelligence. In this paper, I analyzed patent information of US and Korea in order to identify technical trends related to NLP, especially semantic analysis. and the purpose of this study is to provide meaningful information for future research on NLP. In conclusion, the number of Korea patents is 7.9% compared to the USA and the different frequencies of the major keywords were found to differ from country to country in technical direction. In addition, the upward or downward keywords are twice as many in the U.S. as in Korea, and reflect the trend of the times relatively more. Based on these results, in future study, I will analysis how upward trending keywords are described in actual patents for concrete technology prediction. 자연어처리 기술은 사람이 말하는 언어를 기계적으로 분석해 컴퓨터가 이해할 수 있는 형태로 만드는 것을 의미한다. 이것이 중요한 이유는 인공지능의 기본인 인간과 디바이스 간 커뮤니케이션을 위한 핵심기술이기 때문이다. 본 논문에서는 자연어처리, 특히 의미분석과 관련된 기술동향을 확인하기 위해 미국과 한국의 특허정보에 대해 분석하였으며, 본 연구를 통해 향후 자연어처리 관련 연구에 의미있는 정보제공을 그 목적으로 한다. 결론적으로, 국내 특허 수는 미국 대비  7.9% 수준이며, 주요 Keyword의 상이한 빈도는 기술적 방향성에 국가별로 차이가 있음을 확인하였다. 또한 상향 또는 하향 성향의 Keyword가 한국 대비 미국이 2배로 나타나 시대적 흐름을 상대적으로 더 반영한 것으로 분석되었다. 향후 연구에서는 실질적인 기술예측을 위해 상향 성향의 Keyword가 특허에서 어떻게 기술되고 있는지 구체적으로 분석하고자 한다."
20,자연어처리 기계학습 기법을 이용한 공시문서의 자동분류: Confidential treatment를 가진 8-K 문서를 중심으로,"이경란,강창묵",한국전자거래학회,2023,한국전자거래학회지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=6c6098a6d9cf2faa47de9c1710b0298d&keyword=자연어 처리,"Mandatory SEC filings provide crucial information to investors and other stakeholders, offering detailed financial statements and insights into a company's financial condition and material events. These filings also serve as valuable research data for firms and industries. This study investigates the application of machine learning techniques, specifically natural language processing, to automate the classification of disclosure documents. The primary focus is on developing a model for effectively filtering Form 8-Ks that request Confidential treatment (CT), enabling firms to redact proprietary information from mandatory filing forms. The paper compares the performance of a decision tree-based model (XGBoost) with two artificial neural network-based models, EmbedMixed and BERT. The results indicate that the XGBoost model outperforms the others, achieving a balanced trade-off between recall and precision of approximately 80-90%. The proposed model significantly enhances the efficiency of classifying CTs and holds potential for application to other types of SEC filing documents. 기업에 대한 방대한 정보를 제공하는 공시자료는 기업간 거래 및 투자 결정에 있어 필수적인 정보 원천이며 기업 및 산업에 대한 중요 연구자료이다. 본 논문에서는 기계학습에 기반한 자연어처리 기법을 활용하여 공시자료의 분류를 자동화하는 방법에 대해 다룬다. 특히 비밀처리(confidential treatment, CT)를 가지는 미국 수시공시 회계문서 8-K 양식의 자동판별을 위한 자연어처리(natural language processing, NLP) 기계학습 모델을 제안한다. CT란 경쟁우위의 저하를 유발할 수 있는 배타적 정보를 공시자료에서 비공개 하도록 허용하는 제도를 말한다. 문서의 분류를 위해 의사결정나무 기반의 XGBoost 모형과 인공신경망 기반의 EmbedMixed, BERT 모형을 비교하였다. 그 결과 가장 우수한 성능을 보인 모형은 XGBoost 모형으로 재현율과 정밀도가 80%~90% 사이에서 서로 상쇄하는 수준을 보였다. 본 모델을 통해 비밀처리 문서 탐색의 효율성을 크게 높일 수 있으며 다른 유형의 공시문서 분류에도 유사한 접근법을 적용해 볼 수 있을 것으로 기대한다."
21,자연어처리 기반 법적 판결 논증 분석을 활용한 수사결과 검증방안 연구,"구예리,문성준,박노섭",한국경찰법학회,2023,경찰법연구,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=c9b23486a92bd362b7998d826d417196&keyword=자연어 처리,"The recent amendments to the Korean Criminal Procedure Act have brought significant changes to the investigative environment of the police.
By granting the authority to conclude investigations to the police, the process of reviewing cases by police investigators has become unprecedentedly crucial. Furthermore, the growing trend of direct investigation of evidence in courts demands logically complete arguments in the courtroom. Consequently, comprehensive and well-structured reasoning for both investigation and verification of cases is anticipated to become a vital competency for the police. While efforts are being made to ensure objectivity in investigative outcomes, the constraints of the investigative environment make it difficult for investigators to allocate sufficient time and resources to analytical investigations.
However, despite these limitations, it is imperative to establish a process of verifying investigative results based on evidentiary analysis and logical reasoning, considering the constraints faced by law enforcement agencies.
In light of this perspective, this study aims to propose a systematic approach to investigative verification by utilizing primary trial judgments, which share a similar structure with criminal investigative reports. By applying artificial intelligence-based natural language processing techniques, this research postulates that even with limited personnel resources, prompt and efficient analysis of cases can be achieved, leading to improved completeness of investigations.
To explore this, the study conducted experiments on automatically extracting argument structures from trial judgments used as data. Based on the results of these experiments, the research endeavors to design a scientific argument structure for crime investigation verification, ensuring the legitimacy and objectivity of investigations through analyzing legal reasoning structure present in trial judgments. The findings of this study are expected to provide a foundation for advancing research in the field of natural language processing in the domain of crime investigations. 최근 개정된 형사소송법 및 검찰청법으로 인해 경찰의 수사환경은 크게 변화하고 있다. 경찰에게 부여된 수사종결권으로 인해 수사관의 사건 검토 과정이 매우 중요해졌으며, 공판중심주의 강화 추세로 인해 법정에서의 논리적 사실 주장이 더욱 요구되고있어 완성도 높은 논증을 통한 수사검증은 경찰에게 중요한 역량이 될 것으로 예상된다.
이에 수사 결과에 대한 객관성을 확보하기 위한 다양한 노력이 이뤄지고 있지만, 수사 환경의 제약으로 인해 수사관은 분석 수사에 충분한 시간과 여유를 확보하기 어려운 현실이다. 그러나 이러한 제약요인에도 불구하고 수사경찰이 수집된 증거에서 도출한 결론에 대한 논증 분석에 기반한 수사결과 검증은 반드시 필요한 수사과정으로 자리잡을 필요가 있다.
이러한 관점에서 본 연구는 수사결과보고서와 유사한 구조로 사실관계에 대한 판단이 이루어지는 제1심 형사판결문을 데이터로 활용하여, 합리적이고 과학적인 논리규칙에 기반한 논증 기반의 수사 검증 시스템을 구축하는 방안을 제시하고자 하였다. 본연구에서는 수사검증 과정에 인공지능 기반의 자연어처리 기술을 적용한다면 적은 인적 자원에도 불구하고 신속하고 용이한 사건 분석이 가능해질 것이며 수사의 완결성이자연스럽게 향상될 것이라는 가정하에, 판결문을 데이터로 사용하여 논증구조를 자동추출하는 실험을 진행하였다.
이 실험을 바탕으로 본 연구는 합리적인 논증에 기반하여 수사의 정당성 및 객관성을 확보할 수 있는 수사절차를 마련할 수 있도록 판결문상의 법적 논증구조에 대한 분석을 통해 범죄 수사 검증을 위한 과학적인 논증 구조를 고안하고자 시도하였다. 본연구의 결과는 향후 범죄 수사 분야의 자연어처리 연구를 발전시키기 위한 기반을 마련하는 데 기여할 수 있을 것이다."
22,KorPatELECTRA : 자연어처리 분야에서의 성능 향상을 위한 한국어 특허 문헌 사전학습 언어모델(KorPatELECTRA),"장지모,민재옥,노한성",한국컴퓨터정보학회,2022,韓國컴퓨터情報學會論文誌,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=6ca0aaed8183a1d6e9810257f7042666&keyword=자연어 처리,"In the field of patents, as NLP(Natural Language Processing) is a challenging task due to the linguistic specificity of patent literature, there is an urgent need to research a language model optimized for Korean patent literature. Recently, in the field of NLP, there have been continuous attempts to establish a pre-trained language model for specific domains to improve performance in various tasks of related fields.
Among them, ELECTRA is a pre-trained language model by Google using a new method called RTD(Replaced Token Detection), after BERT, for increasing training efficiency. The purpose of this paper is to propose KorPatELECTRA pre-trained on a large amount of Korean patent literature data. In addition, optimal pre-training was conducted by preprocessing the training corpus according to the characteristics of the patent literature and applying patent vocabulary and tokenizer. In order to confirm the performance, KorPatELECTRA was tested for NER(Named Entity Recognition), MRC(Machine Reading Comprehension), and patent classification tasks using actual patent data, and the most excellent performance was verified in all the three tasks compared to comparative general-purpose language models. 특허 분야에서 자연어처리(Natural Language Processing) 태스크는 특허문헌의 언어적 특이성으로문제 해결의 난이도가 높은 과제임에 따라 한국 특허문헌에 최적화된 언어모델의 연구가 시급한실정이다. 최근 자연어처리 분야에서는 특정 도메인에 특화되게 사전 학습(Pre-trained)한 언어모델을 구축하여 관련 분야의 다양한 태스크에서 성능을 향상시키려는 시도가 지속적으로 이루어지고있다. 그 중, ELECTRA는 Google이 BERT 이후에 RTD(Replaced Token Detection)라는 새로운 방식을 제안하며 학습 효율성을 높인 사전학습 언어모델이다. 본 연구에서는 대량의 한국 특허문헌데이터를 사전 학습한 KorPatELECTRA를 제안한다. 또한, 특허 문헌의 특성에 맞게 학습 코퍼스를 정제하고 특허 사용자 사전 및 전용 토크나이저를 적용하여 최적화된 사전 학습을 진행하였다. KorPatELECTRA의 성능 확인을 위해 실제 특허데이터를 활용한 NER(Named Entity Recognition), MRC(Machine Reading Comprehension), 특허문서 분류 태스크를 실험하였고 비교 대상인 범용 모델에 비해 3가지 태스크 모두에서 가장 우수한 성능을 확인하였다."
23,자연어처리 모델을 이용한 이커머스 데이터 기반 감성 분석 모델 구축,"최준영,임희석",한국융합학회,2020,한국융합학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=87e4647cb694ad734884a65323211ff0&keyword=자연어 처리,"In the field of Natural Language Processing, Various research such as Translation, POS Tagging, Q&A, and Sentiment Analysis are globally being carried out. Sentiment Analysis shows high classification performance for English single-domain datasets by pretrained sentence embedding models. In this thesis, the classification performance is compared by Korean E-commerce online dataset with various domain attributes and 6 Neural-Net models are built as BOW (Bag Of Word), LSTM[1], Attention, CNN[2], ELMo[3], and BERT(KoBERT)[4]. It has been confirmed that the performance of pretrained sentence embedding models are higher than word embedding models. In addition, practical Neural-Net model composition is proposed after comparing classification performance on dataset with 17 categories. Furthermore, the way of compressing sentence embedding model is mentioned as future work, considering inference time against model capacity on real-time service. 자연어 처리 분야에서 번역, 형태소 태깅, 질의응답, 감성 분석등 다양한 영역의 연구가 활발히 진행되고 있다. 감성 분석 분야는 Pretrained Model을 전이 학습하여 단일 도메인 영어 데이터셋에 대해 높은 분류 정확도를 보여주고 있다. 본 연구에서는 다양한 도메인 속성을 가지고 있는 이커머스 한글 상품평 데이터를 이용하고 단어 빈도 기반의 BOW(Bag Of Word), LSTM[1], Attention, CNN[2], ELMo[3], KoBERT[4] 모델을 구현하여 분류 성능을 비교하였다. 같은 단어를 동일하게 임베딩하는 모델에 비해 문맥에 따라 다르게 임베딩하는 전이학습 모델이 높은 정확도를 낸다는 것을 확인하였고, 17개 카테고리 별, 모델 성능 결과를 분석하여 실제 이커머스 산업에서 적용할 수 있는 감성 분석 모델 구성을 제안한다. 그리고 모델별 용량에 따른 추론 속도를 비교하여 실시간 서비스가 가능할 수 있는 모델 연구 방향을 제시한다."
24,자연어처리 기술을 활용한 유튜브 악성 댓글 자동 블라인드 시스템,"이재은(Jae Eun Lee),이지은(Ji Eun Lee),임예희(Ye Hee Lim),박규동(Kyudong Park),조민수(Minsu Cho)",한국HCI학회,2022,한국HCI학회 학술대회,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=2b157b87a51943a7c85d2949c297615a&keyword=자연어 처리,"인터넷 상의 댓글이 늘어나면서 악성 댓글의 심각성 또한 점점 커지는 가운데, 특히 최근 사용량이 급증한 유튜브에서 많은 양의 악성 댓글로 인해 피해가 속출하고 있다. 이를 줄이고자, 본 연구에서는 자동으로 유튜브의 악성 댓글을 검출하여 이를 노출시키지 않도록 블라인드 처리하는 크롬 확장 프로그램을 개발하였다. 먼저, 유튜브 댓글을 수집한 후 일반 댓글과 악성 댓글로 라벨링하여 학습 데이터셋을 구축하였다. 이를 바탕으로 지도학습 기반의 악성 댓글 분류기를 구축하여 서버에 내장하였다. 그리고 유튜브 웹사이트에서 댓글의 위치를 읽어서 자동으로 서버로 송신하고 악성 댓글 여부를 수신하는 크롬 확장 프로그램을 개발하였다. 실행 결과, 악성 댓글로 예측된 댓글이 자동으로 블라인드 처리됨을 확인하였다. 추후 사용성 평가를 거쳐 개선 사항을 발굴할 예정이며, 악성 댓글에 노출되지 않는 것이 유튜브의 사용 경험에 어떤 영향을 미치는지 연구하고자 한다."
25,인공신경망 기반 자연어처리를 적용한 연도별 정책내용 변화 분석에 관한 연구: 일본 IT신전략 (2018-2020)을 대상으로,"김민호 ( Minho Kim ),윤호열 ( Ho-yeol Yoon ),최상옥 ( Sang-ok Choi )",정보통신정책학회,2021,정보통신정책연구,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=fbfced76adca3893e9810257f7042666&keyword=자연어 처리,"본 연구는 인공신경망 기반 자연어처리를 적용하여 시간에 따른 정책내용 변화를 확인하고자 하였다. 비정형 텍스트인 일본 IT신전략(2018-2020)에 단어 임베딩 학습모형인 Word2Vec알고리즘을 적용하여 다차원 공간에 추출한 단어들을 벡터화하였으며, 두 벡터 간의 사잇각을 구하는 코사인 유사도(cosine similarity)를 이용하여 단어 유사도(word similarity)를 측정하였다. Word2Vec알고리즘, 코사인 유사도를 이용하여 비정형 텍스트를 수치화하였고, 수치화된 값을 이용하여 정책문서 안에서 단어 간의 중요도와 유사도를 객관적으로 분석하고자 하였다. 또한, 정책문서의 번역과 해석에 의해서는 알기 힘들었던 의미들을 발견하고자 하였다.
분석 결과, 코사인 유사도의 증감을 통해 연관단어의 중요성이 어떻게 변화하고 있는지 확인할 수 있었다. 그리고 코사인 유사도를 통해 도출된 연관단어의 연도별변화와 단어 유사도를 통해 정책내용 변화의 성격을 알 수 있었다. This study aims to confirm changes in policy content over time by applying the method of Natural Language Processing with Artificial Neural Networks. To apply this method to the unstructured data for Japan's new IT strategy, data preprocessing was performed allowing a computer to recognize the unstructured data. Words were vectorized in multidimensional space using the Word2Vec algorithm, and word similarity was approximated using the cosine similarity approach. Using these approaches, we quantified the originally unstructured data and were able to compare and analyze the importance of various words for the policy document.
Relying on the cosine similarity, we confirmed that the relatedness of words varied even when words were same. The importance of the related words varied through the increase or decrease of the cosine similarity. We could thus infer the nature of the change in policy content from the yearly changes in the related words and from word similarity, as inferred from the cosine similarity approach."
26,딥러닝 자연어처리를 통한 판사의 인지적 과정 추론과  한국 법원 판결 예측 가능성에 관한 연구,"박예찬,이재성",중앙대학교 인문콘텐츠연구소,2023,인공지능인문학연구,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=3d01e487cfd50c0ab36097776a77e665&keyword=자연어 처리,"Korean judgeʼs unnaturalized cognitive process make it difficult  to  determine whether  similar  cases  receive  judgments;  therefore,  we  aim  to  understand  these processes. This study presents a data analysis method that combines cognitive process knowledge  and  model  techniques.  First,  the  collected  data  are  text  that  aligns smoothly with the judge's cognitive process, and attempts were made  to  embed  the text into the preprocessed value. In word embedding, FastText was  used  because  it was  deemed  appropriate  for  legal  analysis.  The  vector  values  were learned using Random Forest and Neural network models and enabled judgment to be classified into 81% accuracy. Then, by implementing cognitive maps through language networks and comparing  them  with  the  analyzed  data,  we  confirmed  that  they  had the same cognitive process. This study demonstrates the possibility of capturing  judgesʼ cognitive  process  through  natural  language  processing,  despite  the  emergence  of challenging  legal  terminology  and  lengthy  sentences.  Additionally, it was possible to deduce the crucial factors and their priorities in judgment through  cognitive  maps, enabling a comprehensive understanding of factors influencing judgment. From this, it can  be  concluded  that  they  possess  distinct  aspect,  do  share  and  reflect  certain perceptions. 우리나라의 판결들은 판사의 본연화 되지 않은 인식에 의해 결정되는 부분이존재해 비슷한 사건에서 비슷한 판단하고 있는지 파악하기 어려우므로, 본연화되지 않는 판사의 인식체계를 알고자 한다. 이를 위해 본 논문에서는 인식체계지식과 모델 기법을 융합한 데이터 분석을 제시한다. 우선 데이터를 판사의 인식체계가 잘 들어나는 텍스트를 수집하고, 텍스트를 전처리한 값에 임베딩을 시도한다. 이때, 워드 임베딩에서는 FastText가 법률분석에 적합하다고 판단하였기때문에 사용하였다. 그다음 이렇게 얻어진 벡터 값을 Random Forest와 Neural network 모델을 통해 학습하였고 각 판결을 최고 81%의 정확도로 분류해 낼수 있었다. 그리고 언어 네트워크 분석을 통한 인지적 지도를 구현해 딥러닝한결과와 비교함으로써 판사들 간 같은 인지 과정을 거치는지를 확인하였다. 본 과정을 통해 비록 어려운 법률 용어가 등장하며, 문장의 길이가 긴 판결문일지라도충분히 자연어 처리를 통해 판사들의 인식을 구현화하고 예측하는 것이 학습을통해 가능하다. 또 판결에 중요하게 여겨지는 사건 요소의 우선순위를 인지적 지도를 통해 추론가능해 결국 판단에 중요한 영향을 미치는 것이 무엇인지를 파악할 수 있었다. 이를 바탕으로 판결들이 전혀 다른 양상을 가지고 있어 예측할수 없는 범위에 있는 것이 아니라 일정한 인식을 공유하고 반영한다는 결론을도출해낼 수 있다."
27,딥러닝 자연어처리(NLP)와 일반수사학 (General Rhetoric)과의 융합적 접점 분석 - 그룹 뮤(Groupe μ)의 『A General Rhetoric』을 중심으로,지승학 ( Chi Seung-hak ),한국기호학회,2020,기호학연구,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=6bd425c653a365264884a65323211ff0&keyword=자연어 처리,"본 논문에서는 그룹 뮤(Groupe μ)의 『일반수사학』에서 주목하고 있는 시학과 수사 학적 언어의 형태와 RNN 언어모델의 구조적 유사성을 분석하고자 한다. 여기에서 주로 동원되는 것은 시학과 수사학적 언어의 기능을 분류하는 ‘메타볼’(Metaboles)의 유 형이다. 특히 메타볼은 본 논문에서 다루게 될 ‘수사학적 공간’의 아이디어로 발전하여 딥러닝 기술을 통한 자연어처리와 실질적으로 연결될 수 있다는 점에서 중요한 개념이라고 할 수 있다. 또한 수사학적 공간 개념을 RNN 언어모델에 적용하기 위해서는 무엇보다도 정밀한 언어 데이터 셋 마련과 적확한 ‘의미의 영점’(Degree-Zero) 마련 역시 중요하다. 이런 사실은 결국 학문적 융합이 현재 A.I. 기술에 얼마나 필수적인지를 보여준다. 마지막으로 『일반수사학』의 내용은 현재의 딥러닝 언어모델에서도 여전히 유효하다는 점에서 날카로운 혜안을 증언하고 있으며 우리에게 여전히 인문학과 공학의 초학제적 태도는 중요할 수밖에 없음을 보여준다. In this article, I attempt to analyze the structural similarity between the semantic structure of poetry and rhetorical language on which Groupe μ is focusing and the RNN language model. The main focus of this article was concentrated on the type of ‘metaboles’ that categorizes the functions of poetry and rhetorical language. This type and its insight are considerably useful not only in connection with natural language processing technology but also a application field. In particular, the approach for the idea of ‘rhetorical space’ can be substantially an important concept in terms of connection with deep learning technology of NLP. In addition, this approach shows the fact that it is the paramount importance to prepare a precise language data set which has ‘Degree Zero’ and ‘Subunits’ of the linguistic code. Ultimately, through this convergence analysis, we realize that the trans-disciplinary attitude of the humanities and engineering is inevitably important."
28,문자열 유사도 알고리즘을 이용한 공종명 인식의 자연어처리 연구 - 공종명 문자열 유사도 알고리즘의 비교 -,"정상원,정기창",한국건설관리학회,2020,한국건설관리학회 논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=bf4a73bd18c4c97347de9c1710b0298d&keyword=자연어 처리,"Natural language encountered in construction documents largely deviates from those that are recommended by the authorities. Such practice that is lacking in coherence will discourage integrated research with automation, and it will hurt the productivity in the industry for the long run. This research aims to compare multiple string similarity (string matching) algorithms to compare each algorithm’s performance in recognizing the same task name written in multiple different ways. We also aim to start a debate on how prevalent the aforementioned deviation is. Finally, we composed a small dataset that associates construction task names found in practice with the corresponding task names that are less cluttered w.r.t their formatting. We expect that this dataset can be used to validate future natural language processing approaches. 시공 서류에서 접하는 자연어는 당국에서 권장하는 언어와 크게 다르다. 일관성이 부족한 이러한 관행은 자동화를 통한 통합 연구를 방해하고 장기적으로 업계의 생산성을 저하시킬 것이다. 이 연구는 여러 문자열 유사성(문자열 일치) 알고리즘을 비교하여 여러 다른 방법으로 작성된 동일한 작업 이름을 인식하는 각 알고리즘의 성능을 비교하는 것을 목표로 한다. 우리는 또한 앞서 언급 한 편차가 얼마나 널리 퍼져 있는지에 대한 토론을 시작하는 것을 목표로 한다. 마지막으로, 우리는 실제로 발견된 시공 작업 이름을 형식에 비해 덜 복잡한 해당 작업 이름과 연결하는 작은 데이터 세트를 구성했다. 이 데이터 세트를 사용하여 미래의 자연어 처리 접근 방식을 검증 할 수 있을 것으로 기대한다."
29,자연어처리를 위한 대조 학습 기반의 심층학습 모델에 대한 최근 연구 동향,"유대곤(Daegon Yu),한상우(Sangwoo Han),온병원(Byung-Won On)",한국정보기술학회,2022,Proceedings of KIIT Conference,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=b3cd9ff2589b13e0b7998d826d417196&keyword=자연어 처리,"대조 학습은 의미가 유사한 벡터에서 추출한 양성 샘플과 의미가 다른 벡터에서 추출한 음성 샘플을 기반으로 손실을 줄여 학습한다. 최근 대조 학습이 자연어처리 분야에서 보다 좋은 품질의 벡터를 생성하기 위한 방법으로 널리 사용되고 있다. 특히 비지도 학습에 사용되며 레이블이 지정되지 않은 데이터에서도 지도 학습모델을 능가한다. 이 외에도 대조 학습은 단일 문장 분류, 문장 임베딩 문제의 성능을 향상시키는 등 사전 학습 시 다양하게 활용된다. Contrastive learning methods are trained by reducing the loss based on positive samples extracted from vectors with similar meanings and negative samples extracted from vectors with different meanings. Recently, it is widely used as a method for generating better quality vectors in the field of natural language processing. Especially, it is used in unsupervised learning, outperforming supervised learning models, even with unlabeled data. In addition, it is used in a variety of ways during pre-training, such as improving the performance of single sentence classification and sentence embedding problems."
30,자연어처리와 기계학습을 통한 우울 감정 분석과 인식,"김규리,문지현,오유란",국제문화기술진흥원,2020,The Journal of the Convergence on Culture Technolo,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=66ad3ff8d50537f67f7a54760bb41745&keyword=자연어 처리,"This paper proposes a machine learning-based emotion analysis system that detects a user's depression through their SNS posts. We first made a list of keywords related to depression in Korean, then used these to create a training data by crawling Twitter data - 1,297 positive and 1,032 negative tweets in total. Lastly, to identify the best machine learning model for text-based depression detection purposes, we compared RNN, LSTM, and GRU in terms of performance. Our experiment results verified that the GRU model had the accuracy of 92.2%, which is 2~4% higher than other models. We expect that the finding of this paper can be used to prevent depression by analyzing the users' SNS posts. 본 논문에서는 SNS에 게시된 글의 내용을 통해 사용자의 우울함을 검출하는 기계학습 기반 감성 분석 시스템을 제안한다. 게시한 글의 작성자가 기분을 파악하는 시스템을 구현하기 위해 먼저 감정 사전에서 우울한 감정의 단어와 그렇지 않은 감정과 관련된 단어를 목록화하였다. 그 후, SNS를 대표하는 서비스 중 하나인 트위터의 텍스트 자료에서 검색 키워드를 선정하고 크롤링을 시행하여 우울한 감정을 띤 문장 1297개와 그렇지 않은 문장 1032개로 이뤄진 학습 데이터셋을 구축하였다. 마지막으로 텍스트 기반 우울감 검출 목적에 가정 적합한 기계학습 모델을 찾기 위해 수집한 데이터셋을 바탕으로 순환신경망, 장단기메모리, 그리고 게이트 순환 유닛을 비교 평가하였고, 그 결과 GRU 모델이 다른 모델들보다 2~4%가량의 높은 92.2%의 정확도를 보임을 확인하였다. 이 연구 결과는 SNS상의 게시글을 토대로 사용자의 우울증을 예방하거나 치료를 유도하는 데 활용될 수 있을 것이다."
31,인공지능 기반 자연어처리를 적용한 욕창간호기록 분석,"김명수,류정미,Kim, Myoung Soo,Ryu, Jung-Mi",한국융합학회,2021,한국융합학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=224530af49d101ace9810257f7042666&keyword=자연어 처리,"본 연구의 목적은 자연어처리에 의해 생성된 욕창간호진술문의 특성을 파악하고, 욕창 단계판별 예측정확도를 평가하기 위함이다. 욕창관련 간호기록은 서술통계를 이용하여 분석하였고, 워드클라우드 생성기를 활용하여 욕창예방 간호기록에서 단어의 특성을 파악하였다. 딥러닝을 이용하여 욕창단계판별 정확도(accuracy ratio) 를 구하였다. 연구결과, 욕창의 단계에 대한 기록 중 2단계와 심부조직손상의심단계가 각각 23.1% 와 23.0 % 로 가장 많았고, 빈도수가 높은 핵심단어는 홍반, 수포, 가피, 부위, 크기 등으로 나타났다. 예측의 정확도가 높은 단계는 0단계, 심부조직손상의심단계, 2단계 순으로 나타났다. 따라서, 이를 활용하여 임상적 의사결정지지 시스템으로 개발된다면, 임상간호사의 욕창관리역량 향상 전략 개발에 기초가 될 수 있을 것이다. The purpose of this study was to examine the statements characteristics of the pressure ulcer nursing record by natural langage processing and assess the prediction accuracy for each pressure ulcer stage. Nursing records related to pressure ulcer were analyzed using descriptive statistics, and word cloud generators (http://wordcloud.kr) were used to examine the characteristics of words in the pressure ulcer prevention nursing records. The accuracy ratio for the pressure ulcer stage was calculated using deep learning. As a result of the study, the second stage and the deep tissue injury suspected were 23.1% and 23.0%, respectively, and the most frequent key words were erythema, blisters, bark, area, and size. The stages with high prediction accuracy were in the order of stage 0, deep tissue injury suspected, and stage 2. These results suggest that it can be developed as a clinical decision support system available to practice for nurses at the pressure ulcer prevention care."
32,대학수학능력시험 독서 영역의 교육 목표를 위한 자연어처리 기법을 통한 검증,"이수민,김경민,임희석",한국융합학회,2022,한국융합학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=0f2a79cbc7e8a34a7f7a54760bb41745&keyword=자연어 처리,"대학수학능력시험 국어 과목에서 중요한 비중을 차지하는 독서 영역의 주된 교육 목표는 주어진 지문을 온전히 이해할 수 있는가를 평가하는 데에 있다. 따라서 해당 지문에 포함된 질의를 주어진 지문만으로 풀이할 수 있는지는 해당 영역의 교육 목표와 관련이 깊다. 본 연구에서는 처음으로, 교육학 분야와 딥러닝을 접목하여 이러한 교육 목표가 실제로도 타당하게 실현 가능한지를 입증하고자 한다. 대학수학능력시험의 독서 영역의 개별 지문과 그에 수반된 다수의 문장 쌍(sentence pair)을 정제하여 추출하고, 해당 문장 쌍을 주어진 지문에 비추어 적절하거나(T), 적절하지 않은지(F)를 판단하는 이진 분류 태스크(binary classification task)에 적용하여 평가 하고자 한다. 그 결과, F1 스코어 기준 59.2%의 human performance를 뛰어넘는 성능을 62.49%의 KoELECTRA를 비롯한 대부분의 언어 모델에서 확인할 수 있었으며, 또한 데이터 전처리 과정에 변화를 줌으로써 언어 모델의 구조적 한계를 극복할 수 있었다. The major educational goal of reading part, which occupies important portion in Korean language in Korean SAT, is to evaluated whether a given text can be fully understood. Therefore given questions in the exam must be able to solely solvable by given text. In this paper we developed a datatset based on Korean SAT’s reading part in order to evaluate whether a deep learning language model can classify if the given question is true or false, which is a binary classification task in NLP. In result, by applying language model solely according to the passages in the dataset, we were able to acquire better performance than 59.2% in F1 score for human performance in most of language models, that KoELECTRA scored 62.49% in our experiment. Also we proved that structural limit of language models can be eased by adjusting data preprocess."
33,자연어처리 기반 진화형 임상의사결정지원시스템: 녹내장 진단 사례연구,"장동진,Ubaid Ur Rehman,정윤혜,Hafiz Syed Muhammad Bilal,이승룡",한국통신학회,2020,정보와 통신,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=51031d567bee93454884a65323211ff0&keyword=자연어 처리,"임상의사결정지원시스템 (Clinical Decision Support System, CDSS)은 1980년대에 처음 소개된 개념으로 임상의사결정 능력 제공과 의료 서비스의 향상을 목적으로 하였다. 이후 기술이 발전함에 따라 현대의 CDSS는 임상 관리, 비용 절감, 행정 업무, 그리고 의료진 뿐만 아니라 환자를 위한 의사결정 기능까지 지원하게 되었다. 또한 CDSS에 인공지능을 도입함에 따라 연구 실험 결과의 해석과 의료 영상으로부터 질병을 진단할 수 있는 기능까지 갖추게 되었다. 이렇듯 다양한 기능이 CDSS에 추가되었지만, 핵심적인 의사결정 능력은 여전히 지식베이스에 의존적이다. 지식베이스의 진화를 위해서는 지식의 획득, 표현 및 변환 작업이 요구된다. 그러나 이를 사람이 직접 하는 방법은 많은 비용과 시간이 소모되어 진화 작업이 잘 수행되지 않고, 그에 따라 시간이 경과하면서 기존 지식이 낡은 지식이 되어 진단 능력이 떨어져 추천의 오류가 발생하게 된다. 본고에서는 효율적이고 효과적으로 지식베이스를 진화시키기 위해 자연 언어 처리(Natural Language Processing, NLP) 기법을 활용하는 방법을 제안한다. 제안 방법은 전문의로부터 점진적으로 지식을 획득하며, 획득된 지식은 규칙으로 변환되어 지식베이스를 갱신하게 된다. 녹내장 사례 연구를 바탕으로 제안 방법을 이용하여 진화된 지식베이스의 정확도를 실험한 결과 91%의 정확도를 나타내었다."
34,"SpanBERT를 이용한한국어 자연어처리: 기계 독해, 개체 연결, 의존 파싱","박은환(Eunhwan Park),나승훈(Seung-Hoon Na),김태형(Tae-Hyeong Kim),최윤수(Yun-Su Choi),장두성(Du-Seong Chang)",한국정보과학회,2021,한국정보과학회 학술발표논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=bafddaba86070a6de9810257f7042666&keyword=자연어 처리,"최근 자연어 처리 연구에서 대용량 말뭉치와 양방향 트랜스포머 기반 맥락을 고려한 BERT 와 같은 언어 모델을 사전 학습하고, 응용 태스크에 미세 조정하여 높은 성능을 달성하였다. 본 연구에서는 개별 토큰이 아닌 연속적인 범위(Span)의 토큰을 마스킹(Masking)한다. 그리고 개별 토큰 표현에 의존하지 않고 범위 경계(Span Boundary) 표상을 학습하여 마스킹 된 범위의 전체 내용을 예측 함으로서 기존의 한국어 RoBERTa[1] 모델을 확장한다. 이를 바탕으로 기계 독해, 개체 연결, 의존 파싱과 같은 응용 태스크 일부에서 기존 언어 모델보다 향상된 성능을 거두었다."
35,자연어처리 알고리즘을 이용한 위험기반 항공안전데이터 자동분류 방안 연구,"양성훈,최영,정소영,안주현",한국항행학회,2022,韓國航行學會論文誌,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=8e29f4b93e7f9a5db7998d826d417196&keyword=자연어 처리,"Although the domestic aviation industry has made rapid progress with the development of aircraft manufacturing and transportation technologies, aviation safety accidents continue to occur. The supervisory agency classifies hazards and risks based on risk-based aviation safety data, identifies safety trends for each air transportation operator, and conducts pre-inspections to prevent event and accidents. However, the human classification of data described in natural language format results in different results depending on knowledge, experience, and propensity, and it takes a considerable amount of time to understand and classify the meaning of the content. Therefore, in this journal, the fine-tuned KoBERT model was machine-learned over 5,000 data to predict the classification value of new data, showing 79.2% accuracy. In addition, some of the same result prediction and failed data for similar events were errors caused by human."
36,자연어처리기법을 활용한 코로나19 전후 지속가능한 글로벌 공급망 연구 동향 변화와 시사점,"이소연(So-Yeon Lee),송민채(Min-Chae Song)",한국산학기술학회,2022,한국산학기술학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=bb8b952c3f7250807f7a54760bb41745&keyword=자연어 처리,"코로나19 사태로 기존 글로벌 공급망의 취약점이 드러나면서 위기 발생에 대한 선제적 리스크 관리 및 신속대응을 위한 국가와 기업들의 새로운 공급망 구축에 대한 논의가 활발히 진행 중이다. 그 중 ‘지속가능한 공급망(Sustainable Global Value Chains)’ 전략이 가장 큰 주목을 받고 있다. 그러나 어떠한 배경에서 코로나19가 글로벌 공급망 연구와 관련 논의에 영향을 미쳤는지를 실증 분석한 연구는 찾아보기 어렵다. 본 연구는 코로나19가 어떻게 글로벌 공급망 전략에 영향을 미쳤고, 지속가능한 글로벌 공급망 연구가 2019년 전후로 어떠한 양상으로 변화하고 있는지 텍스트 분석기법을 이용해 살펴보았다. 결론으로 분석에서 도출된 결과를 토대로 지속가능한 글로벌 공급망 연구의 영역 및 연구대상(주체)의 확대, 실행가능한 제도 정비의 필요성 등을 미래 연구의제로 제시하였다. 본 연구는 국가 간 경제의 상호의존성 심화로 코로나19 충격이 개별 기업의 대응 역량과 범위를 벗어나 경제 구조 전반을 변화시킴에 따라 글로벌 공급망의 패러다임 전환이 진행 중에 있음을 실증분석으로 확인하고, 어떠한 대응이 필요한지 제안하였다는 점에서 그 의의가 있다. The vulnerabilities of present global value chains were revealed by the COVID-19 pandemic. Discussions are underway in various countries and companies to establish new global value chains for risk management purposes and improve response to global risks, and the sustainable global value chain strategy has received the most research attention. Although research on sustainable global value chains has increased significantly since 2019, few studies have empirically analyzed how COVID-19 affected global value chain research and discussion. In this study, we analyzed how the COVID-19 pandemic affected global value chain strategies and why sustainable global value chain research changed before and after 2019 using natural language preprocessing techniques.
Based on the implications derived from empirical results, we suggest sustainable global value chain research scope and research subjects be expanded and that the need for system preparation be explored. This study shows, using natural language preprocessing, that a paradigm shift in global value chains is in progress due to the COVID-19 pandemic."
37,보건의료 빅데이터에서의 자연어처리기법 적용방안 연구: 단어임베딩 방법을 중심으로,"김한상 ( Hansang Kim ),정여진 ( Yeojin Chung )",한국보건행정학회,2020,보건행정학회지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=42a2df90c60883aa7f7a54760bb41745&keyword=자연어 처리,"While healthcare data sets include extensive information about patients, many researchers have limitations in analyzing them due to their intrinsic characteristics such as heterogeneity, longitudinal irregularity, and noise. In particular, since the majority of medical history information is recorded in text codes, the use of such information has been limited due to the high dimensionality of explanatory variables. To address this problem, recent studies applied word embedding techniques, originally developed for natural language processing, and derived positive results in terms of dimensional reduction and accuracy of the prediction model. This paper reviews the deep learning-based natural language processing techniques (word embedding) and summarizes research cases that have used those techniques in the health care field. Then we finally propose a research framework for applying deep learning-based natural language process in the analysis of domestic health insurance data."
38,고전시가 분석에서의 자연어처리 활용 ― 次韻詩 詩句의 부자연스러움 증명,이다연,중국어문학연구회,2022,중국어문학논집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=75892a14dfeefc4947de9c1710b0298d&keyword=자연어 처리,"Rhyme-matching poem is a kind of replying poem. It is written based on the rule that the rhymes in the original poem should be used in order. Loved by great poets, it achieved widespread popularity after the Song Dynasty. However, rhyme-matching poems had been criticized for unnatural expressions due to the use of fixed rhymes, and such works had been pointed out. So this study performed the ‘fill-mask’ task using the embeddings of pre-trained models that learned Chinese classical text in a Masked Language Modeling (MLM) so as to verify whether the expressions of the verse in rhyme-matching poems is unnatural compared to those of original poems. The subject of this experiment is the poems of the literary network led by Su-Shi in the North Song Dynasty. The experimental result shows the probability to predict the rhyme tokens in rhyme-matching poem was lower than that of original poem; the probability was much lower in the long poem. This proves that the expressions in rhyme-matching poems are not general compared to that of original poems, but more strongly represents the need for using rhyme-matching method in the literary networks. In conclusion, this study demonstrates that rhyme-matching poems were advantageous for close connection with the original poems and the authors."
39,뇌졸중 연구에서 자연어처리와 텍스트 마이닝의 적용,김철호,대한신경과학회,2021,대한신경과학회지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=87daf1d642328d3a6aae8a972f9116fb&keyword=자연어 처리,"Natural language processing (NLP) is a computerized approach to analyzing text that explores how computers can be used to understand and manipulate natural language text or speech to do useful things. In healthcare field, these NLP techniques are applied in a variety of applications, ranging from evaluating the adequacy of treatment, assessing the presence of the acute illness, and the other clinical decision support. After converting text into computer-readable data through the text preprocessing process, an NLP can extract valuable information using the rule-based algorithm, machine learning, and neural network. We can use NLP to distinguish subtypes of stroke or accurately extract critical clinical information such as severity of stroke and prognosis of patients, etc. If these NLP methods are actively utilized in the future, they will be able to make the most of the electronic health records to enable optimal medical judgment."
40,딥러닝 중심의 자연어 처리 기술 현황 분석,박상언 ( Park Sang-un ),(사)한국빅데이터학회,2021,한국빅데이터학회 학회지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=57165b0ee9b37f796aae8a972f9116fb&keyword=자연어 처리,"자연어 처리는 최근 기계학습 및 딥러닝 기술의 발전과 적용으로 성능이 빠르게 향상되고 있으며, 이로 인해 활용 분야도 넓어지고 있다. 특히 비정형 텍스트 데이터에 대한 분석 요구가 증가함에 따라 자연어 처리에 대한 관심도 더욱 높아지고 있다. 그러나 자연어 전처리 과정 및 기계학습과 딥러닝 이론의 복잡함과 어려움으로 인해 아직도 자연어 처리 활용의 장벽이 높은 편이다.
본 논문에서는 자연어 처리의 전반적인 이해를 위해 현재 활발히 연구되고 있는 자연어 처리의 주요 분야와 기계학습 및 딥러닝을 중심으로 한 주요 기술의 현황에 대해 살펴봄으로써, 보다 쉽게 자연어 처리에 대해 이해하고 활용할 수 있는 기반을 제공하고자 한다. 이를 위해 인공지능 기술 분류체계의 변화를 통해 자연어 처리의 비중 및 변화 과정을 살펴보았으며, 기계학습과 딥러닝을 기반으로 한 자연어 처리 주요 분야를 언어 모델, 문서 분류, 문서 생성, 문서 요약, 질의응답, 기계번역으로 나누어 정리하고 각 분야에서 가장 뛰어난 성능을 보이는 모형들을 살펴보았다. 그리고, 자연어 처리에서 활용되고 있는 주요 딥러닝 모형들에 대해 정리하고 자연어 처리 분야에서 사용되는 데이터셋과 성능평가를 위한 평가지표에 대해 정리하였다.
본 논문을 통해, 자연어 처리를 자신의 분야에서 다양한 목적으로 활용하고자 하는 연구자들이 자연어 처리의 전반적인 기술 현황에 대해 이해하고, 자연어 처리의 주요 기술 분야와 주로 사용되는 딥러닝 모형 및 데이터셋과 평가지표에 대해 보다 쉽게 파악할 수 있기를 기대한다. The performance of natural language processing is rapidly improving due to the recent development and application of machine learning and deep learning technologies, and as a result, the field of application is expanding. In particular, as the demand for analysis on unstructured text data increases, interest in NLP(Natural Language Processing) is also increasing. However, due to the complexity and difficulty of the natural language preprocessing process and machine learning and deep learning theories, there are still high barriers to the use of natural language processing.
In this paper, for an overall understanding of NLP, by examining the main fields of NLP that are currently being actively researched and the current state of major technologies centered on machine learning and deep learning, We want to provide a foundation to understand and utilize NLP more easily. Therefore, we investigated the change of NLP in AI(artificial intelligence) through the changes of the taxonomy of AI technology. The main areas of NLP which consists of language model, text classification, text generation, document summarization, question answering and machine translation were explained with state of the art deep learning models. In addition, major deep learning models utilized in NLP were explained, and data sets and evaluation measures for performance evaluation were summarized.
We hope researchers who want to utilize NLP for various purposes in their field be able to understand the overall technical status and the main technologies of NLP through this paper."
41,기록관리 분야에서 한국어 자연어 처리 기술을 적용하기 위한 고려사항,김학래,한국기록관리학회,2022,한국기록관리학회지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=6d3e05be0036720d4884a65323211ff0&keyword=자연어 처리,"Records have temporal characteristics, including the past and present; linguistic characteristics not limited to a specific language; and various types categorized in a complex way. Processing records such as text, video, and audio  in the life cycle of records’ creation, preservation, and utilization entails exhaustive effort and cost. Primary natural language processing (NLP) technologies, such as machine translation, document summarization, named-entity recognition, and image recognition, can be widely applied to electronic records and analog digitization. In particular, Korean deep learning–based NLP technologies effectively recognize various record types and generate record management metadata. This paper provides an overview of Korean NLP technologies and discusses considerations for applying NLP technology in records management. The process of using NLP technologies, such as machine translation and optical character recognition for digital conversion of records, is introduced as an example implemented in the Python environment. In contrast, a plan to improve environmental factors and record digitization guidelines for applying NLP technology in the records management field is proposed for utilizing NLP technology. 기록물은 과거와 현재를 포함하는 시간적 특성, 특정 언어에 제한되지 않는 언어적 특성, 기록물이 갖고 있는 다양한 유형을 복합적으로 갖고 있다. 기록물의 생성, 보존, 활용에 이르는 생애주기에서 텍스트, 영상, 음성으로 구성된 데이터의 처리는 많은 노력과 비용을 수반한다. 기계번역, 문서요약, 개체명 인식, 이미지 인식 등 자연어 처리 분야의 주요 기술은 전자기록과 아날로그 형태의 디지털화에 광범위하게 적용할 수 있다. 특히, 딥러닝 기술이 적용된 한국어 자연어 처리 분야는 다양한 형식의 기록물을 인식하고, 기록관리 메타데이터를 생성하는데 효과적이다. 본 논문은 한국어 자연어 처리를 기술을 소개하고, 기록 관리 분야에서 자연어 처리 기술을 적용하기 위한 고려사항을 논의한다. 기계번역, 광학문자인식과 같은 자연어 처리 기술이 기록물의 디지털 변환에 적용되는 과정은 파이썬 환경에서 구현한 사례로 소개한다. 한편, 자연어 처리 기술의 활용을 위해 기록관리 분야에서 자연어 처리 기술을 적용하기 위한 환경적 요소와 기록물의 디지털화 지침을 개선하기 위한 방안을 제안한다."
42,자연어 처리 Triple+ 추출을 이용한 진술 일관성 판별 정확도 연구,"조은경,문혜민,윤여훈,전현정,양기주",한국법심리학회,2023,한국심리학회지: 법,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=8a372f3d4a9bbcacb7998d826d417196&keyword=자연어 처리,"Demand for statement analysis is increasing as the credibility of the victim's statement becomes more important in the investigation and trial of sexual offence cases. The consistency of the victim's statement is one of the main criteria for judging the credibility of a victim. In the era of 4th industrial revolution natural language processing technology is rapidly growing to analyze conversation contents. This study tried to verify the accuracy of statement consistency analysis using Triple+ extractions, a natural language processing technology. Trained evaluators conducted a statement consistency analysis on 57 actual transcripts of victim statements and compared them with the results of statement inconsistency analysis using Triple+. The Triple+ for 18 pairs of inconsistent sentences from victim statements were extracted and classified into 7 types of statement inconsistency. The rules of determining statement inconsistency for each type were established. The results showed that Triple+ correctly identified statement discrepancies 77% on the average. For subtypes of inconsistency classification accuracy varied as 100% for the direction, timing, and action, 75% for content denial, 66.7% for place, and 50% accuracy of event sequence and passive/active type were found. 93.8% accuracy was achieved in the judgment of 32 randomly selected pairs of consistent sentences. The results of this study suggest a potential for automatic statement inconsistency discrimination using Triple+ as supplementary tool for human expert statement analysis. The limitations of the existing natural language processing technology required for artificial intelligence statement analysis and the direction of future research are discussed. 성폭력 사건의 수사 및 재판 단계에서 피해자 진술의 신빙성 판단이 중요해짐에 따라 진술분석의 수요가 증가하고 있다. 피해자 진술의 일관성은 진술 신빙성 판단의 주요 기준 중 하나이다. 4차 산업혁명 시대에 점차 고도화되는 자연어처리 기술은 대화 내용을 분석하는데 확장되고 있는 점에 착안하여, 이 연구는 자연어 처리 기술인 Triple+ 추출을 적용한 진술 일관성 분석의 정확도를 확인고자 하였다. 이를 위해 진술분석 교육을 이수한 평가자가 57건의 실제 피해자 진술 녹취록에 대해 진술 일관성 분석을 실시한 후 Triple+를 이용한 진술 불일치 분석 결과와 비교하였다. 평가자의 분석 결과 확인된 18쌍의 비일관적인 문장들에 대한 Triple+를 추출하고 7가지 진술 불일치 유형으로 구분하였으며 유형별 진술 불일치 판단 규칙을 설정하였다. 분석 결과, Triple+가 평균적으로 77% 정확하게 진술 불일치를 판별하는 것으로 나타났다. 세부 유형별로는, 방향, 시점, 행동 주체 유형은 100%, 내용 부정 유형은 75%, 장소 유형은 66.7%, 사건의 순서, 피동․능동 유형 판별은 50%의 정확도로 나타났다. 또한, 무작위로 선정된 32쌍의 일관적인 문장에 대한 판단에서는 93.8%의 판별 정확도를 보였다. 이러한 연구 결과는 Triple+을 이용한 자동적 진술 불일치 판별은 진술분석의 보조도구로서 효율성을 높일 수 있을 것으로 기대된다. 인공지능 진술분석에 필요한 현존하는 자연어 처리 기술의 한계와 향후 연구의 방향에 대해서도 논의하였다."
43,인공지능 시대의 개인정보 개념에 대한 연구 ― 자연어 처리를 중심으로 ―,정종구 ( Jonggu Jeong ),한양대학교 법학연구소,2021,법학논총,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=26548ad4243e87d76aae8a972f9116fb&keyword=자연어 처리,"빅데이터 기술에 기반한 인공지능은 개인정보보호 법제를 크게 바꿀 수밖에 없는 계기이다. 막대한 양의 비정형 데이터가 기계에 의해 실시간으로 생성되어 처리되며 오프라인에 직접적인 유형력을 행사할 수 있게 된 오늘날에는 개인정보 보호법제는 대폭적인 수정 내지변화가 요구되고 있다. 소위 ‘이루다 사건’과 ‘하이퍼클로바의 공개’로 인해 인공지능 기술의 발전이 실생활에 있어 본격적으로 체감되기 시작했기 때문이다. 이들은 모두 자연어 처리기법을 전제로 하고 있다는 점에서 자연어 처리 기법을 중심으로 인공지능 시대의 개인정보보호 문제를 심도있게 연구할 필요가 있다. 가장 치열하게 논의되고 있는 부분은 개인정보의 개념 부분이다. 이는 인공지능 모델의 학습과 활용에 개인정보 보호법제가 적용되는지를 좌우하기 때문이다. 이하 개인정보 개념에 대한 기존 논의를 정리하며, 오늘날 특히 문제되는 것이 무엇인지를 분석한다. 구체적으로, 개인정보 판단주체의 문제와 공개된 개인정보의 문제 및 대화의 개인정보성 문제를 각종 판례와 사례에 비추어 순차적으로 검토한다. 이를 바탕으로 개인정보를 충분히 보호하면서도 인공지능 기술발전을 저해하지 않을 수 있는 합리적인 방안을 모색한다. Artificial intelligence based on big data technology is an opportunity change the data protection law. Nowadays, significant revision or change is required in data protection legislation. This is because the development of artificial intelligence technology has begun to be felt in real life due to the so-called ‘Eruda case’ and ‘disclosure of HyperCLOVA’. Since all of them are based on natural language processing techniques, it is necessary to focus on personal information protection issues in the age of artificial intelligence on natural language processing techniques. The most intensely debated part is the concept of personal information. Below, we summarize the existing discussion on the concept of personal information and analyze what is particularly problematic today. Based on this, we seek reasonable ways to protect personal information while not hindering the development of artificial intelligence technology."
44,자연어 처리 모델을 활용한 블록 코드 생성 및 추천 모델 개발,"전인성,송기상",한국정보교육학회,2022,정보교육학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=36857918b139f9ed4884a65323211ff0&keyword=자연어 처리,"In this paper, we develop a machine learning based block code generation and  recommendation model for the purpose of reducing cognitive load of learners during coding education that learns the learners block that has been made in the block programming environment using natural processing model and fine-tuning and then gen­erates and recommends the selectable blocks for the next step. To develop the model, the training dataset was produced by pre-processing 50 block codes that were on the popular block programming language web site ‘Entry’. Also, after dividing the pre-processed blocks into training dataset, verification dataset and test dataset, we developed a model that generates block codes based on LSTM, Seq2Seq, and GPT-2 model. In the results of the performance evaluation of the developed model, GPT-2 showed a higher performance than the LSTM and Seq2Seq model in the BLEU and ROUGE scores which measure sentence similarity. The data results generated through the GPT-2 model, show that the performance was relatively similar in the BLEU and ROUGE scores ex­cept for the case where the number of blocks was 1 or 17. 본 논문에서는 코딩 학습 중 학습자의 인지 부하 감소를 목적으로 자연어 처리 모델을 이용하여 전이학습 및 미세조정을 통해 블록 프로그래밍 환경에서 이미 이루어진 학습자의 블록을 학습하여 학습자에게 다음 단계에서 선택가능한 블록을 생성하고 추천해주는 머신러닝 기반 블록 코드 생성 및 추천 모델을 개발하였다. 모델 개발을 위해 훈련용 데이터셋은 블록 프로그래밍 언어인 ‘엔트리’ 사이트의 인기 프로젝트 50개의 블록 코드를 전 처리하여 제작하였으며, 훈련 데이터셋과 검증 데이터셋 및 테스트 데이터셋으로 나누어 LSTM, Seq2Seq, GPT-2 모델을 기반으로 블록 코드를 생성하는 모델을 개발하였다. 개발된 모델의 성능 평가 결과, GPT-2가 LSTM과 Seq2Seq 모델보다 문장의 유사도를 측정하는 BLEU와 ROUGE 지표에서 더 높은 성능을 보였다. GPT-2 모델을 통해 실제 생성된 데이터를 확인한 결과 블록의 개수가 1개 또는 17개인 경우를 제외하면 BLEU와 ROUGE 점수에서 비교적 유사한 성능을 내는 것을 알 수 있었다."
45,자연어 처리(NLP : Natural Language Processing) 기반 골프 법·정책연구 지식구조 탐색,"남재준,이제욱",한국스포츠엔터테인먼트법학회,2023,스포츠와 법,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=12d8c27a8fea6823e9810257f7042666&keyword=자연어 처리,"본 연구는 국내 골프정책 연구의 거시적 지식구조를 도출하여 주제영역별 전망을 예측하고 연구 방향성을 제안하는데 목적이 있다. 데이터 분석을 위해 25년(1997-2022)간 국내 골프 정책연구를 수집하고 자연어처리 분석기법 중 하나인 텍스트 마이닝으로 주요 키워드를 추출한 후 토픽모델링 기법을 통해 주제영역을 도출하였다. 설정된 모든 토픽 클러스터에서 뚜렷한 정체성을 지난 핵심토픽 영역과 설정에 따라 변화를 보이는 가변토픽 영역으로 구분된 토픽모델링 결과를 확인할 수 있었다. 구체적으로는 다음과 같다. 첫째, 핵심토픽 중 ‘골프장 개발의 법·제도적 쟁점’, ‘골프장 관련 조세제도에 따른 법적 쟁점’, ‘골프장 사고 발생에 따른 법적 쟁점’, ‘골프장 회생 및 회원 권리보호’, ‘골프장 캐디의 근로자적 지위’는 골프장 운영 과정에서 발생하는 법·정책적 사안에 해당하는 주제영역을 다루고 있다. 둘째, ‘고등교육 기관 시스템 개선 및 인력양성’, ‘골프 산업 활성화를 위한 미시·거시 정책’ 또한 핵심토픽으로써 대학 골프 관련 커리큘럼 및 교육과정과 골프인재 양성, 다양한 관점의 골프 산업 영향요인에 대한 법·정책 방안을 제시하고 있다. 셋째, 가변 토픽은 ‘선수 활동에서의 법적 권리와 의무’, ‘가상현실 골프 플랫폼의 코스 저작권 이슈’ 그리고 ‘내기 골프 문화의 법·윤리적’로 나타났으며, 골프장 입지적 요인에 따른 이해관계 주체들과 법적 사례, 선수의 보호와 법·윤리적 불찰에 대한 사례와 대응, 가상현실 골프 시스템에 표현되는 실제 골프 코스의 저작물 가치 인정 여부, 내기 골프의 법·윤리적 문제 등으로 구성되어 있다. 각 토픽들은 클러스터 비중과 별개로 사회·경제·기술·문화 등 내외부 요인과 관련된 골프의 법·정책적 이슈를 다루고 있다. 이는 앞으로도 각 주제영역이 변화하는 환경으로부터 영향을 받아 지속과 변주를 통한 연구가 활발히 수행될 것으로 전망되며, 새롭게 주목할 주제영역 또한 기대할 수 있다는 의미로 해석된다."
46,트랜스포머 기반 효율적인 자연어 처리 방안 연구,"임승철,윤성구",한국인터넷방송통신학회,2023,한국인터넷방송통신학회 논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=3117a953e86cc86fe9810257f7042666&keyword=자연어 처리,"The natural language processing models used in current artificial intelligence are huge, causing various difficulties in processing and analyzing data in real time. In order to solve these difficulties, we proposed a method to improve the efficiency of processing by using less memory and checked the performance of the proposed model. The technique applied in this paper to evaluate the performance of the proposed model is to divide the large corpus by adjusting the number of attention heads and embedding size of the BERT[1] model to be small, and the results are calculated by averaging the output values of each forward. In this process, a random offset was assigned to the sentences at every epoch to provide diversity in the input data. The model was then fine-tuned for classification. We found that the split processing model was about 12% less accurate than the unsplit model, but the number of parameters in the model was reduced by 56%. 현재의 인공지능에서 사용되는 자연어 처리 모델은 거대하여 실시간으로 데이터를 처리하고 분석하는 것은 여러가지 어려움들을 야기하고 있다. 이런 어려움을 해결하기 위한 방법으로 메모리를 적게 사용해 처리의 효율성을 개선하는 방법을 제안하고 제안된 모델의 성능을 확인하였다. 본 논문에서 제안한 모델의 성능평가를 위해 적용한 기법은BERT[1] 모델의 어텐션 헤드 개수와 임베딩 크기를 작게 조절해 큰 말뭉치를 나눠서 분할 처리 후 출력값의 평균을통해 결과를 산출하였다. 이 과정에서 입력 데이터의 다양성을 주기위해 매 에폭마다 임의의 오프셋을 문장에 부여하였다. 그리고 모델을 분류가 가능하도록 미세 조정하였다. 말뭉치를 분할 처리한 모델은 그렇지 않은 모델 대비 정확도가12% 정도 낮았으나, 모델의 파라미터 개수는 56% 정도 절감되는 것을 확인하였다."
47,자연어 처리를 활용한 D 대학교 교양교육튜터링 참여자 텍스트 분석,"윤혜경(Hae-Gyung Yoon),김태영(Taeyoung Kim),최승배(Seungbae Choi),김용하(Yongha Kim)",한국자료분석학회,2021,Journal of the Korean Data Analysis Society,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=989367b0c8b9cfb6e9810257f7042666&keyword=자연어 처리,"비정형 데이터로서의 텍스트를 통계적인 분석 기법과 접목시킨 이른바 텍스트 마이닝(text mining)은 연구방법론에 있어 새로운 지평을 열었으며 이미 다양한 분야에서 널리 활용되고 있다. 본 연구에서는 D 대학교 교양교육튜터링 프로그램 참여자들을 대상으로 한 포커스 그룹 인터뷰 자료를 기반으로 인터뷰에 드러난 튜터와 튜티의 사용 단어 빈도의 차이를 조사하였다. 본 연구는 핵심 역량 관점에서 접근한 동료 튜터링 운영 사례를 기반으로 하였으며, 프로그램 실시 이후 동료 튜터링에 참여한 학생들 중 자원자를 대상으로 이루어진 포커스 그룹 인터뷰(Focus Group Interview)의 내용을 분석하였다. 사용된 연구 질문은 1) “사전에 설정한 범주별로 튜터와 튜티의 사용 단어의 출현 빈도에 차이가 있는가?” 2) “튜터와 튜티의 역량 범주에 해당하는 단어의 출현 빈도에 차이가 있는가?” 였으며 동질성 검정 결과 연구진들이 상정한 튜터와 튜티의 발화 빈도 차이를 발견하지는 못하였다. 그럼에도 불구하고 본 연구는 교양교육연구에 있어 질적 연구방법론과 자연어 처리를 활용한 텍스트 마이닝 기법을 결합시킴으로써 향후 전개될 교양교육 연구에 새로운 접근법을 제공하고 있다. Text mining, which combines text as unstructured data with statistical analysis techniques, has opened a new horizon in research methodology and has been already widely used in various realms. In this study, the difference in word frequency between tutors and tutees revealed in the interviews was investigated based on focus group interview data for participants in the liberal arts education tutoring program at the D University. This study was based on a case of peer tutoring approached from the perspective of core competency, and after the program was implemented, the contents of a focus group interview with volunteers among students who participated in peer tutoring were analyzed. The research questions used were 1) “Is there a difference in the frequency of appearance of the words used by the tutor and the tutor for each category set in advance?” 2) “Is there a difference in the frequency of occurrence of words that fall within the competency category of tutors and tutors?” As a result of the homogeneity test, the difference in the utterance frequency between the tutor and tutee groups assumed by the researchers was not found. Nevertheless, this study provides a new approach to liberal arts education research that will be developed in the future by combining a qualitative research methodology and text mining technique using natural language processing in the liberal arts education research."
48,자연어 처리 기반 문구 추천 프로그램 설계,"김재훈(JaeHoon Kim),박수환(SuHwan Park),김온기(OnGi Kim),박수현(Suhyun Park)",한국정보통신학회,2021,한국정보통신학회 여성 ICT 학술대회 논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=f8ff520a9e0a49bc7ecd42904f0c5d65&keyword=자연어 처리,"대화는 인간관계에서 큰 영향을 미치는 중요한 매개체이다. 상황마다 적절한 단어와 어투가 있고 경험을 통해서 습득하는 대학 능력도 다양하다. 특수한 상황에서 경험이나 지식의 부족으로 어떤 말을 하는 것이 최선일지 알지 못하는 경우가 있을 수 있다. 본 논문에서는 인공지능 프로그래밍과 자연어 처리와 감정 분석을 통해 대화 전체의 주제와 흐름을 파악하여 여러 모델을 학습시킨 후 기존에 저장된 문장을 출력하는 것이 아닌 단어들을 조합하여 유연한 문장을 출력할 수 있는 프로그램을 설계한다. Conversation is an important thing that has a great influence on human relationships. For different situations, we have appropriate words and tones, and the ability to communicate through experience varies. In special circumstances, you may not know what is best to say because of a lack of experience or knowledge. In this paper, we design a program that can identify topics and flows throughout the conversation to learn different models and then output flexible sentences by combining words4rather than outputting previously-stored sentences by using Al, natural language processing, and emotion analysis."
49,근대계몽기 잡지 자연어 전처리 작업에서 문체 분류와 형태분석 방안에 대한 모색,전성규,한림대학교 한림과학원,2020,개념과 소통,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=347459c81dd93db17ecd42904f0c5d65&keyword=자연어 처리,"This paper classifies the style and discusses natural language processing problems presented by eleven academic journals published during the modern Enlightenment period which have been digitized to the Korean history database. This is a basic step in studying these journals, which deploy various types of stylistic formats, including Chinese, Korean, and Korean written in Chinese characters. These stylistic complexities are significant obstacles which prevent accurate data extraction by means of digital humanities methodologies based upon word processing.
Journal articles were initially classified into ten types, and those articles which predominantly used Chinese words with Korean grammatical patterns were selected for further research. This style was typically used by articles which translated or transcribed academic content, and also for articles which described new or revised legal codes. Thus, if digital humanities methodology is applied to articles selected by this stylistic criterion, research results tend to be more tightly focused upon the introduction of modern education and knowledge, and upon new concepts related to the legal, political, and economic fields.
The method of discourse analysis used by this study, in which stylistic criteria are used to segment the texts found in journals of modern Enlightenment for further analysis, is a useful and appropriate tool, since the various types of modern Enlightenment material are readily and recognizably separable on the basis of their writing style: each type tends toward a characteristic format. This segmentation also allows a clearer and more focused discussion of how to process the target data for each style, resulting in an increased accuracy for the data extracted, and a more effective understanding of the way in which the worldview of the authors is revealed by their stylistic choices.
In addition, this paper discusses the morphological analysis of the Chinese words, especially the processing of vocabulary in complex relations and derivative relations. The general criteria used in Korean linguistic analysis are inadequate for this kind of morphological analysis, which needs to be adapted to the specific research aims of a particular study. 본고는 근대계몽기 발간되어 한국사데이터베이스상에 전자화된 잡지 11종을 디지털인문학 방법론을 통해 연구하기 위한 기초단계로 문체 분류를 시도하고 자연어 처리문제를 논의하고자 하였다.
근대계몽기 잡지에서는 한문체, 국한문체, 국문체 등 여러 층위의 문체들이 복잡하게사용되고 있다. 이러한 특징은 단어 처리가 기본이 되는 디지털인문학 방법론 안에서는 정확한 데이터를 추출할 수 없게 하는 중요한 요인이 될 수 있어 우선적으로 잡지에 실린 기사에 대한 문체 분류를 시도하고, 다양한 문체의 특성을 보여 주는 근대계몽기 잡지에 대한 하나의 연구 방법으로 문체별 담론 분석의 방법을 제안하였다. 문체가 하나의 글쓰기 형식으로 강하게 인식되었던 근대계몽기 자료를 문체별로 파악할 경우, 그 형식이 담은 내용에 보다 특징적으로 접근할 수 있으며, 문체별로 그 대상 자료를 가공하는 방법에 보다 논의가 집중될 수 있다. 이는 근대계몽기 잡지를분절하여 보는 방법이지만, 데이터의 정확도를 보다 높이는 방법이기도 하고 문체의세계관을 드러내는 데 효율적인 방법이 될 수도 있다.
이에 따라 근대계몽기 잡지상의 문체를 10종으로 분류해 보았고, 그중 보다 가공이용이한 문체라고 판단되는 한문단어체가 주도적으로 사용된 기사에 한정해 형태분석에 관한 논의를 진행하였다. 한문단어체가 주도적으로 사용된 기사의 형태분석은 복합관계ㆍ파생관계에 있는 어휘들의 분석이 중요하다고 보았고, 이 경우 국어학적 분석 기준보다는 연구자의 연구 목적에 따른 형태분석이 이루어질 필요가 있다.
한문단어체는 근대계몽기 잡지 안에서 주로 학술적 내용을 번역 혹은 역술하여 싣거나, 관보나 민간 신문의 소식과 새로 재정되거나 개정된 법에 대한 소식을 요약하여전달하는 기사의 문체로 종종 선택되었다. 그렇기 때문에 한문단어체로 쓰인 기사를선별해 디지털인문학 방법론을 적용할 경우 근대 교육과 지식이 정립되거나 법ㆍ정치ㆍ경제 영역과 관련된 신개념 등이 유입되는 상황에 보다 주목한 연구 결과가 나올수 있다."
50,언어학적 특징을 고려한 자연어 처리 기반 한국어 요약 시스템,"이종원,박성준,김한중,정회경",한국지식정보기술학회,2023,한국지식정보기술학회 논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=5f4981f24519cc9bd18150b21a227875&keyword=자연어 처리,"As large-scale data is distributed through the Internet, it has become difficult for Internet users to find the data they need. In addition, when the form of data is text, it is required to compress and summarize the text. In this paper, we construct an efficient system for compressing and summarizing text composed of Korean using the Transformer Encoder-Decoder-based KoBART (Korean Bidirectional and Auto-Regulatory Transformers) model. This system consisted of a preprocessor that performs an extraction summary and a KoBART model that performs a generation summary. The preprocessor performs an extraction summary based on the sentence when a specific phrase appears considering the linguistic characteristics of the Korean language, and the KoBART model performs a generation summary on texts not processed by the preprocessor. The proposed system used the preprocessor considering the linguistic features of Korean and the KoBART model, which is a pre-learning language model, to compress and summarize text composed of Korean, and showed superior performance compared to the general extraction summary model and generation summary model. This suggests that a method of analyzing and utilizing the characteristics of a specific country's language in more detail can expect better results than using only a pre-learning language model with excellent performance. It is expected that this paper will be a leading study in spreading the synergy of the pre-learning language model with linguistic features and excellent performance. 인터넷을 통해 대규모 데이터가 유통되면서 인터넷 이용자들은 자신에게 필요한 데이터를 찾기 어려워졌다. 또한, 데이터의 형태가 텍스트인 경우 텍스트를 압축 및 요약하는 작업이 요구되고 있는 실정이다. 본 논문에서는 한국어 텍스트에 대해서 학습한 Transformer Encoder-Decoder 기반의 KoBART(Korean Bidirectional and Auto-Regressive Transformers) 모델을 활용하여 한국어로 구성된 텍스트를 압축 및 요약하기에 효율적인 시스템을 구축하였다. 본 시스템은 추출요약을 수행하는 전처리기와 생성요약을 수행하는 KoBART 모델로 구성하였다. 전처리기는 한국어의 언어학적 특징을 고려하여 특정 문구가 출현하였을 경우 해당 문장을 중심으로 추출요약을 수행하고 KoBART 모델은 전처리기가 처리하지 않은 텍스트들에 대해서 생성요약을 수행한다. 제안하는 시스템은 한국어로 구성된 텍스트를 압축 및 요약하기 위하여 한국어의 언어학적 특징을 고려한 전처리기와 사전학습 언어모델인 KoBART 모델을 활용하였으며 일반적인 추출요약 모델과 생성요약 모델에 비해 우수한 성능을 보였다. 이는 특정 국가의 언어가 가지는 특징을 보다 상세하게 분석하고 활용하는 방안이 우수한 성능의 사전학습 언어모델만을 활용하는 것보다 좋은 결과를 기대할 수 있다는 점을 시사한다. 본 논문이 언어학적 특징과 우수한 성능의 사전학습 언어모델의 시너지를 전파하는데 선도하는 연구가 될 수 있을 것으로 기대된다."
51,자연어 처리를 통한 코드 난독화 커버리지 측정,"김병연(Byeong Yeon Kim),김휘강(Huy Kang Kim)",한국정보보호학회,2021,정보보호학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=0844a59bb6d5ea35b7998d826d417196&keyword=자연어 처리,"난독화는 코드를 보호하고 분석을 위해 더 큰 노력을 요구하기 위한 목적으로 일반 앱부터 악성 앱까지 광범위하게 사용되고 있다. 따라서 공격자와 보안 담당자는 보안성 분석을 위해 앱이 어느 정도 난독화 되어있는지 아는 것이 중요한데, 현재 관련 연구 및 솔루션들의 성능은 좋지 않다. 첫 번째로 상용 솔루션들은 조금의 난독화만 발견해도 전체가 난독화 되었다고 판단하고 있다. 두 번째로, 읽을 수 있지만 이해할 수 없는 방식의 난독화를 발견하지 못한다. 마지막으로, 자체적으로 비공개 난독화 기술을 개발하여 난독화 하는 기업들도 생겨나고 있으므로 단순히 시중에 존재하는 난독화 도구의 규칙을 학습하는 기존 방법으로는 난독화를 탐지하는 것에 한계가 있다. 따라서 본 논문에서는 소스 코드를 문서처럼 학습하여 ‘코드를 얼마나 읽을 수 있는지’에 대한 것을 넘어서서 ‘얼마나 이해할 수 있는지’에 대한 관점으로 접근하였고, 자연어 처리, 휴리스틱을 통해 코드 난독화 구역을 측정할 수 있는 솔루션 “AndrObfusec”를 개발하여 높은 정확도로 난독화를 분류해 냈다. Obfuscation has been vastly applied to both malware and benign Android applications in the last years. Because Obfuscation hides the apps’ semantics from analysts by increasing the cost of reverse engineering and decompilation. Consequently, It is important for attackers and security team to measure the quantitative of obfuscation of the app for analysis. However, current research and solutions are surprisingly bad at detecting obfuscation.
  First, When only a small amount of obfuscation is found, They will have the tendency to judge that code as obfuscated. Second, They can not detect misunderstandable obfuscation techniques.
  Finally, The systems do not necessarily remain effective over time — when novel obfuscation techniques are proposed.
  In this work, we propose AndrObfusec, an Natural language processing and heuristic based system to detect obfuscation in Android applications, known as identifier renaming. This system examines a different aspect of the issue - It measure not only readability but also understandability with quantitative measurement for code obfuscation coverage. Particularly, AndrObfusec achieves an high accuracy for identifier renaming detection."
52,자연어 처리를 이용한 책 추천 시스템에 관한 연구,"김민우(Minwoo Kim),김성현(Sunghyun Kim),박대영(Daeyoung Park)",한국통신학회,2021,한국통신학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=09aec30fd88a0106d18150b21a227875&keyword=자연어 처리,"본 논문은 사용자가 입력한 단어와 키워드를 자연어 처리 기법을 통해 책을 추천해주는 시스템을 제안한다. 책의 소개 부분을 웹 크롤링하여 데이터 셋을 구축하며 책의 소개 부분에 들어간 각 단어의 빈도를 나타내는 TF-IDF 행렬을 구성한다. 이후에 Word2Vec 모델을 이용하여 사용자가 입력한 단어와 의미가 유사한 단어를 모아서 하나의 텍스트로 만들고, 이 텍스트와 코사인 유사도가 높은 책을 데이터셋의 책 소개 부분에서 찾아 사용자에게 제시한다."
53,자연어 처리(NLP) 기반 텍스트마이닝을 적용한 한국체육측정  평가학회지 연구동향 분석: 국문초록을 중심으로,조혜수,한국체육측정평가학회,2023,한국체육측정평가학회지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=749c6722e884803c47de9c1710b0298d&keyword=자연어 처리,"본 연구는 한국체육측정평가학회지의 연구 동향 분석을 위해 토픽모델링(LDA)을 활용했다. 특히, 정보의 소실을최소화하고자 분석 대상을 국문 초록으로 설정하였으며, Coherence 점수를 활용해 최적의 토픽 수를 결정하였다.
최종적으로 COVID-19가 이 분야의 연구 동향에 미친 영향을 분석하였고, 그로 인한 학문적 변화를 규명하였다.
연구의 목적을 달성하기 위해 한국체육측정평가학회지에 게재된 1999년 제1권 1호부터 2023년 제25권 1호까지를연구 대상으로 선정하였다. 그중 1999년부터 2004년까지의 59편의 국문 초록은 크롤링이 불가능하여 직접 전사처리를 진행하였고, 23편의 영문초록은 국문으로 번역 및 전사 처리하여 포함하였으며, 연구의 목적과 부합하지않는 4편을 분석 대상에서 제외하여 최종적으로 520편의 연구논문 국문 초록을 분석 대상으로 선정하였다. 국문초록을 기반으로 전처리(명사추출, 불용어 제거, 공통어변환)된 데이터를 토대로 상위 키워드 빈도분석, N-gram 분석, 토픽모델링(LDA), 토픽 점유율, 연도와 토픽 점유율 간 상관관계를 Python 3.5와 SPSS 27버전을 사용하여분석하였다.
연구 결과 ‘Topic 1: 척도 및 평가 기준 개발의 양호도’, ‘Topic 3: 경기 종목별 체력 특성 분석’, ‘Topic: 4 건강 체력 측정’, ‘Topic 5: 측정 및 분석 도구 양호도’는 음의 상관관계를 나타냈으나 유의미하지 않았다.  ‘Topic 6: 학교체육’ 토픽은 시간이 지남에 따라 점유율에 증·감의 변동 일정하였지만, 통계적으로 유의미하지 않았다. 반면‘Topic 2: 경기분석 및 빅데이터 활용’ 토픽은 연도가 증가할수록 점유율이 지속해 증가하였고 유의미한 양의 상관관계가 나타났다. 특히, COVID-19 이후 ‘경기분석 및 빅데이터’에 대한 활용 토픽의 중요성이 증가하고 있음을 확인할수 있었다."
54,"LUKE를 이용한 한국어 자연어 처리: 개체명 인식, 개체 연결","민진우,나승훈,김현호,김선훈,강인호",한국정보과학회,2022,정보과학회 컴퓨팅의 실제 논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=b64a5507ebe56c927ecd42904f0c5d65&keyword=자연어 처리,"Transformer-based language models (LM) such as BERT trained from a large amount of unlabeled corpus using self-supervised learning methods have shown remarkable performance improvement on various natural language processing (NLP) application tasks. Despite the marked improvements, the classical pretrained language model has not directly incorporate external real-world knowledge bases such as a Wikipedia knowledge graph or triples. To inject the real-world knowledge bases to a pretrained language model, many studies towards “knowledge enhanced” pretrained language models have been conducted. Among them, LUKE attaches a sequence of entities to a sequence of original input tokens and performs entity-aware self-attention using entity embeddings, leading to noticeable improved results on entity-related tasks and the state-of-the-art performance in SQuAD dataset. In this paper, we present a Korean version of LUKE pretrained from a large amount of Korean Wikipedia corpus and show its application results on entity-related tasks of Korean. In particular, we newly propose a way of applying LUKE to the entity linking task which has not been explored in the previous works of using LUKE. Experiment results on both Korean named entity recognition and entity linking tasks show improvements over the RoBERTa-based models. BERT와 같은 트랜스포머 기반의 언어 모델은 대용량의 레이블이 없는 말뭉치를 자가 학습방법을 통해 학습한 후 다양한 자연어 처리 응용 태스크에 적용하여 놀라운 성능 향상을 보였다. 이와 같은 언어 모델은 실세계 지식 정보를 표현할 수 없는 단점이 존재하고 이러한 문제를 해결하기 위해 언어 모델에 지식 베이스를 반영하려는 다양한 연구들이 수행되었다. 본 연구에서는 단어 시퀀스 이외에 엔티티 시퀀스와 임베딩을 정의하고 단어와 엔티티의 모든 시퀀스 쌍에 따라 별도의 쿼리 파라미터를 두고 셀프 어텐션을 수행하는 LUKE 모델을 한국어 위키피디아 상에서 학습한 후 엔티티 관련 태스크인 개체명 인식, 개체 연결에 적용하여 기존의 RoBERTa 기반 모델 대비 각각 0.5%p, 1.05%p의 성능 향상을 가져왔다."
55,"자연어 처리를 활용한 메타버스 보도, 연구 간 인식 차이 비교","이규호(Gyuho Lee),이준환(Joonhwan Lee)",한국멀티미디어학회,2022,멀티미디어학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=d996f8469e1a2177e9810257f7042666&keyword=자연어 처리,"While public interests in the metaverse are growing recently in the Korean media and research, its understanding has not been fully established yet. In this study, we aimed to probe whether the rapid growth in media attention about the metaverse has increased its usage as a buzzword accompanied by an absence of scientific context. We analyzed publications and online news containing metaverse from 2020 to 2022. The data analysis methods are 1) time series frequency, 2) keyword network, 3) natural language model. The findings indicate the perception gap about metaverse between research and news articles broadened as its popularity has grown. Research about metaverse gradually expanded its connections with related topics—virtual and augmented realities—focusing on social changes in a remote environment. However, media reporting frequently used metaverse as a buzzword rather than explaining its scientific background, stimulating the proliferation of related topics and the dispersion of news content. This study further discusses the need for a media strategy to improve public conception of the long-term development of the metaverse."
56,자연어 처리를 활용한 뉴스 분석 서비스,"김효림(Hyo-Lim Kim),한승연(Seung-Yun Han),이광재(Kwang-jae Lee)",대한전기학회,2021,대한전기학회 학술대회 논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=9b2ddf4e5c759a25c85d2949c297615a&keyword=자연어 처리,"최근 가짜 뉴스를 통한 허위사실 유포, 공인과 관련한 근거 없는 비방, 정치 사회 혼란기 때의 여론 조작 등 가짜 뉴스의 주제는 정해져 있지 않고, 무차별적으로 이뤄지고 있다. 하지만, 이러한 가짜 뉴스를 구별해낼 수 있는 사람들은 많지 않다. 따라서, 본 연구자들은 사용자 스스로 가짜 뉴스를 판별할 수 있게 도움을 주는 챗봇을 제안한다.

  뉴스 분석 챗봇 서비스는 기자의 신뢰도, 제목과 본문의 일치 정도, 기사 감정 분석, 올바른 맞춤법 사용이라는 4가지 기준을 웹 크롤링, Word2Vec, 감정 사전을 활용한 감정 분석, 맞춤법 검사를 통해 구현하였다. 또한 분석 결과를 사용자에게 제공하는 플랫폼으로는 카카오톡 채널을 사용하여 접근성을 높였다.

  본 시스템으로 사용자들은 가짜 뉴스를 구분하는데에 편리함을 얻고 스스로 판단하는 힘을 길러 조금이나마 가짜뉴스로부터 오는 사회혼란을 방지할 수 있도록 했다. 더 나아가, 판별에 적합한 기준들을 추가한다면, 사용자들은 해당 기사에 대한 더 다양한 분석 내용을 얻음으로써 보다 나은 시스템이 될 것으로 기대한다."
57,자연어 처리를 이용한 유튜브 댓글 여론 변화 분석,"박진우,서하영,이선호,은지우,김익수",한국지식정보기술학회,2022,한국지식정보기술학회 논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=41f5dc0ab919e27fe9810257f7042666&keyword=자연어 처리,"As information in online media has increased, various studies have been conducted on the effect of comments on public opinion. However, in the existing studies, experiments and surveys were conducted on individuals. This cannot be considered appropriate in that the situation of writing comments in an actual online environment is anonymous. In this paper, in order to overcome the limitations of existing research papers, we chose a method of selecting a medium in which public opinion has hardened to some extent and observing it. Among many online media, we selected YouTube, in which opinion sharing is most actively performed recently and information on comments is easy to obtain and specified the videos on topics in which public opinion could be changed over time. After that, we crawled comments on the videos and measured the degree of the emotion of the comments by conducting a natural language processing-based sentiment analysis using the KcELECTRA model. In addition, we visualized this and analyzed how much public opinion of the latter period is affected by early public opinion. The analysis result of this paper show that the probability of public opinion reversal is very low, which means that the probability that the initial public opinion will become the final public opinion is very high. Based on the conclusion of this study, we expect the public to realize that the public can be one of the users who are swept by public opinion, and to accept information from a more critical and objective perspective with caution. 온라인 매체에서 얻는 정보가 늘어나면서 댓글이 여론에 미치는 영향에 관한 다양한 연구가 진행되었다. 하지만 기존의 연구들은 개인을 대상으로 실험과 설문이 진행되었고, 이는 실제 온라인 환경에서는 댓글을 쓰는 상황이 익명 상태로 이루어진다는 점에서 적절하지 않다고 볼 수 있다. 본 논문에서는 기존 연구의 한계점을 극복하기 위해 여론이 어느 정도 굳어진 매체에 대해 여론 변화를 관측하는 방법을 선택했다. 많은 온라인 매체 중 최근 의견 공유가 가장 활발하게 이루어지며 댓글을 얻기 쉬운 매체인 유튜브를 선정하여, 여론 변화가 이뤄질 만한 영상을 선정하였다. 이후, API를 활용해 해당 영상에 대한 댓글을 크롤링하고, KcELECTRA 모델을 사용해 감성 분석을 하여 댓글의 긍정, 부정 정도를 측정하였다. 또한 이를 시각화하여 최종 여론이 초기 여론에 얼마나 큰 영향을 받는지에 관한 연구를 진행하였다. 본 연구의 분석 결과를 보면 여론이 반전되는 확률이 매우 낮음을 알 수 있으며, 이것은 초기 여론이 최종 여론으로 될 확률이 매우 크다는 것을 뜻한다. 본 연구의 결론을 바탕으로 우리는 대중들이 여론에 휩쓸리는 사용자 중 하나라는 것을 깨닫고, 경각심을 가지고 보다 비판적이고 객관적인 시각으로 정보를 받아들이기를 기대한다."
58,다양한 뉴스데이터를 이용한 자연어 처리모델 성능 비교,"Hyunwoo Ko,Jun Kwon Hwangbo",한국정보통신학회,2023,한국정보통신학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=ffd0dffa418dcf5947de9c1710b0298d&keyword=자연어 처리,"Natural Language Processing is one of the fields that attracts a lot of attention in deep learning, and with the introduction of transformer-based GPT[1] and BERT[2], it is showing tremendous performance improvement. In this paper, we compared and analyzed the performance of word embedding, neural network, and pre-trained language model, dependent othe model and data type of the news. ISOT, Kaggle, and Politifact datasets were used for fake news dataset as a result, BERT showed best performance in this study, however in Politifact Dataset, it showed relatively poor performance. We analyzed the structure of dataset and from the model perspectives to find out the reason why the performance differences were occurred."
59,의무 기록 문서 분류를 위한 자연어 처리에서 최적의 벡터화 방법에 대한 비교 분석,유성림,대한의용생체공학회,2022,의공학회지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=d51cee1b54c6ad8bd18150b21a227875&keyword=자연어 처리,"Medical records classification using vectorization techniques plays an important role in natural language processing. The purpose of this study was to investigate proper vectorization techniques for electronic med- ical records classification. Material and methods: 403 electronic medical documents were extracted retrospectively and classified using the cosine similarity calculated by Scikit-learn (Python module for machine learning) in Jupyter Notebook. Vectors for medical documents were produced by three different vectorization techniques (TF-IDF, latent sematic analysis and Word2Vec) and the classification precisions for three vectorization techniques were evaluated. The Kruskal-Wallis test was used to determine if there was a significant difference among three vectorization tech- niques. Results: 403 medical documents were relevant to 41 different diseases and the average number of documents per diagnosis was 9.83 (standard deviation=3.46). The classification precisions for three vectorization techniques were 0.78 (TF-IDF), 0.87 (LSA) and 0.79 (Word2Vec). There was a statistically significant difference among three vec- torization techniques. Conclusions: The results suggest that removing irrelevant information (LSA) is more efficient vectorization technique than modifying weights of vectorization models (TF-IDF, Word2Vec) for medical documents classification."
60,자연어 처리 딥러닝 모델 감정분석을 통한 감성콘텐츠 개발 연구,"이현수,김민하,서지원,김정이",국제문화기술진흥원,2023,The Journal of the Convergence on Culture Technolo,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=89fc479ee07db1674884a65323211ff0&keyword=자연어 처리,"본 연구는 자연어 처리 딥러닝 모델의 감정분석 정확성을 확인해보고 이를 감성 콘텐츠 개발에 활용하도록 제안한다. GPT-3모델의 개요를 살펴본 후 Aihub에서 제공하는 희곡 대사 데이터 약 6000개를 입력하고 ‘기쁨’, ‘슬픔’, ‘공포’, ‘분노’, ‘혐오’, ‘놀람’, ‘흥미’, ‘지루함’, ‘통증’ 총 9가지 감정 범주로 분류하였다. 이후 자연어 처리 모델 평가 방법인 정확도, 정밀도, 재현율, F1-score 의 평가지표를 활용하여 성능평가를 진행하였다. 감정분석 결과 91% 이상의 정확도를 보였으며 정밀도의 경우 ‘공포’,’통증’이 낮은 수치를 보였다. 재현도의 경우 ‘슬픔’, ‘분노’, ‘혐오’와 같은 부정적인 감정에서 낮은 수치가 나타났고 특히 ‘혐오’의 경우 데이터 양의 부족으로 인해 오차가 나타난 것으로 확인된다. 기존 연구의 경우 감정분석을 긍정, 부정, 중립으로 나누는 극성분석에만 주로 사용되어 그 특성상 피드백 단계에서만 사용되는 한계가 있었다. 본 연구는 감정분석을 9가지 범주로 확장하여 기획 단계에서부터 이를 고려한 개발을 통해 게임, 전시, 공연, 관광, 디자인, 에듀테크, 미디어 등에서 감성 콘텐츠 개발에 활용될 수 있음을 제안한다. 후속 연구를 통하여 더욱 다양한 일상 대화들을 추가로 수집하여 감정분석을 진행한다면 더욱 정확한 결과를 얻을 수 있을 것으로 기대된다."
61,음성인식과 자연어 처리 딥러닝을 통한 전자의무기록자동 생성 시스템,"손현곤,류기환",국제문화기술진흥원,2023,The Journal of the Convergence on Culture Technolo,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=018a0cd8f8e9a30d4884a65323211ff0&keyword=자연어 처리,"Recently, the medical field has been applying mandatory Electronic Medical Records (EMRs) and Electronic Health Records (EHRs) systems that computerize and manage medical records, and distributing them throughout the entire medical industry to utilize patients' past medical records for additional medical procedures. However, the conversations between medical professionals and patients that occur during general medical consultations and counseling sessions are not separately recorded or stored, so additional important patient information cannot be efficiently utilized. Therefore, we propose an electronic medical record system that uses speech recognition and natural language processing deep learning to store conversations between medical professionals and patients in text form, automatically extracts and summarizes important medical consultation information, and generates electronic medical records. The system acquires text information through the recognition process of medical professionals and patients' medical consultation content. The acquired text is then divided into multiple sentences, and the importance of multiple keywords included in the generated sentences is calculated. Based on the calculated importance, the system ranks multiple sentences and summarizes them to create the final electronic medical record data. The proposed system's performance is verified to be excellent through quantitative analysis. 최근 의료 현장은 전자의무기록, 전자건강기록 등의 의료 기록을 전산화하여 저장하고 관리하는 시스템이 의무적으로 적용되거나 전체 의료 현장에 보급되어 환자 개개인의 과거 의료 기록을 추가적인 의료 행위에 활용하고 있다. 그러나 일반적인 의료 문진 및 상담 간 발생하는 의료진과 환자 간의 대화는 별도로 기록되거나 저장되지 않고 있어 추가적인 환자의 주요 정보는 효율적으로 활용되지 못하고 있다. 이에 따라, 의료 문진 현장에서 발생하는 의료진과 환자와의 대화를 저장하고 이를 텍스트 데이터로 변환하여 주요한 문진 내용만 자동으로 추출, 요약하여 정보화하는 음성인식과 자연어 처리 딥러닝을 통한 의료 상담 요약문을 자동으로 생성하는 전자의무기록 시스템을 제안한다. 본 시스템은 의료 종사자와 환자의 의료 상담 내용의 인식과정을 거쳐서 텍스트 정보를 획득한다. 이렇게 획득된 텍스트를 복수의 문장으로 구분하고, 생성된 문장에 포함된 복수 키워드의 중요도를 산출한다. 산출된 중요도를 기반으로 복수의 문장에 순위를 매기고, 순위를 기반으로 문장들을 요약하여 최종 전자의무기록 데이터를 생성한다. 제안하는 시스템 성능은 정량적 분석을 통하여 우수함을 확인한다."
62,논문 및 특허 데이터를 활용한 자연어 처리 기반 ICT 동향 분석 연구,"최은영,김예은,우창완,최예림",한국EA학회,2020,정보기술아키텍처연구,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=2e68650353ee3207e9810257f7042666&keyword=자연어 처리,"많은 기업들은 지속적으로 발전하는 정보통신기술(ICT)에 발맞추고자 이를 파악하는데 높은 관 심을 갖고 있다. 기존의 ICT 동향 분석에 관한 연구들은 비교적 적은 양의 데이터를 사용하거나 특정 종류의 데이터 혹은 특정 분야만을 중점적으로 분석하였다. 하지만, 정확한 기술 동향 파악을 위해서 는 한정된 분야가 아닌 전반적인 분야에 대한 분석이 필요하다. 따라서 본 논문에서는 전문가가 선정 한 주요 ICT 용어를 기반으로 논문 및 특허 데이터를 활용한 ICT 동향 분석 연구를 진행한다. 구체 적으로, ICT 용어가 포함된 문서의 빈도수, 이를 기반으로 한 단어의 위상, 그리고 단어 간 네트워크 분석을 수행한다. 2018년 및 2019년 발행 문서에 대해 각각 분석을 진행한 후, 결과를 비교하여 앞 으로의 ICT 동향을 제시한다. Companies are increasingly interested in the identification of the trends in information and communication technology (ICT) as ICTs are rapidly developing. Previous research on the analysis of ICT trends utilized relatively small sized data or focused only on a specific data or field. In order to identify ICT trends clearly, it is necessary to analyze data covering the overall fields. To this end, in this paper, trend analysis is conducted using manuscript and patent data based on the ICT related keywords selected by experts. In detail, keyword frequency analysis, positioning of keywords based on their frequencies, and keyword network analysis are performed. Documents published in 2018 and 2019 are analyzed separately and compared to identify the future technology trends."
63,자연어 처리 모델을 활용한 퍼징 시드 생성 기법,"김동영,전상훈,류민수,김휘강,Kim, DongYonug,Jeon, SangHoon,Ryu, MinSoo,Kim, Huy Kang",한국정보보호학회,2022,정보보호학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=8a22009f2c2cf9544884a65323211ff0&keyword=자연어 처리,"Fuzzing에서 seed corpus의 품질은 취약점을 보다 빠르게 찾기 위해서 중요한 요소 중 하나라고 할 수 있다. 이에 dynamic taint analysis와 symbolic execution 기법 등을 활용하여 효율적인 seed corpus를 생성하는 연구들이 진행되어왔으나, 높은 전문 지식이 요구되고, 낮은 coverage로 인해 광범위한 활용에 제약이 있었다. 이에 본 논문에서는 자연어 처리 모델인 Sequence-to-Sequence 모델을 기반으로 seed corpus를 생성하는 DDRFuzz 시스템을 제안한다. 본 논문에서 제안하는 시스템은 멀티미디어 파일을 입력값으로 하는 5개의 오픈소스 프로젝트를 대상으로 관련 연구들과 비교하여 효과를 검증하였다. 실험 결과, DDRFuzz가 coverage와 crash count 측면에서 가장 뛰어난 성능을 나타냄을 확인할 수 있었고, 또한 신규 취약점을 포함하여 총 3개의 취약점을 탐지하였다."
64,자연어 처리 AI 모델의 편향 원인과 해결책 : 문헌을 통한 탐색적 연구,"한민수,민진영",한국경영정보학회,2023,한국경영정보학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=17b0ea0687435ae46aae8a972f9116fb&keyword=자연어 처리,"최근 자연어 처리(NLP: Natural Language Processing) 인공지능(AI: Artificial Intelligence) 모델은 여러 분야에서 활용되며 크게 발전하고 있다. 그러나 모델이 특정 집단에 유리하게 설계되거나 학습된 모델에 인간의 선입견이 반영되는 등 다양한 원인으로 인해 편향 문제가 발생하고 있다. 이러한 편향은 AI 모델의 공정성과 신뢰성을 떨어뜨려 사회에 악영향을 미치고 AI 모델의 궁극적인 발전을 저해한다. 따라서, 본 연구는 NLP AI 모델의 편향 문제와 그것을 일으키는 다양한 원인 및 해결방법에 대해 선행 연구 분석을 통해 살펴보고, 원인과 해결 방법 간의 관계 구조를 정리한다. 향후 이 결과를 이용하여 데이터 및 모델 설계를 시뮬레이션하고 본 연구에서 제시한 편향 문제의 증상- 원인-해법 구조를 검증하려 한다. 나아가 이를 통해 편향 확인 및 해결을 위한 가이드라인을 제시한다."
65,자연어 처리 기반 멀티 소스 이벤트 로그의 보안 심각도 다중 클래스 분류,서양진,한국정보보호학회,2022,정보보호학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=946240fd0a7faf3547de9c1710b0298d&keyword=자연어 처리,"Log data has been used as a basis in understanding and deciding the main functions and state of information systems. It has also been used as an important input for the various applications in cybersecurity. It is an essential part to get necessary information from log data, to make a decision with the information, and to take a suitable countermeasure according to the information for protecting and operating systems in stability and reliability, but due to the explosive increase of various types and amounts of log, it is quite challenging to effectively and efficiently deal with the problem using existing tools. Therefore, this study has suggested a multiclass classification of the security severity level of multi-source event log using machine learning based on natural language processing. The experimental results with the training and test samples of 472,972 show that our approach has archived the accuracy of 99.59%. 로그 데이터는 정보 시스템의 주요 동작과 상태를 이해하고 판단하는 근거로 사용되어 왔으며, 여러 보안 분야 응용에서도 중요한 입력 데이터로 사용된다. 로그 데이터로부터 필요한 정보를 얻어 이를 근거로 의사 결정을 하고, 적절한 대응 방안을 취하는 것은 시스템을 보호하고 안정적으로 운영하는 데 있어 필수적인 요소이지만, 로그의 종류와 양이 폭발적으로 증가함에 따라 기존 도구들로는 효과적이고 효율적인 대응이 쉽지 않은 상황이다. 이에 본 연구에서는 자연어 처리 기반의 머신 러닝을 이용해 멀티 소스 이벤트 로그의 보안 심각도를 여러 단계로 분류하는 방법을 제안하였으며, 472,972건의 훈련 및 테스트 샘플을 이용하여 실험을 수행한 결과 99.59%의 정확도를 달성하였다."
66,감정인지강화를 위한 자연어 처리 기반 챗봇 서비스,"이수진(Sujin Lee),이한솔(Hansol Lee),문성운(Sungwoon Moon),김진우(Jin Woo Kim)",한국HCI학회,2020,한국HCI학회 학술대회,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=d4d05f921ff0007bb36097776a77e665&keyword=자연어 처리,이 논문은 밀레니얼 세대가 다양한 정신질환 진단률이 높아지는 것에 경각심을 느낀 후 정신질환과 감정표현불능증 사이의 유의한 관계를 바탕으로 감정표현불능증을 해소하기 위한 감정인지 강화를 유도하는 A.I. 기반 챗봇 서비스 사례를 소개하고 있다.
67,자연어 처리 기반 교수자의 온라인 글쓰기 피드백 양상 유형화 연구,이슬기,한국텍스트언어학회,2023,텍스트언어학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=5fbf479b1a0276077ecd42904f0c5d65&keyword=자연어 처리,"The purpose of this study is to categorize feedback provided by instructors according to the focus and mode, based on pattern recognition related to natural language processing. This study analyzed the feedback provided by 20 writing professors on 30 pieces of online writing each, adding up to a total of 600 pieces. The analysis was conducted using a combination of machine learning methods such as clustering from unsupervised learning and classification from supervised learning. As a result of clustering, focus was classified into four types: context, content, organization, and correctness. Mode was classified into three types: reflective statement and praise, correction and command, and advice and suggestion. The types of focus and mode were predicted by dividing the pieces by paragraph. Then, types and predicted values were applied to the neural network model to derive the types of instructor feedback through a deep learning method. Finally, this study identified the possibility of instructor feedback categorization by examining the examples of instructor feedback by type and discussing their differences."
68,자연어 처리 기반 『傷寒論』 辨病診斷體系 분류를 위한 기계학습 모델 선정,김영남,대한상한금궤의학회,2022,대한상한금궤의학회지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=ba93bd4a6b90df88b36097776a77e665&keyword=자연어 처리,"Objective : The purpose of this study is to explore the most suitable machine learning model algorithm for Shanghanlun diagnostic system classification using natural language processing (NLP).
Methods : A total of 201 data items were collected from 『Shanghanlun』 and 『Clinical Shanghanlun』, ‘Taeyangbyeong-gyeolhyung’ and ‘Eumyangyeokchahunobokbyeong’ were excluded to prevent oversampling or undersampling. Data were pretreated using a twitter Korean tokenizer and trained by logistic regression, ridge regression, lasso regression, naive bayes classifier, decision tree, and random forest algorithms. The accuracy of the models were compared.
Results : As a result of machine learning, ridge regression and naive Bayes classifier showed an accuracy of 0.843, logistic regression and random forest showed an accuracy of 0.804, and decision tree showed an accuracy of 0.745, while lasso regression showed an accuracy of 0.608.
Conclusions : Ridge regression and naive Bayes classifier are suitable NLP machine learning models for the Shanghanlun diagnostic system classification."
69,자연어 처리(NLP)기반 텍스트마이닝을 활용한 소나무에 대한 국내외 연구동향(2001∼2020) 분석,"이진규,이창배",경상대학교 농업생명과학연구원,2022,농업생명과학연구,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=016a8cb56cc3d9b94884a65323211ff0&keyword=자연어 처리,"본 연구는 최근 20년간(2001~2020) 소나무에 관한 주요 연구 주제 및 연구영역 분석을 통한 향후 연구 방향성을 파악하고자 하였다. 이를 위해 Python.3.9.0과 Textom를 활용하여 RISS와 Web of Science의 소나무 관련 총 3866편의 논문 제목과 키워드 데이터를 수집하고 분석을 실시하였다. 분석 결과, 국가별 총 논문 수는 일본 383편(46.8%), 한국 363편(44.4%), 중국 78편(9.5%)순으로 소나무 자생국가를 중심으로 한 관련 연구들이 활발히 진행되었다. 단어 빈도 및 TF-IDF, N-gram, CONCOR 분석을 통해 국내와 국외에서 소나무 관련 주요 연구 주제는 소나무재 선충으로 나타났으며, 사회 및 경제적 환경, 관련 정책 등 차이에 의해 국내와는 달리 국외에서는 '균근' 관련 연구가 주요 연구 영역으로 도출되었다. 또한 소나무 관련 연구는 일부 인문 사회학적인 연구들이 진행되었지만 주로 생태적인 측면에 집중되어 있는 것으로 나타 났다. 이에 소나무의 인문·사회학적 가치를 고려할 때 향후 연구에서는 이와 관련 후속연구가 필요할 것으로 판단된다. The purpose of this study is to analyze domestic and foreign research trends and future direction of Pinus densiflora in recent 20 years using text mining. A total of 3866 academic papers related to Pinus densiflora were collected by the ‘RISS’ and‘WOS’ and the collected data is analyzed by Python 3.9.0 and UCINET. The findings of this study show that academic papers on the theme of Pinus densiflora with the ranking of Japan (383 papers, 46.8%), the Korea (363 papers, 44.4%), U.S. (78 papers, 9.5%) and so on. This result indicates that researches are the most vigorously conducted in pine tree native nations. From the results of TF, TF-IDF, N-gram and CONCOR analyses. The major research topic was pine wilt disease Bursaphelenchus xylophilus over the past 20 years. The studies related to‘mycorrhiza’were derived as major research subject in foreign than Korea. In addition, some humanities and social studies have been conducted on Pinus densiflora, but they are mainly focused on ecological aspects. Considering the humanistic and social value of Pinus densiflora, it need to expand research topics on humanities and social values."
70,자연어 처리 기법을 활용한 산업재해 위험요인 구조화,"강성식,장성록,이종빈,서용윤,Kang, Sungsik,Chang, Seong Rok,Lee, Jongbin,Suh, Yongyoon",한국안전학회,2021,한국안전학회지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=00825e0581de59d6b36097776a77e665&keyword=자연어 처리,"The narrative texts of industrial accident reports help to identify accident risk factors. They relate the accident triggers to the sequence of events and the outcomes of an accident. Particularly, a set of related keywords in the context of the narrative can represent how the accident proceeded. Previous studies on text analytics for structuring accident reports have been limited to extracting individual keywords without context. We proposed a context-based analysis using a Natural Language Processing (NLP) algorithm to remedy this shortcoming. This study aims to apply Word2Vec of the NLP algorithm to extract adjacent keywords, known as word embedding, conducted by the neural network algorithm based on supervised learning. During processing, Word2Vec is conducted by adjacent keywords in narrative texts as inputs to achieve its supervised learning; keyword weights emerge as the vectors representing the degree of neighboring among keywords. Similar keyword weights mean that the keywords are closely arranged within sentences in the narrative text. Consequently, a set of keywords that have similar weights presents similar accidents. We extracted ten accident processes containing related keywords and used them to understand the risk factors determining how an accident proceeds. This information helps identify how a checklist for an accident report should be structured."
71,연구개발정보 문헌 자동분류를 위한 자연어 처리 딥러닝 모델 개발: 기후기술 분류체계를 중심으로,"주경원,이관수,이성만,최안준,노건태,천지영",대한전자공학회,2022,전자공학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=fed6c6d1bb4ff85fc85d2949c297615a&keyword=자연어 처리,"신기후체제에 들어서며 전세계적으로 탄소중립을 선언하고 있으며 이를 위해 국가연구개발사업이 어떤 기후기술에 투자되고 있는지 관심이 고조되고 있다. 본 연구에서는 국가연구개발사업들의 문헌정보를 활용하여 45개의 기후기술 분류체계로 자동분류하는 딥러닝 모델을 개발하였다. NTIS에 등록되어 있는 2016∼2020년에 수행된 291,381건의 연구개발과제 중 2016∼2019년의 217,880건은 훈련 데이터셋으로, 2020년의 73,501건은 테스트 데이터셋으로 구분하여 실험하였다. 형태소 분석을 위해 kiwi와 Mecab을 사용하였으며 딥러닝 모델의 구조는 1D-CNN을 활용한 FC, EC 모델과 ELECTRA 사전학습 모델을 활용한 KoE 모델을 개발하였다. 각 클래스별 빈도의 편차가 큰 불균형데이터임을 고려하여 성능지표로 F1 스코어를 활용하였으며 각 개별모델과 앙상블 모델의 성능을 확인하였다. 개별모델에서는 키워드 빈도를 중심으로 학습하는 FC 모델이 0.824의 F1 스코어로 가장 우수했으며, 앙상블 모델에서는 개별모델 모두를 소프트 보팅(soft voting)한 Ens4 모델이 0.833의 F1 스코어로 가장 높은 성능을 나타냈다. 일반적인 말뭉치보다 전문적인 용어를 다수 포함하고 있는 대량의 기술문서 자동분류에서 본 모델을 사용한다면 기술전문가가 직접 라벨링하는 방법보다 보다 효율적인 프로세스를 갖출 수 있을 것이다."
72,"SNS대상의 지능형 자연어 수집, 처리 시스템 구현을 통한 한국형 감성사전 구축에 관한 연구",이종화,한국정보시스템학회,2020,情報시스템硏究,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=e20ad6d20ed10ac57f7a54760bb41745&keyword=자연어 처리,"Purpose: The research was studied the hierarchical Hangul emotion index by organizing all the emotions which SNS users are thinking. As a preliminary study by the researcher, the English-based Plutchick (1980)'s emotional standard was reinterpreted in Korean, and a hashtag with implicit meaning on SNS was studied. To build a multidimensional emotion dictionary and classify three-dimensional emotions, an emotion seed was selected for the composition of seven emotion sets, and an emotion word dictionary was constructed by collecting SNS hashtags derived from each emotion seed. We also want to explore the priority of each Hangul emotion index.
Design/methodology/approach: In the process of transforming the matrix through the vector process of words constituting the sentence, weights were extracted using TF-IDF (Term Frequency Inverse Document Frequency), and the dimension reduction technique of the matrix in the emotion set was NMF (Nonnegative Matrix Factorization) algorithm. The emotional dimension was solved by using the characteristic value of the emotional word. The cosine distance algorithm was used to measure the distance between vectors by measuring the similarity of emotion words in the emotion set.
Findings: Customer needs analysis is a force to read changes in emotions, and Korean emotion word research is the customer's needs. In addition, the ranking of the emotion words within the emotion set will be a special criterion for reading the depth of the emotion. The sentiment index study of this research believes that by providing companies with effective information for emotional marketing, new business opportunities will be expanded and valued. In addition, if the emotion dictionary is eventually connected to the emotional DNA of the product, it will be possible to define the “emotional DNA”, which is a set of emotions that the product should have."
73,자연어 및 시계열 데이터 처리를 지원하는 C++ 기반 오픈소스 딥러닝 프레임워크 WICWIU.v3,"오준석,이찬효,우옥균,김인중",한국정보과학회,2023,정보과학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=9a5aff0c8b8bc5304884a65323211ff0&keyword=자연어 처리,"WICWIU is the first open-source deep learning framework developed by Korean university. In this work, we developed WICWIU.v3 that includes features for natural language and time-series data processing. WICWIU was designed for C++ environment, and supports GPU-based parallel processing, and has excellent readability and extensibility, allowing users to easily add new features. In addition to WICWIU.v1 and v2 that focus on image processing models, such as convolutional neural networks (CNN) and general adversarial networks (GAN), WICWIU.v3 provides classes and functions for natural language and time-series data processing, such as recurrent neural networks (RNN), including LSTM (Long Short-Term Memory Networks) and GRU (Gated Recurrent Units), attention modules, and Transformers. We validated the newly added functions for natural language and time-series data by implementing a machine translator and a text generator with WICWIU.v3. WICWIU(위큐)는 국내 대학에서 최초로 공개한 오픈소스 딥러닝 프레임워크이다. 본 연구에서는 자연어 및 시계열 데이터 처리 기능들이 추가된 WICWIU.v3를 개발하였다. WICWIU는 C++ 환경을 위해 설계되었고, GPU 기반 병렬처리를 지원하며, 가독성과 확장성이 우수해 사용자가 직접 새로운 기능을 추가하기에 용이하다. CNN(Convolutional Neural Networks), GAN(Generative Adversarial Networks) 등 영상처리 모델에 중점을 둔 WICWIU.v1과 v2에 비해 WICWIU.v3에는 LSTM(Long Short-Term Memory Networks)과 GRU(Gated Recurrent Units)를 포함한 순환 신경망(RNN), 어텐션 모듈, 트랜스포머(Transformer) 등 자연어 및 시계열 데이터 처리를 위한 클래스와 함수들이 추가되었다. WICWIU.v3를 이용해 기계번역 및 텍스트 합성 모델을 구현함으로써 새로 추가된 자연어 및 시계열 처리 기능들이 정상적으로 동작함을 확인하였다."
74,검색엔진과 자연어 생성 모델을 결합한 문서 내 정보 처리 챗봇 서비스,"김명준(MyeongJun Kim),김명헌(MyungHun Kim),김태일(Taeil Kim),전현진(HyeonJin Jeon),황유민(YuMin Hwang),유철중(CheolJung Yoo)",한국정보기술학회,2023,Proceedings of KIIT Conference,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=1bf6c890ed74e8e847de9c1710b0298d&keyword=자연어 처리,"현재 개인 및 조직은 저장하는 문서들이 많아질수록 관리 및 정보 추출에 어려움을 겪고 있고, 출시된 언어생성모델들은 사용자가 관리하는 문서들의 내용을 반영한 질의능력이 떨어진다. 이를 해결하기 위해 언어생성모델과 검색엔진을 결합하여 개인과 조직의 정보를 기반으로 사용자가 원하는 정보를 반환할 수 있는 서비스를 제공할 필요가 있다. 또한, 이런 해결 방안을 적용하면 문서 요약과 번역 등 부수적인 효과도 기대할 수 있다. 본 논문에서는 언어생성모델 중 GPT-3.5와 검색엔진 중 하나인 Elastic Search를 이용하여 웹 애플리케이션을 제작하였다. Currently, as more documents are stored, individuals and organizations are having difficulty in managing and extracting information, and the released language generation models have less ability to query the contents of documents managed by users. To solve this problem, it is necessary to provide a service that combines language generation models and search engines to return information that users want based on individual and organizational information. In addition, if these solutions are applied, additional effects such as document summary and translation can be expected. In this paper, a web application was created using GPT-3.5 among language generation models and Elastic Search, one of the search engines."
75,불균형 데이터 처리를 통한 소프트웨어 요구사항 분류 모델의 성능 개선에 관한 연구,"최종우,이영준,임채균,최호진,Jong-Woo Choi,Young-Jun Lee,Chae-Gyun Lim,Ho-Jin Choi",한국정보처리학회,2023,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=9404243beae0813eb7998d826d417196&keyword=자연어 처리,"자연어로 작성되는 소프트웨어 요구사항은 이해관계자가 바라보는 관점에 따라 의미가 달라질 수 있다. 품질 속성 기반으로 아키텍처 설계시에 품질 속성별로 적합한 설계 전술(Tactic)을 선택해야 효율적인 설계가 가능해 품질 속성 요구사항의 정확한 분류가 필요하다. 이에 따라 고비용 작업인 요구사항 분류에 관한 자연어처리 모델이 많이 연구되고 있지만, 품질 속성 데이터셋(dataset)의 불균형을 처리해 분류 성능을 개선하는 주제는 많이 다루고 있지 않다. 본 연구에서는 먼저 실험을 통해 분류 모델이 한국어 요구사항 데이터셋을 자동으로 분류할 수 있음을 보인다. 이 결과를 바탕으로 EDA(Easy Data Augmentation) 기법을 통한 데이터 증강과 언더샘플링(undersampling) 전략으로 품질 속성 데이터셋의 불균형을 개선할 수 있음을 설명하고 요구사항의 카테고리 분류에 효과가 있음을 보인다. 실험 결과 F1 점수(F1-Score) 기준으로 최대 5.24%p 향상되어 불균형 데이터 처리 기법이 분류 모델의 한국어 요구사항 분류에 도움이 됨을 확인할 수 있다. 또한, EDA의 세부 실험을 통해 분류 성능 개선에 도움이 되는 데이터 증강 연산에 관해 설명한다. Software requirements written in natural language may have different meanings from the stakeholders' viewpoint. When designing an architecture based on quality attributes, it is necessary to accurately classify quality attribute requirements because the efficient design is possible only when appropriate architectural tactics for each quality attribute are selected. As a result, although many natural language processing models have been studied for the classification of requirements, which is a high-cost task, few topics improve classification performance with the imbalanced quality attribute datasets. In this study, we first show that the classification model can automatically classify the Korean requirement dataset through experiments. Based on these results, we explain that data augmentation through EDA(Easy Data Augmentation) techniques and undersampling strategies can improve the imbalance of quality attribute datasets, and show that they are effective in classifying requirements. The results improved by 5.24%p on F1-score, indicating that handling imbalanced data helps classify Korean requirements of classification models. Furthermore, detailed experiments of EDA illustrate operations that help improve classification performance."
76,텍스트 요약을 위한 스파크 기반 대용량 데이터 전처리,"지동준 ( Dong-jun Ji ),전희국 ( Hee-gook Jun ),임동혁 ( Dong-hyuk Im )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=a525d3671063ac2eb36097776a77e665&keyword=자연어 처리,"텍스트 요약(Text Summarization)은 자연어 처리(NLP) 분야의 주요 작업 중 하나이다. 높은 정확성을 보이는 문서 요약 딥 러닝 모델을 만들기 위해서 대용량 학습 데이터가 필요한데, 대용량 데이터 전처리 과정에서 처리 시간, 메모리 관리 등과 같은 문제가 발생한다. 본 논문에서는 대규모 병렬처리 플랫폼 Apache Spark 를 사용해 추상 요약 딥 러닝 모델의 데이터 전처리 과정을 개선하는 방법을 제안한다. 실험 결과 제안한 방법이 기존 방법보다 데이터 전처리 시간이 개선된 결과를 보이고 있다."
77,온라인 커뮤니티에서 사용되는 댓글의 형태를 고려한 악플 탐지를 위한 전처리 기법,"김해수 ( Kim Hae Soo ),김미희 ( Kim Mi Hui )",한국정보처리학회,2023,정보처리학회논문지. 컴퓨터 및 통신시스템,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=7c2af658e8ad56967f7a54760bb41745&keyword=자연어 처리,"인터넷이 보급되면서 사람들 간의 소통을 위한 커뮤니티가 활성화됨과 함께 익명 커뮤니티가 나타났고 익명성을 이용한 공격적인 게시글, 댓글을 남기는 등 타인에게 피해를 주는 행위를 하는 이용자가 많아지고 있다. 과거에는 관리자가 직접 글과 댓글을 확인하며 삭제 및 차단했지만, 커뮤니티 이용자가 늘어나면서 관리자가 계속 감시할 수 없는 수준에 이르렀다. 초기에는 특정 단어가 포함되면 해당 글을 게시하거나 댓글을 달 수 없는 형태로 악의적인 글이 게시되는 것을 막는 단어 필터링 기법을 사용하였으나 유사한 단어를 사용하는 등 우회하는 형식으로 필터링을 피해 갔다. 이를 해결하는 방법으로 딥러닝을 이용하여 실시간으로 이용자들이 게시하는 글들을 감시하였으나 최근 커뮤니티에서는 해당 커뮤니티에서만 이해할 수 있는 단어를 사용하거나 일반적인 한글이 아닌 인간의 시야에서만 이해할 수 있는 문자를 사용하고 있다. 이들이 사용하는 문자의 종류나 형태가 다양하여 인공지능 모델에 모든 것을 학습시키기에 어려움이 있다. 이에 본 논문에서는 한글의 자음과 모음 띄어쓰기 이미지를 학습시킨 CNN 모델을 이용해서 문장의 각 문자를 이미지화해 인간의 시야에서만 이해할 수 있는 문자를 모델이 예측한 문자로 변환하는 전처리 기법을 제안한다. 실험 결과, 제안한 전처리 기법을 통해 LSTM, BiLSTM, CNN-BiLSTM 모델에서의 성능이 각각 3.2%, 3.3%, 4.88% 증가함을 확인했다. With the spread of the Internet, anonymous communities emerged along with the activation of communities for communication between people, and many users are doing harm to others, such as posting aggressive posts and leaving comments using anonymity. In the past, administrators directly checked posts and comments, then deleted and blocked them, but as the number of community users increased, they reached a level that managers could not continue to monitor. Initially, word filtering techniques were used to prevent malicious writing from being posted in a form that could not post or comment if a specific word was included, but they avoided filtering in a bypassed form, such as using similar words. As a way to solve this problem, deep learning was used to monitor posts posted by users in real-time, but recently, the community uses words that can only be understood by the community or from a human perspective, not from a general Korean word. There are various types and forms of characters, making it difficult to learn everything in the artificial intelligence model. Therefore, in this paper, we proposes a preprocessing technique in which each character of a sentence is imaged using a CNN model that learns the consonants, vowel and spacing images of Korean word and converts characters that can only be understood from a human perspective into characters predicted by the CNN model. As a result of the experiment, it was confirmed that the performance of the LSTM, BiLSTM and CNN-BiLSTM models increased by 3.2%, 3.3%, and 4.88%, respectively, through the proposed preprocessing technique."
78,자연어의 논리식으로의 변환을 이용한 고급검색 및 이를 활용한 히스토리 검색,"이대홍,유한석,박상원",한국정보처리학회,2020,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=ca70f4f8c1e49e0dc85d2949c297615a&keyword=자연어 처리,"Nowadays there are over 1.6 billion web pages and it is hard to get necessary results that user wants. Most search engines allow you to search with logical form to get accurate results. However, normal users are not familiar to search information as logical form. Therefore, they search in natural language rather than in complicated logical form. In this paper there are some suggestions to improve quality of searching results, converting natural language input by the user into logical form which can able to use advanced search engine. Users tend to make short searches due to the ‘Simplicity’ which is one of the features of the search form. Therefore we suggest history retrieval method; advanced version of previous suggestion to provide convenience to the normal users. We had improvement on accuracy of the search results converting natural languages to logical form and also can contain every keyword without missing any keywords using searching methods on this paper. It is expected that these search methods will contribute to the development of search engines. 현재 웹에서 존재하는 웹페이지는 16억개 이상이며 이중에서 원하는 검색결과를 얻기란 쉽지 않은 일이다. 대부분의 검색엔진에서는 정밀한 검색결과를 제공하기 위하여 논리식의 형태로 검색할 수 있게 하고 있다. 하지만 일반적인 경우 사람들은 원하는 정보를 논리식 형태로 검색하는데 익숙하지 않다. 때문에 복잡한 논리식 형태로 검색하기 보다는 자연어로 검색한다. 따라서 본 논문에서는 사용자가 입력하는 자연어 질의를 검색엔진의 고급검색을 사용할 수 있는 논리식으로 변환하여 검색결과의 품질을 향상시켜주는 검색방법을 제안한다. 또한 사용자들은 검색형태의 특징 중 하나인 단순성에 의해 길게 검색하기 보다는 여러 번의 짧은 검색을 이용하는 경우가 훨씬 많다. 이에 따라 사용자들에게 편리성을 제공하기 위하여 앞에서 제안한 검색방법을 활용한 히스토리 검색방법을 제안한다. 본 논문의 검색방법들을 사용한 결과 자연어 상태의 검색결과보다 논리식으로 변환한 검색결과의 정확도가 개선되었고 누락되는 키워드 없이 사용자가 검색하고자하는 모든 키워드를 반영할 수 있다. 이러한 검색방법이 검색엔진의 발전에 기여할 것으로 기대한다."
79,청각 장애인을 위한 수어 영상-자연어 번역 서비스 및 모바일 어플리케이션 구현,"조수민 ( Su-min Cho ),조성연 ( Seong-yeon Cho ),신소연 ( So-yeon Shin ),이지항 ( Jee Hang Lee )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=9e20d3a838e72d83d18150b21a227875&keyword=자연어 처리,"Covid-19 로 인한 마스크 착용이 청각장애인들의 소통을 더 어렵게 하는 바, 제 3 자의 도움 없이 쌍방향 소통을 가능하게 하는 서비스의 필요성이 커지고 있다. 이에 본 논문은 소통의 어려움을 겪는 청각장애인과 비청각장애인을 위한 쌍방향 소통 서비스에 대한 연구와 개발 과정, 기대 효과를 담는다. 서비스는 GRU-CNN 하이브리드 아키텍처를 사용하여 데이터셋을 영상 공간 정보와 시간 정보를 포함한 프레임으로 분할하는 영상 분류 기법과 같은 딥 러닝 알고리즘을 통해 수어 영상을 분류한다. 해당 연구는 “눈속말” 모바일 어플리케이션으로 제작 중이며 음성을 인식하여 수어영상과 텍스트로 번역결과를 제공하는 청각장애인 버전과 카메라를 통해 들어온 수어 영상을 텍스트로 변환하여 음성과 함께 제공하는 비청각장애인 버전 두 가지로 나누어 구현한다. 청각장애인과 비장애인의 쌍방향 소통을 위한 서비스는 청각장애인이 사회로 나아가기 위한 가장 기본적인 관문으로서의 역할을 할 것이며 사회 참여를 돕고 소통이라는 장벽을 넘어서는 발돋움이 될 것이라 예측된다."
80,발화 의도 예측 및 슬롯 채우기 복합 처리를 위한 한국어 데이터셋 개발,"한승규,임희석",한국융합학회,2021,한국융합학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=4fbca88c6b8a8198b36097776a77e665&keyword=자연어 처리,"사람의 발화 내용을 이해하도록 하는 언어 인식 시스템은 주로 영어로 연구되어 왔다. 본 논문에서는 시스템과 사용자의 대화 내용을 수집한 말뭉치를 바탕으로 언어 인식 시스템을 훈련시키고 평가할 때 사용할 수 있는 한국어 데이터셋을 개발하고, 관련 통계를 제시한다. 본 데이터셋은 식당 예약이라는 고정된 주제 안에서 사용자의 발화 의도와 슬롯 채우기를 해야 하는 데이터셋이다. 본 데이터셋은 6857개의 한국어 문장으로 이루어져 있으며, 표기된 단어 슬롯 의 종류는 총 7개이다. 본 데이터셋에서 표기된 발화의 종류는 총 5개이며, 문장의 발화 내용에 따라 최대 2개까지 동시에 기입되어 있다. 영어권에서 연구된 모델을 본 데이터셋에 적용시켜 본 결과, 발화 의도 추측 정확도는 조금 하락 하였고, 슬롯 채우기 F1 점수는 크게 차이나는 모습을 보였다. Spoken language understanding, which aims to understand utterance as naturally as human would, are mostly focused on English language. In this paper, we construct a Korean language dataset for spoken language understanding, which is based on a conversational corpus between reservation system and its user. The domain of conversation is limited to restaurant reservation. There are 7 types of slot tags and 5 types of intent tags in 6857 sentences. When a model proposed in English-based research is trained with our dataset, intent classification accuracy decreased a little, while slot filling F1 score decreased significantly."
81,BERT를 이용한 한국어 특허상담 기계독해,"민재옥,박진우,조유정,이봉건,Min, Jae-Ok,Park, Jin-Woo,Jo, Yu-Jeong,Lee, Bong-Gun",한국정보처리학회,2020,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=a927ee59c4ad89ce6aae8a972f9116fb&keyword=자연어 처리,"기계독해는(Machine reading comprehension) 사용자 질의와 관련된 문서를 기계가 이해한 후 정답을 추론하는 인공지능 자연어처리 태스크를 말하며, 이러한 기계독해는 챗봇과 같은 자동상담 서비스에 활용될 수 있다. 최근 자연어처리 분야에서 가장 높은 성능을 보이고 있는 BERT 언어모델은 대용량의 데이터를 pre-training 한 후에 각 자연어처리 태스크에 대해 fine-tuning하여 학습된 모델로 추론함으로써 문제를 해결하는 방식이다. 본 논문에서는 BERT기반 특허상담 기계독해 태스크를 위해 특허상담 데이터 셋을 구축하고 그 구축 방법을 소개하며, patent 코퍼스를 pre-training한 Patent-BERT 모델과 특허상담 모델학습에 적합한 언어처리 알고리즘을 추가함으로써 특허상담 기계독해 태스크의 성능을 향상시킬 수 있는 방안을 제안한다. 본 논문에서 제안한 방법을 사용하여 특허상담 질의에 대한 정답 결정에서 성능이 향상됨을 보였다. MRC (Machine reading comprehension) is the AI NLP task that predict the answer for user's query by understanding of the relevant document and which can be used in automated consult services such as chatbots. Recently, the BERT (Pre-training of Deep Bidirectional Transformers for Language Understanding) model, which shows high performance in various fields of natural language processing, have two phases. First phase is Pre-training the big data of each domain. And second phase is fine-tuning the model for solving each NLP tasks as a prediction. In this paper, we have made the Patent MRC dataset and shown that how to build the patent consultation training data for MRC task. And we propose the method to improve the performance of the MRC task using the Pre-trained Patent-BERT model by the patent consultation corpus and the language processing algorithm suitable for the machine learning of the patent counseling data. As a result of experiment, we show that the performance of the method proposed in this paper is improved to answer the patent counseling query."
82,BERT-Fused Transformer 모델에 기반한한국어 형태소 분석 기법,"이창재,나동열",한국정보처리학회,2022,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=fe79133edac88288b7998d826d417196&keyword=자연어 처리,"Morphemes are most primitive units in a language that lose their original meaning when segmented into smaller parts. In Korean,a sentence is a sequence of eojeols (words) separated by spaces. Each eojeol comprises one or more morphemes. Korean morphologicalanalysis (KMA) is to divide eojeols in a given Korean sentence into morpheme units. It also includes assigning appropriatepart-of-speech(POS) tags to the resulting morphemes. KMA is one of the most important tasks in Korean natural language processing(NLP). Improving the performance of KMA is closely related to increasing performance of Korean NLP tasks. Recent research on KMAhas begun to adopt the approach of machine translation (MT) models. MT is to convert a sequence (sentence) of units of one domaininto a sequence (sentence) of units of another domain. Neural machine translation (NMT) stands for the approaches of MT that exploitneural network models. From a perspective of MT, KMA is to transform an input sequence of units belonging to the eojeol domain intoa sequence of units in the morpheme domain. In this paper, we propose a deep learning model for KMA. The backbone of our modelis based on the BERT-fused model which was shown to achieve high performance on NMT. The BERT-fused model utilizes Transformer,a representative model employed by NMT, and BERT which is a language representation model that has enabled a significant advancein NLP. The experimental results show that our model achieves 98.24 F1-Score. 형태소는 더 이상 분리하면 본래의 의미를 잃어버리는 말의 최소 단위이다. 한국어에서 문장은 공백으로 구분되는 어절(단어)의 조합이다. 형태소분석은 어절 단위의 문장을 입력 받아서 문맥 정보를 활용하여 형태소 단위로 나누고 각 형태소에 적절한 품사 기호를 부착한 결과를 생성하는것이다. 한국어 자연어 처리에서 형태소 분석은 가장 핵심적인 태스크다. 형태소 분석의 성능 향상은 한국어 자연어 처리 태스크의 성능 향상에직결된다. 최근 형태소 분석은 주로 기계 번역 관점에서 연구가 진행되고 있다. 기계 번역은 신경망 모델 등으로 어느 한 도메인의 시퀀스(문장)를다른 도메인의 시퀀스(문장)로 바꾸는 것이다. 형태소 분석을 기계 번역 관점에서 보면 어절 도메인에 속하는 입력 시퀀스를 형태소 도메인 시퀀스로변환하는 것이다. 본 논문은 한국어 형태소 분석을 위한 딥러닝 모델을 제안한다. 본 연구에서 사용하는 모델은 기계 번역에서 높은 성능을 기록한BERT-fused 모델을 기반으로 한다. BERT-fused 모델은 기계 번역에서 대표적인 Transformer 모델과 자연어 처리 분야에 획기적인 성능 향상을이룬 언어모델인 BERT를 활용한다. 실험 결과 형태소 단위 F1-Score 98.24의 성능을 얻을 수 있었다."
83,한국어 뉴스 분석 성능 향상을 위한 번역 전처리 기법,"이지민(Ji-Min Lee),정다운(Da-Woon Jeong),구영현(Yeong-Hyeon Gu),유성준(Seong-Joon Yoo)",한국방송·미디어공학회,2020,한국방송공학회 학술발표대회 논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=ca837e8ce9be9f186aae8a972f9116fb&keyword=자연어 처리,"한국어는 교착어로 1개 이상의 형태소가 단어를 이루고 있기 때문에 텍스트 분석 시 형태소를 분리하는 작업이 필요하다. 자연어를 처리하는 대부분의 알고리즘은 영미권에서 만들어졌고 영어는 굴절어로 특정 경우를 제외하고 일반적으로 하나의 형태소가 단어를 구성하는 구조이다. 그리고 영문은 주로 띄어쓰기 위주로 토큰화가 진행되기 때문에 텍스트 분석이 한국어에 비해 복잡함이 떨어지는 편이다. 이러한 이유들로 인해 한국어 텍스트 분석은 영문텍스트 분석에 비해 한계점이 있다고 알려져 있다. 한국어 텍스트 분석의 성능 향상을 위해 본 논문에서는 번역 전처리 기법을 제안한다. 번역 전처리 기법이란 원본인 한국어 텍스트를 영문으로 번역하고 전처리를 거친 뒤 분석된 결과를 재번역하는 것이다. 본 논문에서는 한국어 뉴스 기사 데이터와 번역 전처리 기법이 적용된 영문 뉴스 텍스트 데이터를 사용했다. 그리고 주제어 역할을 하는 키워드를 단어 간의 유사도를 계산하는 알고리즘인 Word2Vec(Word to Vector)을 통해 유사 단어를 추출했다. 이렇게 도출된 유사 단어를 텍스트 분석 전문가 대상으로 성능 비교 투표를 진행했을 때, 한국어 뉴스보다 번역 전처리 기법이 적용된 영문 뉴스가 약 3배의 득표 차이로 의미있는 결과를 도출했다."
84,언어 정보가 반영된 문장 점수를 활용하는삭제 기반 문장 압축,"이준범,김소언,박성배",한국정보처리학회,2022,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=672c8dba3c273b436aae8a972f9116fb&keyword=자연어 처리,"Sentence compression is a natural language processing task that generates concise sentences that preserves the important meaning ofthe original sentence. For grammatically appropriate sentence compression, early studies utilized human-defined linguistic rules.
Furthermore, while the sequence-to-sequence models perform well on various natural language processing tasks, such as machine translation,there have been studies that utilize it for sentence compression. However, for the linguistic rule-based studies, all rules have to be definedby human, and for the sequence-to-sequence model based studies require a large amount of parallel data for model training. In orderto address these challenges, Deleter, a sentence compression model that leverages a pre-trained language model BERT, is proposed. Becausethe Deleter utilizes perplexity based score computed over BERT to compress sentences, any linguistic rules and parallel dataset is not requiredfor sentence compression. However, because Deleter compresses sentences only considering perplexity, it does not compress sentencesby reflecting the linguistic information of the words in the sentences. Furthermore, since the dataset used for pre-learning BERT are farfrom compressed sentences, there is a problem that this can lad to incorrect sentence compression. In order to address these problems,this paper proposes a method to quantify the importance of linguistic information and reflect it in perplexity-based sentence scoring.
Furthermore, by fine-tuning BERT with a corpus of news articles that often contain proper nouns and often omit the unnecessary modifiers,we allow BERT to measure the perplexity appropriate for sentence compression. The evaluations on the English and Korean dataset confirmthat the sentence compression performance of sentence-scoring based models can be improved by utilizing the proposed method. 문장 압축은 원본 문장의 중요한 의미는 유지하면서 길이가 축소된 압축 문장을 생성하는 자연어처리 태스크이다. 문법적으로 적절한 문장압축을 위해, 초기 연구들은 사람이 정의한 언어 규칙을 활용하였다. 또한 시퀀스-투-시퀀스 모델이 기계 번역과 같은 다양한 자연어처리 태스크에서좋은 성능을 보이면서, 이를 문장 압축에 활용하고자 하는 연구들도 존재했다. 하지만 언어 규칙을 활용하는 연구의 경우 모든 언어 규칙을 정의하는데에 큰 비용이 들고, 시퀀스-투-시퀀스 모델 기반 연구의 경우 학습을 위해 대량의 데이터셋이 필요하다는 문제점이 존재한다. 이를 해결할 수있는 방법으로 사전 학습된 언어 모델인 BERT를 활용하는 문장 압축 모델인 Deleter가 제안되었다. Deleter는 BERT를 통해 계산된 perplexity를활용하여 문장을 압축하기 때문에 문장 압축 규칙과 모델 학습을 위한 데이터셋이 필요하지 않다는 장점이 있다. 하지만 Deleter는 perplexity만을고려하여 문장을 압축하기 때문에, 문장에 속한 단어들의 언어 정보를 반영하여 문장을 압축하지 못한다. 또한, perplexity 측정을 위한 BERT의사전 학습에 사용된 데이터가 압축 문장과 거리가 있어, 이를 통해 측정된 perplexity가 잘못된 문장 압축을 유도할 수 있다는 문제점이 있다.
이를 해결하기 위해 본 논문은 언어 정보의 중요도를 수치화하여 perplexity 기반의 문장 점수 계산에 반영하는 방법을 제안한다. 또한 고유명사가자주 포함되어 있으며, 불필요한 수식어가 생략되는 경우가 많은 뉴스 기사 말뭉치로 BERT를 fine-tuning하여 문장 압축에 적절한 perplexity를측정할 수 있도록 하였다. 영어 및 한국어 데이터에 대한 성능 평가를 위해 본 논문에서 제안하는 LI-Deleter와 비교 모델의 문장 압축 성능을비교 실험을 진행하였고, 높은 문장 압축 성능을 보임을 확인하였다."
85,Transformer기반의 언어모델 Bert와 GPT-2 성능 비교 연구,"유연준 ( Yean-jun Yoo ),홍석민 ( Seok-min Hong ),이협건 ( Hyeop-geon Lee ),김영운 ( Young-woone Kim )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=64af6542ce3411d77ecd42904f0c5d65&keyword=자연어 처리,"최근 자연어처리 분야에서는 Bert, GPT 등 Transformer기반의 언어모델 연구가 활발히 이뤄지고 있다. 이러한 언어모델은 대용량의 말뭉치 데이터와 많은 파라미터를 이용하여 사전학습을 진행하여 다양한 자연어처리 테스트에서 높은 성능을 보여주고 있다. 이에 본 논문에서는 Transformer기반의 언어모델인 Bert와 GPT-2의 성능평가를 진행한다. 성능평가는 ‘네이버 영화 리뷰’ 데이터 셋을 통해 긍정 부정의 정확도와 학습시간을 측정한다. 측정결과 정확도에서는 GPT-2가 Bert보다 최소 4.16%에서 최대 5.32% 높은 정확도를 나타내었지만 학습시간에서는 Bert가 GPT-2보다 최소 104초에서 116초 빠르게 나타났다. 향후 성능 비교는 더 많은 데이터와 다양한 조건을 통해 구체적인 성능 비교가 필요하다."
86,딥러닝을 이용한 법률 분야 한국어 의미 유사판단에 관한 연구,"김성원,박광렬",한국정보처리학회,2022,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=06567b71074ad439b36097776a77e665&keyword=자연어 처리,"Keyword-oriented search methods are mainly used as data search methods, but this is not suitable as a search method in the legalfield where professional terms are widely used. In response, this paper proposes an effective data search method in the legal field. Wedescribe embedding methods optimized for determining similarities between sentences in the field of natural language processing of legaldomains. After embedding legal sentences based on keywords using TF-IDF or semantic embedding using Universal Sentence Encoder,we propose an optimal way to search for data by combining BERT models to check similarities between sentences in the legal field. 기존의 데이터 검색 방법으로는 키워드 중심의 검색 방법이 주로 사용되나, 이는 전문적인 용어가 많이 쓰이는 법률 분야의 검색 방법으로는적합하지 않다. 이에 대해 본 논문에서는 법률 분야의 효과적인 데이터 검색 방안을 제안한다. 법률 도메인의 자연어처리 분야에서 문장 간의유사성을 판단하는 데 최적화된 임베딩 방법에 관하여 서술한다. 법률문장을 TF-IDF를 이용하여 키워드 기반으로 임베딩하거나 Universal SentenceEncoder를 이용하여 의미 기반으로 임베딩을 한 후, BERT모델을 결합하여 법률 분야에서 문장 간 유사성을 검사하여 데이터를 검색하는 최적의방안을 제안한다."
87,토픽 기반의 지식그래프를 이용한 BERT 모델,"민찬욱 ( Chan-wook Min ),안진현 ( Jin-hyun Ahn ),임동혁 ( Dong-hyuk Im )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=c40a0e5db96c3eebd18150b21a227875&keyword=자연어 처리,"최근 딥러닝의 기술발전으로 자연어 처리 분야에서 Q&A, 문장추천, 개체명 인식 등 다양한 연구가 진행 되고 있다. 딥러닝 기반 자연어 처리에서 좋은 성능을 보이는 트랜스포머 기반 BERT 모델의 성능향상에 대한 다양한 연구도 함께 진행되고 있다. 본 논문에서는 토픽모델인 잠재 디리클레 할당을 이용한 토픽별 지식그래프 분류와 입력문장의 토픽을 추론하는 방법으로 K-BERT 모델을 학습한다. 분류된 토픽 지식그래프와 추론된 토픽을 이용해 K-BERT 모델에서 대용량 지식그래프 사용의 효율적 방법을 제안한다."
88,CNN 기반 감성 변화 패턴을 이용한 가짜뉴스 탐지,"이태원,박지수,손진곤",한국정보처리학회,2023,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=f91402dd01a05e34d18150b21a227875&keyword=자연어 처리,"Recently, fake news disguises the form of news content and appears whenever important events occur, causing social confusion.
Accordingly, artificial intelligence technology is used as a research to detect fake news. Fake news detection approaches such asautomatically recognizing and blocking fake news through natural language processing or detecting social media influencer accounts thatspread false information by combining with network causal inference could be implemented through deep learning. However, fake newsdetection is classified as a difficult problem to solve among many natural language processing fields. Due to the variety of forms andexpressions of fake news, the difficulty of feature extraction is high, and there are various limitations, such as that one feature mayhave different meanings depending on the category to which the news belongs. In this paper, emotional change patterns are presentedas an additional identification criterion for detecting fake news. We propose a model with improved performance by applying aconvolutional neural network to a fake news data set to perform analysis based on content characteristics and additionally analyze emotionalchange patterns. Sentimental polarity is calculated for the sentences constituting the news and the result value dependent on the sentenceorder can be obtained by applying long-term and short-term memory. This is defined as a pattern of emotional change and combinedwith the content characteristics of news to be used as an independent variable in the proposed model for fake news detection. We trainthe proposed model and comparison model by deep learning and conduct an experiment using a fake news data set to confirm thatemotion change patterns can improve fake news detection performance. 최근 가짜뉴스는 뉴스 콘텐츠 형식을 가장하고 중요한 사건이 발생할 때마다 등장하여 사회적 혼란을 초래한다. 이에 가짜뉴스를 탐지하기위한 연구로 인공지능 기술이 사용된다. 자연어 처리를 통해 가짜뉴스를 자동으로 인지 및 차단하거나, 네트워크 인과 추론과 결합함으로써 허위정보를 확산시키는 소셜미디어 인플루언스 계정을 감지하는 등의 가짜뉴스 탐지 접근법이 딥러닝을 통해 구현될 수 있었다. 그러나 가짜뉴스 탐지는여러 자연어 처리 분야 중에서도 해결이 어려운 문제로 분류된다. 가짜뉴스가 가지는 형식 및 표현의 다양성으로 특성 추출의 난도가 높고, 뉴스가속한 범주에 따라 하나의 특성이 서로 다른 의미를 가질 수도 있는 등 다양한 한계점이 존재한다. 본 논문에서는 가짜뉴스를 탐지하기 위한 추가적인식별 기준으로 감성 변화 패턴을 제시한다. 합성곱 신경망을 가짜뉴스 데이터 세트에 적용하여 콘텐츠 특성에 기반한 분석을 수행하고, 감성 변화패턴을 추가로 분석함으로써 성능이 개선된 모델을 제안한다. 뉴스를 구성하는 문장에 대하여 감성 극성을 산출하고 장단기 메모리를 적용함으로써문장 순서에 의존적인 결괏값을 얻을 수 있다. 이를 감성 변화의 패턴으로 정의하고 뉴스의 콘텐츠 특성과 결합하여 가짜뉴스 탐지를 위한 제안모델의 독립변수로 활용한다. 제안 모델과 비교 모델을 딥러닝으로 학습시키고 가짜뉴스 데이터 세트를 이용한 실험을 진행하여 감성 변화 패턴이가짜뉴스 탐지 성능을 개선할 수 있음을 확인한다."
89,감성 분류를 위한 워드 임베딩 성능 비교,"윤혜진 ( Hye-jin Yoon ),구자환 ( Jahwan Koo ),김응모 ( Ung-mo Kim )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=eea6b517e55d5b066aae8a972f9116fb&keyword=자연어 처리,"텍스트를 자연어 처리를 위한 모델에 적용할 수 있게 언어적인 특성을 반영해서 단어를 수치화하는 방법 중 단어를 벡터로 표현하여 나타내는 워드 임베딩은 컴퓨터가 인간의 언어를 이해하고 분석 가능한 언어 모델의 필수 요소가 되었다. Word2vec 등 다양한 워드 임베딩 기법이 제안되었고 자연어를 처리할 때에 감성 분류는 중요한 요소이지만 다양한 임베딩 기법에 따른 감성 분류 모델에 대한 성능 비교 연구는 여전히 부족한 실정이다. 본 논문에서는 Emotion-stimulus 데이터를 활용하여 7가지의 감성과 2가지의 감성을 5가지의 임베딩 기법과 3종류의 분류 모델로 감성 분류 학습을 진행하였다. 감성 분류를 위해 Logistic Regression, Decision Tree, Random Forest 모델 등과 같은 보편적으로 많이 사용하는 머신러닝 분류 모델을 사용하였으며, 각각의 결과를 훈련 정확도와 테스트 정확도로 비교하였다. 실험 결과, 7가지 감성 분류 및 2가지 감성 분류 모두 사전훈련된 Word2vec가 대체적으로 우수한 정확도 성능을 보였다."
90,지능형 문서처리 도입과 기록관리 변화에 관한 연구,"류한조,이경남,황진현,임진희,Ryu, Hanjo,Lee, Kyungnam,Hwang, Jinhyun,Yim, Jinhee",한국기록학회,2021,기록학연구,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=c1edd27559cb9b294884a65323211ff0&keyword=자연어 처리,"빅데이터 분석을 위해서는 기계가독성을 높이는 개방형 문서 포맷으로의 변화와 자연어 처리 기술 도구가 필요하다. 본 연구는 지능형 문서 처리의 도입 배경과 연구 현황을 공공부문 중심으로 살펴보고, 지능형 문서 처리가 가져올 업무의 변화를 예측해 보았다. 나아가 지능형 문서 처리가 기록관리 업무에 가져올 변화를 전망해보고, 기록관리 전문가의 역할의 변화와 요구되는 역량 등을 고찰해 보았다. 기록관 업무 단계와 아카이브 업무 단계의 광범위한 영역에 걸쳐 기록관리 업무의 변화를 전망하였고, 특히 반복적인 기록관리 업무의 자동화나 기록물의 기술 및 활용 업무에 영향을 미칠만한 변화들을 서술하였다. 이러한 업무 수행의 변화에 맞추어 기록관리계는 새로운 업무 절차와 방법, 그리고 필요한 역량을 준비해야 할 것이다. In order to analyze big data, documents should be converted to a open standard format to increase machine readability. It also need natural language processing tools. This study focused on the background of intelligent document processing and the status of research in the public sector, and predicted the changes in work that intelligent document processing would bring. This study noted the changes that intelligent document processing would bring to the archival work, and also considered changes in the role of archivist and their required competencies. Changes in archival work could be anticipated across a wide range of Records Management work and Archives Management work. In particular, it was expected to have a significant impact on the automation of repetitive archival tasks or the description and utilization of records. This study proposed the need to prepare new archival work procedures, methods, and necessary competencies in response to these change in archival work."
91,목적지향 대화시스템에서 LSTM 언어모델 기반의 한국어 자연어 생성,"허윤석,강상우,서정연",한국차세대컴퓨팅학회,2020,한국차세대컴퓨팅학회 논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=2ec8ca0f580cf0336aae8a972f9116fb&keyword=자연어 처리,"Natural language generation in the dialogue system is a task that transforms the semantic frame of the system utterance determined in the dialogue management phase into a natural language that can be understood by humans. Existing studies have still faced some obstacles in that only very limited types of utterances or grammatically incomplete ones are generated from the semantic frames. In order to address these issues simultaneously, we propose a Korean natural language generation model using a long short term memory based language model. In particular, we exploit the beam search decoding method to obtain system utterances with diverse structures and grammatical correctness. The experiments were conducted individually with respect to the word, morpheme, and syllable units, and the generated utterances were evaluated in both quantitative and qualitative ways. As a result, the morpheme-based model with the beam search decoding has achieved the most robust result of all. In fact, in the quantitative evaluation result of the generated sentence, the BLEU-4 score was 0.86 and the SER was 0.03, and the qualitative evaluation was also confirmed to be grammatically correct and contextually natural. 대화시스템에서 자연어 생성은 대화관리 단계에서 결정한 시스템 발화의 의미표현을 사람이 이해할 수 있는 자연어로 생성하는 것이다. 기존의 자연어 생성 연구는 의미표현에 대하여 매우 제한된 종류의 발화만을 생성하거나 문법적으로 불완전한 발화를 생성한다는 문제점이 있다. 그래서 본 논문에서는 문제점들을 동시에 처리하기 위하여 Long Short Term Memory 기반의 언어모델을 이용한 한국어 자연어 생성 모델을 제안한다. 특히 우리는 시스템 발화의 다양성과 문법적 정확성을 높이기 위하여 빔서치 디코딩을 적용한다. 실험은 어절, 형태소, 음절단위에 따라 개별적으로 진행하였으며, 생성한 문장들은 정량적, 정성적 평가를 모두 진행하였다. 그 결과 형태소 단위로 학습한 제안모델에 빔서치 디코딩을 적용한 방법은 가장 좋은 성능을 보였다. 실제로 해당 생성 문장은 정량평가 결과에서 BLEU 지표는 0.86, Slot Error Rate 지표는 0.03을 기록하였으며 정성평가 역시 문법적으로 정확하고 문맥적으로 충분히 자연스러운 결과임을 확인하였다."
92,워드 임베딩의 유사도 클러스터링을 통한 다중 문장 요약 생성 기법,"이필원 ( Pil-won Lee ),송진수 ( Jin-su Song ),신용태 ( Yong-tae Shin )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=504b2c472ab41d41c85d2949c297615a&keyword=자연어 처리,최근 인코더-디코더 구조의 자연어 처리모델이 활발하게 연구가 이루어지고 있다. 인코더-디코더기반의 언어모델은 특히 본문의 내용을 새로운 문장으로 요약하는 추상(Abstractive) 요약 분야에서 널리 사용된다. 그러나 기존의 언어모델은 단일 문서 및 문장을 전제로 설계되었기 때문에 기존의 언어모델에 다중 문장을 요약을 적용하기 어렵고 주제가 다양한 여러 문장을 요약하면 요약의 성능이 떨어지는 문제가 있다. 따라서 본 논문에서는 다중 문장으로 대표적이고 상품 리뷰를 워드 임베딩의 유사도를 기준으로 클러스터를 구성하여 관련성이 높은 문장 별로 인공 신경망 기반 언어모델을 통해 요약을 수행한다. 제안하는 모델의 성능을 평가하기 위해 전체 문장과 요약 문장의 유사도를 측정하여 요약문이 원문의 정보를 얼마나 포함하는지 실험한다. 실험 결과 기존의 RNN 기반의 요약 모델보다 뛰어난 성능의 요약을 수행했다.
93,BERT 언어 모델을 이용한 감정 분석 시스템,"김택현 ( Taek-hyun Kim ),조단비 ( Dan-bi Cho ),이현영 ( Hyun-young Lee ),원혜진 ( Hye-jin Won ),강승식 ( Seung-shik Kang )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=a2d12e96f5ae2b47b7998d826d417196&keyword=자연어 처리,"감정 분석은 문서의 주관적인 감정, 의견, 기분을 파악하기 위한 방법으로 소셜 미디어, 온라인 리뷰 등 다양한 분야에서 활용된다. 문서 내 텍스트가 나타내는 단어와 문맥을 기반으로 감정 수치를 계산하여 긍정 또는 부정 감정을 결정 한다. 2015년에 구축된 네이버 영화평 데이터 20 만개에 12 만개를 추가 구축하여 감정 분석 연구를 진행하였으며 언어 모델로는 최근 자연어처리 분야에서 높은 성능을 보여주는 BERT 모델을 이용하였다. 감정 분석 기법으로는 LSTM(Long Short-Term Memory) 등 기존의 기계학습 기법과 구글의 다국어 BERT 모델, 그리고 KoBERT 모델을 이용하여 감정 분석의 성능을 비교하였으며, KoBERT 모델이 89.90%로 가장 높은 성능을 보여주었다."
94,챗봇 데이터에 나타난 우울 담론의 범주와 특성의 이해,"진효진,정찬이,백금희,차지영,최정회,차미영",한국정보처리학회,2022,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=e7b9c5bd44bf23f747de9c1710b0298d&keyword=자연어 처리,"Influenced by a culture that prefers non-face-to-face activity during the COVID-19 pandemic, chatbot usage is accelerating. Chatbotshave been used for various purposes, not only for customer service in businesses and social conversations for fun but also for mentalhealth. Chatbots are a platform where users can easily talk about their depressed moods because anonymity is guaranteed. However,most relevant research has been on social media data, especially Twitter data, and few studies have analyzed the commercially usedchatbots data. In this study, we identified the characteristics of depressive discourse in user-chatbot interaction data by analyzing thechats, including the word ‘depress,’ using the topic modeling algorithm and the text-mining technique. Moreover, we compared itscharacteristics with those of the depressive moods in the Twitter data. Finally, we draw several design guidelines and suggest avenuesfor future research based on the study findings. 자연어처리 기술과 비대면 문화의 확산과 더불어 챗봇의 사용 증가세가 가파르며, 챗봇의 용도 또한 일상 대화와 소비자 응대를 넘어서 정신건강을 위한 용도로 확장하고 있다. 챗봇은 익명성이 보장된다는 점에서 사용자들이 우울감에 관해 이야기하기 적합한 서비스이다. 그러나 사용자가작성한 문장들을 분석해 우울 담론의 유형과 특성을 파악하는 연구들은 주로 소셜 네트워크 데이터를 대상으로 했다는 한계점이 존재하며, 실제환경에서 사용되는 챗봇과 상호작용한 데이터를 분석한 연구는 찾아보기 힘들다. 이 연구에서는 챗봇-사람의 상호작용 데이터에서 무작위로 추출한‘우울’과 관련된 대화 데이터를 토픽 모델링 방법과 텍스트마이닝 기법으로 분석하여 채팅에서의 우울 관련 담론의 특성을 파악하였다. 또한, 챗봇에서 빈번히 나타나는 ‘우울’ 담론의 범주와 트위터 ‘우울’ 담론의 범주의 차이점을 비교하였다. 이를 통해 챗봇 데이터의 ‘우울’ 대화만의 특징을파악하고, 적절한 심리지원 정보를 제공하는 챗봇 서비스를 위한 시사점과 향후 연구 방향에 대해 논의한다."
95,현장 데이터셋과 딥러닝 기술을 이용한 대화 utterance 유사성 판별,"김주희 ( Juhee Kim ),이은서 ( Eunseo Lee ),남지희 ( Jeehee Nam ),고나경 ( Nakyeong Koh ),배상환 ( Sanghwan Bae ),심준호 ( Junho Shim )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=1e69387ef128ad0947de9c1710b0298d&keyword=자연어 처리,"객체 유사도를 판별하는 기술은 정보 처리의 여러 분야에서 응용되고 있다. 본 연구에서는 현장 자연어 텍스트 데이터셋과 딥러닝 모델을 이용하여 챗봇 등에서 응용되는 데이터 유사성을 판별하고, 해당 모델의 성능을 측정해보았다."
96,CNN Architecture Predicting Movie Rating from Audience’s Reviews Written in Korean,"김형찬,오흥선,김덕수",한국정보처리학회,2020,정보처리학회논문지. 컴퓨터 및 통신시스템,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=2d85f50e321fe556b36097776a77e665&keyword=자연어 처리,"In this paper, we present a movie rating prediction architecture based on a convolutional neural network (CNN). Our prediction architecture extends TextCNN, a popular CNN-based architecture for sentence classification, in three aspects. First, character embeddings are utilized to cover many variants of words since reviews are short and not well-written linguistically. Second, the attention mechanism (i.e., squeeze-and-excitation) is adopted to focus on important features. Third, a scoring function is proposed to convert the output of an activation function to a review score in a certain range (1-10). We evaluated our prediction architecture on a movie review dataset and achieved a low MSE (e.g., 3.3841) compared with an existing method. It showed the superiority of our movie rating prediction architecture."
97,웹 뉴스 빅데이터를 이용한 태풍 상황정보의 인터렉티브 지도 기반 시공간 시각화 방안,"이지애 ( Jiae Lee ),김준철 ( Junchul Kim )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=058b1f181a241708d18150b21a227875&keyword=자연어 처리,"웹 뉴스 기사는 태풍과 같은 재해 발생상황에 대한 신속하고 정확한 정보를 포함하고 있다. 예를 들어, 태풍의 발생시점, 이동·예측경로, 피해·사고 현황 등 유용한 정보를 텍스트, 이미지, 동영상의 형태로 관련 상황정보를 전달한다. 그러나 대부분의 재해재난 관련 뉴스 기사는 특정 시점의 정보만을 웹페이지 형태로 제공하므로, 시계열 측면의 연결성을 지니는 기사들에 대한 정보를 전달하기 어렵다. 또한 시간적 변화에 따라 기사 내용에 포함된 장소, 지역, 건물 등의 지명에 대한 공간적 정보를 지도와 연계하여 정보를 전달하는데 한계가 있어, 시공간적 변화에 따른 특정 재해재난 상황정보에 대한 전체적인 현황파악이 어렵다. 따라서, 본 논문에서는 데이터 시각화 측면에서 이러한 한계를 극복하기 위해, 1) 웹크롤링을 통해 구축된 뉴스 빅데이터를 자연어 처리를 통해 태풍과 관련된 뉴스 기사들을 추출하였고, 2) 시공간적 관련 정보를 지식그래프로 구축하였고, 이를 통해 최근 발생한 태풍 사건들과 관련된 뉴스 정보를 시계열 특성을 고려하여 3) 인터렉티브 지도 기반의 태풍 상황정보를 시각화하는 방안을 연구하였다."
98,OpenPose를 활용한 음성인식기반 드론제어 촬영시스템,"조유진 ( Yu-jin Cho ),김세현 ( Se-hyun Kim ),권예림 ( Ye-rim Kwon ),정순호 ( Soon-ho Jung )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=75bc1206c5145a007f7a54760bb41745&keyword=자연어 처리,"최근 드론과 1인 미디어 시장의 성장으로, 영상 촬영 분야에서의 드론 산업이 활발하게 발전되고 있다. 본 논문에서는 딥러닝 기반 다중 객체 인식 기술인 Openpose를 활용하여 인물촬영을 위한 음성 인식 드론 제어 시스템을 제안한다. 해당 시스템은 자연어 처리된 음성명령어를 통해 드론이 각 촬영 객체에 대한 회전, 초점변화 등 실제 영상촬영기법에 사용되는 다수의 동작을 수행할 수 있도록 한다. 최종적으로 96.2%의 정확도로 음성명령에 따라 동작을 수행하는 것을 확인할 수 있다. 이는 누구나 전문적 지식이나 경험 없이 음성만으로 쉽게 드론을 제어할 수 있을 것으로 기대된다."
99,EEG Report의 의무기록 유형 분류를 위한 딥러닝 기반 모델,"오경수,강민,강석환,이영호",한국정보처리학회,2022,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=e6eb4a34483236cde9810257f7042666&keyword=자연어 처리,"As more and more research and companies use health care data, efforts are being made to vitalize health care data worldwide. However,the system and format used by each institution is different. Therefore, this research established a basic model to classify text data ontomultiple institutions according to the type of the future by establishing a basic model to classify the types of medical records of theEEG Report. For EEG Report classification, four deep learning-based algorithms were compared. As a result of the experiment, the ANNmodel trained by vectorizing with One-Hot Encoding showed the highest performance with an accuracy of 71%. 보건의료 데이터를 사용하는 연구 및 기업이 늘어나며 세계적으로 보건의료 데이터 활성화를 위한 노력을 진행 중이다. 하지만 기관에 따라사용하는 시스템과 서식이 다르다. 이에 본 연구는 EEG Report의 의무기록 유형을 분류하는 기저 모델 구축을 통해 향후 다기관의 텍스트 데이터를유형에 따라 분류하는 기저 모델을 구축하였다. EEG Report 분류를 위해 4가지의 딥러닝 기반 알고리즘에 대해 비교하였다. 실험 결과 One-HotEncoding으로 벡터화하여 학습한 ANN 모델이 71%의 정확도로 가장 높은 성능을 보였다."
100,FMEA 와 FTA 를 활용한 챗봇 시스템의 사용성 개선 프로세스,"이연재 ( Yeonjae Lee ),송재우 ( Jaewoo Song ),한혁수 ( Hyuksoo Han )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=e9b52cb4c06aed8bc85d2949c297615a&keyword=자연어 처리,"챗봇(Chatbot)은 자연어처리기술 등 인공지능 기술을 기반으로 한 사용자 친화적인 대화 방식 인터페이스를 제공하는 장점이 있어, 금융, 상담, 주문 등 다양한 산업 분야에서 적용되고 있다. 그러나, 챗봇의 응답이 사용자의 정신 모형과 불일치하는 경우, 다음 대화를 이어가는데 어려움을 야기하게 된다. 그러므로, 챗봇의 사용성을 확보하기 위해서는 응답 오류의 제거 또는 완화가 필수적이다. 기존의 챗봇의 사용성 개선과 관련된 연구들은 설문조사와 인터뷰 등 사용성 평가를 통해 상위 수준의 개선 방향만을 제안하고 있다. 따라서, 챗봇 개발 시, 실무자들이 응답 오류의 문제점을 분석하고, 이를 해결하기 위한 구체적인 개선 방안을 제시하는 데 한계가 있었다.
본 논문에서는 FMEA(Failure Modes and Effects Analysis) 기법을 활용해, 응답 오류의 치명도를 파악하고, 치명적인 오류들에 대해서는 FTA(Fault Tree Analysis) 기법을 기반으로 원인 분석을 실시하여 구체적으로 문제를 해결하기 위한 프로세스를 제안한다. 본 프로세스의 효용성을 검증하기 위해 주문 도메인의 챗봇에 적용해 보았다."
101,언어모델 기반 오픈 도메인 챗봇 구현,"김승태 ( Seung-tae Kim ),구자환 ( Jahwan Koo ),김응모 ( Ung-mo Kim )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=c28e34aac1323545d18150b21a227875&keyword=자연어 처리,"자연어 처리는 인공지능의 핵심기술 중 하나이다. 그 중 오픈 도메인 챗봇 구현은 NLP 에서 어려운 태스크로 꼽힌다. 명확한 목표, FAQ 가 존재하는 기능형 챗봇과 달리 오픈 도메인 챗봇은 연속적 대화, 방대한 양의 상식 등 구현에 어려움이 많았다. 짧은 질문과 대답으로 이루어진 데이터로 학습한 모델을 대화 데이터로 학습시켜 좀더 자연스러운 챗봇을 구현해보고자 한다."
102,소수 클래스 데이터 증강을 통한 BERT기반의 유형 분류 모델 성능 개선,"김정우 ( Jeong-woo Kim ),장광호 ( Kwangho Jang ),이용태 ( Yong Tae Lee ),박원주 ( Won-joo Park )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=234f26811b3d75e0d18150b21a227875&keyword=자연어 처리,자연어처리 분야에서 딥러닝 기반의 분류 모델은 획기적인 성능을 보여주고 있다. 특히 2018 년 발표된 구글의 BERT 는 다양한 태스크에서 높은 성능을 보여준다. 본 논문에서는 이러한 BERT 가 클래스 불균형이 심한 데이터에 대해 어느 정도 성능을 보여주는지 확인하고 이를 해결하는 방법으로 EDA 를 선택해 성능을 개선하고자 한다. BERT 에 알맞게 적용하기 위해 다양한 방법으로 EDA를 구현했고 이에 대한 성능을 평가하였다.
103,BERT를 활용한 반려동물 사료제품의 감성분석 모델 개발,"김영웅 ( Young Woong Kim ),강다은 ( Da Eun Kang ),이동규 ( Dong Kyu Lee ),김건호 ( Geonho Kim ),윤지성 ( Ji Seong Yoon ),김건우 ( Geon Woo Kim ),길준민 ( Joon-min Gil )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=998e0da66e95490ad18150b21a227875&keyword=자연어 처리,"본 논문에서는 맞춤형 반려동물 사료제품 추천을 위해 최근의 자연어처리 모델인 KoBERT 모델에 기반하여 반료동물 사료제품에 대한 감성분석 모델을 설계하고 구현한다. 본 논문을 통해 구현된 반려동물 사료제품의 감성분석 모델은 정확도 평가에 대해서 비교적 우수한 성능을 보였으며, 학습과정에 참여하지 않은 새로운 반려동물 사료제품에 대해서 0.93 이상의 정확도를 산출하였다."
104,"DNA (Data, Network, AI) 기반 지능형 정보 기술","윤주상,한연희,Youn, Joosang,Han, Youn-Hee",한국정보처리학회,2020,정보처리학회논문지. 컴퓨터 및 통신시스템,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=e5c78741b4d497d2e9810257f7042666&keyword=자연어 처리,"4차 산업혁명 시대에 다양한 분야에서 ICT 기술 간 융합에 대한 요구가 증가하고 있다. 이에 마쳐 데이터, 네트워크, 인공지능 기술이 결합한 새로운 용어인 DNA(Data, Network, AI)가 사용 중이다. DNA는 지능형 응용 및 서비스 개발에 있어 잠재적 기술력을 가지고 있다. 이에 본 논문에서는 DNA 기술 기반의 논리적 포그 네트워크 기반의 서비스 이미지 배치 기술, 산업용 무선 센서 네트워크에서의 기계학습 기반 이동성 기술, 뇌신호 주파수 특성을 이용한 CNN 기반 BCI 성능 예측 기술, 소스코드 주제를 이용한 인공신경망 기반 경고 분류 방법 기술, 챗봇 환경에서 데이터 시각화 인터랙션을 위한 자연어처리 기술에 대한 심사 완료된 논문들을 소개한다. In the era of the 4th industrial revolution, the demand for convergence between ICT technologies is increasing in various fields. Accordingly, a new term that combines data, network, and artificial intelligence technology, DNA (Data, Network, AI) is in use. and has recently become a hot topic. DNA has various potential technology to be able to develop intelligent application in the real world. Therefore, this paper introduces the reviewed papers on the service image placement mechanism based on the logical fog network, the mobility support scheme based on machine learning for Industrial wireless sensor network, the prediction of the following BCI performance by means of spectral EEG characteristics, the warning classification method based on artificial neural network using topics of source code and natural language processing model for data visualization interaction with chatbot, related on DNA technology."
105,자연어 추론에서의 교차 검증 앙상블 기법,"양기수(Kisu Yang),황태선(Taesun Whang),오동석(Dongsuk Oh),박찬준(Chanjun Park),임희석(Heuiseok Lim)",한국정보과학회,2021,정보과학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=7598d71f6524fdb2d18150b21a227875&keyword=자연어 처리,"앙상블 기법은 여러 모델을 종합하여 최종 판단을 산출하는 기계 학습 기법으로서 딥러닝 모델의 성능 향상을 보장한다. 하지만 대부분의 기법은 앙상블만을 위한 추가적인 모델 또는 별도의 연산을 요구한다. 이에 우리는 앙상블 기법을 교차 검증 방법과 결합하여 앙상블 연산을 위한 비용을 줄이며 일반화 성능을 높이는 교차 검증 앙상블 기법을 제안한다. 본 기법의 효과를 입증하기 위해 MRPC, RTE 데이터셋과 BiLSTM, CNN, ELMo, BERT 모델을 이용하여 기존 앙상블 기법보다 향상된 성능을 보인다. 추가로 교차 검증에서 비롯한 일반화 원리와 교차 검증 변수에 따른 성능 변화에 대하여 논의한다. An ensemble method is a machine learning technique that combines several models to make the final prediction, which guarantees improved performance for deep learning models. However, most techniques require additional models or operations only for an ensemble. To address this problem, we propose a cross-validated ensemble method for reducing the costs of ensemble operations with cross-validation and for improving the generalization effects with the ensemble. To demonstrate the effectiveness of the proposed method, we show the improved performances of the proposed ensemble over the previous ensemble methods using the BiLSTM, CNN, ELMo and BERT models on the MRPC and RTE datasets. We also discuss the generalization mechanism involved in cross-validation along with the performance changes caused by the hyper-parameter of cross-validation."
106,용어 신뢰도 기반 유튜브 영상 필터링 웹 서비스 설계,"한소현 ( So-hyun Hano ),신희원 ( Hee-won Shin ),황윤조 ( Yoon-jo Hwang ),김윤희 ( Yoonhee Kim )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=26693fc7ab9c3ff647de9c1710b0298d&keyword=자연어 처리,"유튜브 등의 1인 미디어 플랫폼 열풍과 반대로, 이에 대한 엄격한 방송 규약은 존재하지 않아 생기는 여러 사회적 문제가 대두되고 있다. 이러한 1인 미디어 시청자는 원하는 정보를 찾기 위해 영상 제공자가 제공하는 정보에만 의존하여 영상을 선택하고 내용을 확인하여야 한다. 그 결과 의도한 주제와 맞지 않은 영상을 시청하게 되는 비효율성을 해결하기 위해, 본 연구에서는 용어 신뢰도 기반 유튜브 영상 필터링 웹 서비스(YouChoose)를 제안한다. YouChoose는 유튜브 리뷰 영상의 음성을 자연어 처리 기법을 이용하여 사전 처리하고 신뢰도를 도출해 사용자에게 제공함으로써 검색 시 의도와 일치하는 영상을 직접 시청 전에 추천 받을 수 있도록 한다."
107,Open STT API와 머신러닝을 이용한 AI 보이스피싱 예방 솔루션,"모시은 ( Shi-eun Mo ),양혜인 ( Hye-in Yang ),조은비 ( Eun-bi Cho ),윤종호 ( Jong-ho Yoon )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=5b6b3e47cf082e564884a65323211ff0&keyword=자연어 처리,본 논문은 보이스피싱에 취약한 VoIP와 일반 유선전화 상의 보안을 위해 유선전화의 대화내용을 Google STT API 및 텍스트 자연어 처리를 통해 실시간으로 보이스피싱 위험도를 알 수 있는 모델을 제안했다. 보이스피싱 데이터를 Data Augmentation와 BERT 모델을 활용해 보이스피싱을 예방하는 솔루션을 구상했다.
108,언어 정보를 반영한 문장 점수 측정 기반의 문장 압축,"이준범 ( Jun-beom Lee ),김소언 ( So-eon Kim ),박성배 ( Seong-bae Park )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=fae295e1ab29bfbe4884a65323211ff0&keyword=자연어 처리,"문장 압축은 원본 문장의 중요한 의미를 보존하는 짧은 길이의 압축 문장을 생성하는 자연어처리 태스크이다. 문장 압축은 사용자가 텍스트로부터 필요한 정보를 빠르게 획득할 수 있도록 도울 수 있어 활발히 연구되고 있지만, 기존 연구들은 사람이 직접 정의한 압축 규칙이 필요하거나, 모델 학습을 위해 대량의 데이터셋이 필요하다는 문제점이 존재한다. 사전 학습된 언어 모델을 통한 perplexity 기반의 문장 점수 측정을 통해 문장을 압축하여 압축 규칙과 모델 학습을 위한 데이터셋이 필요하지 않은 연구 또한 존재하지만, 문장 점수 측정에 문장에 속한 단어들의 의미적 중요도를 반영하지 못하여 중요한 단어가 삭제되는 문제점이 존재한다. 본 논문은 언어 정보 중 품사 정보, 의존관계 정보, 개체명 정보의 중요도를 수치화하여 perplexity 기반의 문장 점수 측정에 반영하는 방법을 제안한다. 또한 제안한 문장 점수 측정 방법을 활용하였을 때 문장 점수 측정 기반 문장 압축 모델의 문장 압축 성능이 향상됨을 확인하였으며, 이를 통해 문장에 속한 단어의 언어 정보를 문장 점수 측정에 반영하는 것이 의미적으로 적절한 압축 문장을 생성하는 데 도움이 될 수 있음을 보였다."
109,사회문제 해결 연구보고서 기반 문장 의미 식별 데이터셋 구축,"신현호,정선기,전홍우,권이남,이재민,박강희,최성필",한국정보처리학회,2023,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=f91402dd01a05e347f7a54760bb41745&keyword=자연어 처리,"In general, social problem-solving research aims to create important social value by offering meaningful answers to various socialpending issues using scientific technologies. Not surprisingly, however, although numerous and extensive research attempts have beenmade to alleviate the social problems and issues in nation-wide, we still have many important social challenges and works to be done.
In order to facilitate the entire process of the social problem-solving research and maximize its efficacy, it is vital to clearly identifyand grasp the important and pressing problems to be focused upon. It is understandable for the problem discovery step to be drasticallyimproved if current social issues can be automatically identified from existing R&D resources such as technical reports and articles. Thispaper introduces a comprehensive dataset which is essential to build a machine learning model for automatically detecting the socialproblems and solutions in various national research reports. Initially, we collected a total of 700 research reports regarding social problemsand issues. Through intensive annotation process, we built totally 24,022 sentences each of which possesses its own category or labelclosely related to social problem-solving such as problems, purposes, solutions, effects and so on. Furthermore, we implemented foursentence classification models based on various neural language models and conducted a series of performance experiments using ourdataset. As a result of the experiment, the model fine-tuned to the KLUE-BERT pre-trained language model showed the best performancewith an accuracy of 75.853% and an F1 score of 63.503%. 일반적으로 사회문제 해결 연구는 과학기술을 활용하여 다양한 사회적 현안들에 의미있는 해결 방안을 제시함으로써 중요한 사회적 가치를창출하는 것을 연구 목표로 한다. 그러나 사회문제와 쟁점을 완화하기 위하여 많은 연구들이 국가적으로 수행되었음에도 불구하고 여전히 많은사회문제가 남아 있는 상황이다. 사회문제 해결 연구의 전 과정을 원활하게 하고 그 효과를 극대화하기 위해서는 사회적으로 시급한 현안들에대한 문제를 명확하게 파악하는 것이 중요하다. 사회문제 해결과 관련된 기존 R&D 보고서와 같은 자료에서 중요한 사안을 자동으로 식별할 수있다면 사회문제 파악 단계가 크게 개선될 수 있다. 따라서 본 논문은 다양한 국가 연구보고서에서 사회문제와 해결방안을 자동으로 감지하기위한 기계학습 모델을 구축하는 데에 필수적인 데이터셋을 제안하고자 한다. 우선 데이터를 구축하기 위해 사회문제와 쟁점을 다룬 연구보고서를총 700건 수집하였다. 수집된 연구보고서에서 사회문제, 목적, 해결 방안 등 사회문제 해결과 관련된 내용이 담긴 문장을 추출 후 라벨링을 수행하였다. 또한 4개의 사전학습 언어모델을 기반으로 분류 모델을 구현하고 구축된 데이터셋을 통해 일련의 성능 실험을 수행하였다. 실험 결과 KLUE-BERT사전학습 언어모델을 미세조정한 모델이 정확도 75.853%, F1 스코어 63.503%로 가장 높은 성능을 보였다."
110,개체단위 감정분석을 위한 글로벌 텍스트&로컬 텍스트 통합 방법,"임특 ( Te Lin ),조인휘 ( Inwhee Joe )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=19ab9002636ec7117f7a54760bb41745&keyword=자연어 처리,개체단위 감정분석(Aspect-Based Sentiment Analysis)는 자연어 처리에서 중요한 연구분야이다. 이는 입력 문장중에 존재하는 aspect term 의 감정 극성을 분석하는 것이 목적이다. 이 분야에서 현재 많이 사용되는 모델은 대부분 로컬 텍스트 또는 로컬 덱스트와 aspect term 사이의 관계에 주목하고 있다. 로켈 텍스트에 비해 글로벌 텍스트는 로컬 텍스트 뒤에 aspect term 내용을 추가해서 문장중에 있는 aspect term 내용을 더 깊게 학습할 수 있다고 생각한다. 본 논문에서는 새로운 masked attention 메커니즘을 사용하고 attention 메커니즘의 입력으로 글로벌 텍스트중에 있는 로컬 텍스트를 가로채어 전체 글로벌 텍스트의 내용과 융합한다. 이 방법은 semeval2014 데이터 셋에서 매우 좋은 결과를 얻었다.
111,한국어 법률 텍스트 처리 방안 연구 - 유사 판례 도출 태스크를 중심으로 -,"강예지,김한샘",연세대학교 언어정보연구원,2023,언어사실과 관점,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=14035dcaceb804b8d18150b21a227875&keyword=자연어 처리,"본 연구는 법률 시장에서의 유사 판결문 매칭 데이터셋의 수요가 증가함에도 불구하고 이에 대한 국내 연구가 부족함을 인식하고, 법률 문서를 사용하여 자연어 처리에 근본적으로 활용할 수 있는 한국어 법률 텍스트 특화 모델을 개발하기 위한 기초 실험을 진행하였다. 한국어 법률 텍스트 처리를 위해 세 가지 사전 학습된 모델을 미세 조정하였고 유사 판결 요지 추출 태스크를 수행하였다. 성능 평가를 위해 타겟 판결 요지와 후보 판결 요지 간의 유사도를 계산하였으며, 유사도를 바탕으로 추출된 판결 요지가 실제 법률 전문가와 일반 언어학 전공자의 직관에 부합하는지 판단하기 위해 정성적 평가를 진행하였다. 그 결과 법률 전문가가 일반 언어학 전공자에 비해 판결 요지 간 유사도를 낮게 평가하였으며 이를 통해 법률 전문가의 법률 텍스트 유사성 판단 기준이 모델과 일반 언어학 전공자와는 다르다는 것을 알 수 있었다. 최종 연구 결과로는 언어학 분야와 법률 분야의 학문적 융합이 필수적인 동시에 전문가 자문을 기반으로 한 한국어 법률 AI 모델 개발의 필요성을 확인하였다."
112,"부동산 거래에의 스마트계약 도입과 관련된 법적 문제들 - 코드와 자연어 사이의 괴리, 블록체인과 현실세계 사이의 간극 -",고유강,법조협회,2020,法曹,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=1c7646d0ce86be256aae8a972f9116fb&keyword=자연어 처리,"The Bitcoin hype that once shook the market might be over, but the underlying blockchain technology is still offering some promising future use cases. Smart contracts are one of the blockchain-related sectors that are attracting the most attention. This paper’s objective is to discuss some precautions we should take before hastily applying smart contracts into real estate transactions, as the Korean government has recently initiated a project to develop a blockchain-based transaction system dedicated to real estate transactions.
This paper aims to cover two issues. The first issue is related to the practical difficulties entangled in the actual drafting, interpretation and self-execution of smart contracts in general. The second issue deals with the problems arising when attempting to transfer titles of real world (‘off-chain’) assets through smart contracts. The overarching analysis will tackle the yet unresolved tension among contract language’s ambiguity, software code’s rigidity, and blockchain’s immutability.
While the definition of a smart contract has not reached a consensus, for the purpose of the discussion, I would like to define a smart contract as ‘a program executable according to the predefined conditions, which is written based on the parties’ agreement.’ As the prevalent literature and practice focus on smart contracts running on blockchains, this paper will discuss smart contracts on the premises that they run on distributed ledgers.
One main obstacle to adopting smart contracts is the complexity of crafting smart contract language using rigid programming languages. Due to the immutable and self-executing features of smart contracts, contracting parties are required to foresee possible permutations of their relationship prior to the deployment. Not only is this task practically impossible, but it also is in conflict with the ambiguity and flexibility of the natural language profoundly used in contractual terms. There are some ways to mitigate this rigidity through implementing ‘kill switch’ codes from the outset, or by using oracles to import external events, but they all have certain limitations. Moreover, contract law principles should also be coded into smart contracts in order to achieve compliance with the existing law, which will introduce extra challenges.
Additional legal repercussions that can be triggered when on-chain transactions are tied with title transfers of off-chain assets, such as real property. Merely producing virtual representations of off-chain assets (‘tokenization’) would not be sufficient to bridge the gap between the blockchain and the real world. As a solution, the Korean government has plans to migrate the current real estate registry to blockchain networks. This migration might bring certain advantages, such as facilitating the potential integration with smart contracts, and preventing attempts of manipulating the records with the assistance of a decentralized storage system.
Smart contracts do not appear to be ‘smart’ enough, at least for the moment. However, a bright enough future still awaits, as NLP techniques are currently showing impressive advancements, and one day they are expected to enable the embracing of contract language and contract law’s ambiguity into smart contracts. 스마트계약은 최근 주목받고 있는 블록체인의 응용영역 중 하나로, 우리나라 정부도 부동산 거래에 블록체인 기술을 도입하는 방안을 추진하고 있다. 본 글은 거래 당 규모가 크고 사람들의 실생활에 큰 영향을 미치는 부동산 거래에 스마트계약을 도입할 때에 생겨날 수 있는 몇 가지 법적 쟁점에 관한 분석을 하고자 한다.
스마트계약은 블록체인에 등록되는 순간 내용을 수정하기가 까다롭고, 실행이 시작되고 나서는 도중에 중단시키기도 어렵다. 이러한 특성들은 계약의 위ㆍ변조를 어렵게 하고 이행을 보장하는 장점이면서 동시에 스마트계약 도입에 장애물로 작용하기도 한다. 스마트계약은 경직된 프로그래밍 언어로 작성되므로 작성 당시부터 장래 발생할 수 있는 상황들을 예측하여 프로그램 내에 입력해두어야 하는데 이는 과도한 시간과 비용을 요구할 뿐만 아니라 현실적으로도 불가능에 가깝다. 스마트계약의 경직성은 계약과 실정법규에서 사용되는 추상적이고 불명확한 개념들을 온전히 수용하지 못하는 한계를 드러낸다. 이를 극복하기 위하여 스마트계약을 사후에 수정하거나 실행을 중단시킬 수 있는 코드를 미리 삽입하거나, 블록체인 외부의 정보를 호출할 수 있는 오라클 기능을 도입하는 방안들이 있지만, 자칫 스마트계약의 강점이 사라질 수 있고 기술적으로도 한계와 부작용이 존재한다.
나아가 부동산과 같이 현실세계에 존재하는 실물자산의 경우 스마트계약의 자동실행기능으로 권리변동을 어떻게 해결할 수 있을지의 문제도 해결해야 한다. 단순하게 블록체인에 실물자산의 권리변동을 기록하는 것만으로는 현실세계에 어떠한 영향을 끼칠 수 없고 민법상 형식주의를 준수해야 하는 문제가 생기기 때문이다. 현실세계와 블록체인 사이의 간극을 좁히는 방안 중 하나로, 부동산등기부를 블록체인으로 이전하고 스마트계약이 구동하는 블록체인과 연동시키는 방안을 생각할 수 있다.
적어도 현재 단계에서 스마트계약은 생각만큼 ‘스마트’하지는 않다. 그러나 자연어 처리기술이 더 발전하면 컴퓨터가 모호한 자연어 개념을 이해하고 처리할 수 있는 폭이 지금과는 차원이 다르게 넓어질 것이고, 오라클 기능의 발달로 스마트계약이 블록체인 바깥의 세계를 탐지하고 인식하는 능력도 비약적으로 향상될 것으로 전망된다."
113,한국어 언어 모델을 활용한 보이스피싱 탐지 기능 개선,"밀란두,박동주",한국정보처리학회,2022,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=70e15c25f97f85cd6aae8a972f9116fb&keyword=자연어 처리,"Text classification task from Natural Language Processing (NLP) combined with state-of-the-art (SOTA) Machine Learning (ML) andDeep Learning (DL) algorithms as the core engine is widely used to detect and classify voice phishing call transcripts. While numerousstudies on the classification of voice phishing call transcripts are being conducted and demonstrated good performances, with the increaseof non-face-to-face financial transactions, there is still the need for improvement using the latest NLP technologies. This paper conductsa benchmarking of Korean voice phishing detection performances of the pre-trained Korean language model KoBERT, against multipleother SOTA algorithms based on the classification of related transcripts from the labeled Korean voice phishing dataset called KorCCVi. The results of the experiments reveal that the classification accuracy on a test set of the KoBERT model outperforms the performancesof all other models with an accuracy score of 99.60%. 보이스피싱 통화 내용을 탐지하고 분류하는데 핵심 엔진으로 최신 머신러닝(ML) 및 딥러닝(DL) 알고리즘과 결합된 자연어 처리(NLP)의 텍스트분류 작업이 널리 사용된다. 비대면 금융거래의 증가와 더불어 보이스피싱 통화 내용 분류에 대한 많은 연구가 진행되고 양호한 성과를 보이고있지만, 최신 NLP 기술을 활용한 성능 개선의 필요성이 여전히 존재한다. 본 논문은 KorCCVi라는 레이블이 지정된 한국 보이스 피싱 데이터의텍스트 분류를 기반으로 여러 다른 최신 알고리즘과 비교하여 사전 훈련된 한국어 모델 KoBERT의 한국 보이스 피싱 탐지 성능을 벤치마킹한다. 실험 결과에 따르면 KoBERT 모델의 테스트 집합에서 분류 정확도가 99.60%로 다른 모든 모델의 성능을 능가한다."
114,Transformer 를 사용한 영한 기계 번역,"천진우 ( Jin-woo Chun ),구자환 ( Jahwan Koo ),김응모 ( Ung-mo Kim )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=c28e34aac1323545b7998d826d417196&keyword=자연어 처리,"최근 자연어 처리 기술은 지속적으로 발전하고 있으며, 많은 분야에서 활용되고 있다. 그 중 번역 기술은 가장 널리 사용되고 있는 자연어 처리 기술 중 하나이다. 본 논문에서는 기존의 seq2seq 모델의 단점을 극복하기 위해 개발된 Transformer 를 통해 영어-한국어 번역기를 만드는 것의 가능성을 제시한다."
115,AI 기반 챗봇 한국어 텍스트의 자연어 분석 및 한국어 교육 활용 모색 - 챗GPT(ChatGPT)와 뉴빙(New-Bing)을 중심으로 -,왕감경,한국문화융합학회,2023,문화와 융합,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=2c26bb4acfcff8e47f7a54760bb41745&keyword=자연어 처리,"The recent advancement of Artificial Intelligence(AI) technology has reached a new phase, thanks to the convergence of data and computing. In particular, AI-based chatbot systems are constructing interactive structures for conversation with humans by utilizing various technologies such as Natural Language Processing(NLP), Machine Learning, Deep Learning, and rule-based systems. This paper verifies the potential of the representative modern AI-based chatbots, ChatGPT and New-Bing, in the field of Korean education. To this end, responses were extracted in text form using the two models, and the preprocessing steps of Korean text were conducted to analyze the NLP process. Subsequently, text similarity was calculated using FastText, and a process was undergone to verify the reliability of similarity values between extracted high-frequency words. The ultimate goal is to describe the applications of AI-based chatbots in the field of Korean education and to provide examples of their correct and efficient use. Considering the future advancement of AI technology and various directions for its application, it is anticipated that the yet-to-be-developed Korean-specific chatbots will not only offer text conversation but also extend to voice recognition features, and thus be applicable to many aspects of Korean education. 최근 인공지능(AI) 기술의 발전은 데이터와 컴퓨팅의 집합 덕분에 새로운 단계에 이르렀다. 특히 AI 기반 챗봇 시스템은 자연어 처리, 머신러닝, 딥러닝, 규칙 기반 시스템 등 다양한 기술을 활용하여 인간과 대화하는 대화형 구조를 구축하고 있다. 본고에서는 대표적인 현대 AI 기반 챗봇인 챗GPT(ChatGPT)와 뉴빙(New-Bing)을 대상으로 한국어 교육 분야에서의 활용 가능성을 검증한다. 이를 위해 두 가지 모델을 사용하여 텍스트 형태로 답변을 추출하고, 자연어 처리 과정을 분석하기 위해 한국어 텍스트 전처리 단계를 진행하였다. 그 다음, FastText를 이용해 텍스트 간의 유사도를 계산하고 추출된 고빈도 단어 간의 유사도 값의 신뢰성을 검증하는 과정을 거쳤다. 최종 목표는 AI 기반 챗봇이 한국어 교육 분야에서의 활용 분야를 설명하고, 올바르고 효율적으로 활용할 수 있는 예시를 제시하는 것이다. 앞으로 AI 기술의 발전과 다양한 활용 방향을 고려하면, 아직 개발되지 않은 한국어 전용 챗봇은 텍스트 대화뿐만 아니라 음성 인식 기능까지 확장되어 한국어 교육의 많은 부분에 적용될 것으로 기대된다."
116,Low-Resource 환경에서 Multi-Task 학습을 이용한 카자흐어 형태소 분석,"( Nazira Kaibalina ),박성배 ( Seong-bae Park )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=5990f738b140c2b947de9c1710b0298d&keyword=자연어 처리,"지난 10년 동안 기계학습을 통해 자연어 처리 분야에서 많은 발전이 있었다. Machine translation, question answering과 같은 문제는 사용 가능한 데이터가 많은 언어에서 높은 정확도 성능 결과를 보여준다. 그러나 low-resource 언어에선 동일한 수준의 성능에 도달할 수 없다. 카자흐어는 형태학적 분석을 위해 구축된 대용량 데이터셋이 없으므로 low-resource 환경이다. 카자흐어는 단일 어근으로 수백 개의 단어 형태를 생성할 수 있는 교착어이다. 그래서 카자흐어 문장의 형태학적 분석은 카자흐어 문장의 의미를 이해하는 기본적인 단계이다. 기존에 존재하는 카자흐어 데이터셋은 구체적인 형태학적 분석의 부재로 모델이 충분한 학습이 이루어지지 못하기 때문에 본 논문에서 새로운 데이터셋을 제안한다. 본 논문은 low-resource 환경에서 높은 정확도를 달성할 수 있는 신경망 모델기반의 카자흐어 형태학 분석기를 제안한다."
117,영상 콘텐츠의 신뢰도 평가를 위한 언어와 비언어 통합 감성 분석 시스템,"신희원 ( Hee Won Shin ),이소정 ( So Jeong Lee ),손규진 ( Gyu Jin Son ),김혜린 ( Hye Rin Kim ),김윤희 ( Yoonhee Kim )",한국정보처리학회,2021,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=7552f765f9dce34f47de9c1710b0298d&keyword=자연어 처리,"IT 기술 발달에 따른 영상 콘텐츠 생산과 소비가 증가함에 따라 영상 콘텐츠를 통한 제품 리뷰 정보로 구매의사 결정이 빈번해졌다. 따라서, 리뷰 영상에 대한 신뢰성을 평가할 필요가 있다. 본 연구에서는 제품 리뷰 영상을 얼굴 표정 분석과 텍스트 마이닝을 통해 리뷰어의 표정과 음성을 분석하여 영상의 신뢰도를 분석한다. 영상 내 인물 표정의 감성 값을 추출하는 알고리즘을 활용하여 비언어 감성을 정량화하고, 유의미한 감정변화 구간을 추출한다. 유의미한 감정 변화 구간의 리뷰어 음성을 텍스트화하여 표준어 및 비표준어 감성 사전 활용을 통해 긍정과 부정으로 리뷰에 대한 언어 감성 분석 후 수치화 한다. 비언어 감성 분석과 언어 감성 분석의 결과를 통합하여 일치 여부에 따라 신뢰도를 도출한다. 본 연구를 통해 영상 콘텐츠의 신뢰성 평가 방법을 제시한다. With the advent of the “age of video” due to the simplification of video content production and the convenience of broadcasting channel operation, review videos on various products are drawing attention. We proposes RASIA, an integrated reliability analysis system based on verbal and nonverbal sentiment analysis of review videos. RASIA extracts and quantifies each emotional value obtained through language sentiment analysis and facial analysis of the reviewer in the video. Subsequently, we conduct an integrated reliability analysis of standardized verbal and nonverbal sentimental values. RASIA provide an new objective indicator to evaluate the reliability of the review video."
118,신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어,"문종혁 ( Jong Hyeok Mun ),김도형 ( Do Hyung Kim ),최종선 ( Jong Sun Choi ),최재영 ( Jae Young Choi )",한국정보처리학회,2021,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=7552f765f9dce34fb7998d826d417196&keyword=자연어 처리,"최근 딥러닝은 하드웨어 성능이 향상됨에 따라 자연어 처리, 영상 인식 등의 다양한 기술에 접목되어 활용되고 있다. 이러한 기술들을 활용해 지능형 교통 시스템(ITS), 스마트홈, 헬스케어 등의 산업분야에서 데이터를 분석하여 고속도로 속도위반 차량 검출, 에너지 사용량 제어, 응급상황 등과 같은 고품질의 서비스를 제공하며, 고품질의 서비스를 제공하기 위해서는 정확도가 향상된 딥러닝 모델이 적용되어야 한다. 이를 위해 서비스 환경의 데이터를 분석하기 위한 딥러닝 모델을 개발할 때, 개발자는 신뢰성이 검증된 최신의 딥러닝 모델을 적용할 수 있어야 한다. 이는 개발자가 참조하는 딥러닝 모델에 적용된 학습 데이터셋의 정확도를 측정하여 검증할 수 있다. 이러한 검증을 위해서 개발자는 학습 데이터셋, 딥러닝의 계층구조 및 개발 환경 등과 같은 내용을 포함하는 딥러닝 모델을 문서화하여 적용하기 위한 구조적인 정보가 필요하다. 본 논문에서는 신뢰성있는 딥러닝 기반 데이터 분석 모델을 참조하기 위한 딥러닝 기술 언어를 제안한다. 제안하는 기술 언어는 신뢰성 있는 딥러닝 모델을 개발하는데 필요한 학습데이터셋, 개발 환경 및 설정 등의 정보와 더불어 딥러닝 모델의 계층구조를 표현할 수 있다. 제안하는 딥러닝 기술 언어를 이용하여 개발자는 지능형 교통 시스템에서 참조하는 분석 모델의 정확도를 검증할 수 있다. 실험에서는 제안하는 언어의 유효성을 검증하기 위해, 번호판 인식 모델을 중심으로 딥러닝 기술 문서의 적용과정을 보인다. With the recent advancements of deep learning, companies such as smart home, healthcare, and intelligent transportation systems are utilizing its functionality to provide high-quality services for vehicle detection, emergency situation detection, and controlling energy consumption. To provide reliable services in such sensitive systems, deep learning models are required to have high accuracy. In order to develop a deep learning model for analyzing previously mentioned services, developers should utilize the state of the art deep learning models that have already been verified for higher accuracy. The developers can verify the accuracy of the referenced model by validating the model on the dataset. For this validation, the developer needs structural information to document and apply deep learning models, including metadata such as learning dataset, network architecture, and development environments. In this paper, we propose a description language that represents the network architecture of the deep learning model along with its metadata that are necessary to develop a deep learning model. Through the proposed description language, developers can easily verify the accuracy of the referenced deep learning model. Our experiments demonstrate the application scenario of a deep learning description document that focuses on the license plate recognition for the detection of illegally parked vehicles."
119,KoBERT기반 Youtube 자막 감정 분석 연구,"최다은 ( Da-eun Choi ),김효민 ( Hyo-min Kim ),이혜린 ( Hae-rin Lee ),황유림 ( Yu-rim Hwang )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=545b4efded58af2b7f7a54760bb41745&keyword=자연어 처리,"YouTube 이용자의 급증으로 많은 사람이 유튜브 알고리즘에 의해 무분별한 영상에 노출되고 있다. 이는 YouTube 이용자에게 부정적인 영향을 미칠 수 있으며 더 나아가 사회적으로 미성숙한 미디어 문화를 조장할 수 있다. 본 논문에서는 YouTube 컨텐츠에 대한 감정분석 연구를 처음으로 시도한다. 구체적으로, YouTube 컨텐츠 자막에 대해 기존의 자연어 처리 기반 감정분석 기법을 적용하여 성능을 분석한다."
120,딥러닝 기반의 로봇팔 시스템 연구,"신준호 ( Jun-ho Shin ),심규석 ( Gyu-seok Sh )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=c28e34aac13235457ecd42904f0c5d65&keyword=자연어 처리,본 시스템은 세 단계의 모델을 복합적으로 구성하여 이루어진다. 첫 단계로 사람의 음성언어를 텍스트로 전환한 후 사용자의 발화 의도를 분류해내는 BoW방식을 이용해 인간의 명령을 이해할 수 있는 자연어 처리 알고리즘을 구성한다. 이후 YOLOv3-tiny를 이용한 실시간 영상처리모델과 OctoMapping모델을 활용하여 주변환경에 대한 3차원 지도생성 후 지도데이터를 기반으로하여 동작하는 기구제어 알고리즘 등을 ROS actionlib을 이용한 관리자시스템을 구성하여 ROS와 딥러닝을 활용한 편리한 인간-로봇 상호작용 시스템을 제안한다.
121,AI 챗봇을 활용한 정부 및 지자체의 혜택·복지·소식 정보 제공 및 추천 서비스에 관한 연구,"김현도 ( Hyun-do Kim ),김선우 ( Sun-woo Kim ),연정민 ( Jung-min Yeon ),정다현 ( Da-hyeon Jeong ),정진우 ( Jin-woo Jung )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=11ea73dc5e87a4ff7f7a54760bb41745&keyword=자연어 처리,"본 연구에서는 Google Dialogflow 자연어 처리 엔진(NLP 엔진), 정보수집(크롤링), iOS 챗봇 애플리케이션을 통해 정부 및 지자체 혜택 및 정보 추천 서비스를 제공하는 챗봇 구현을 제안한다. 해당 챗봇은 디지털 기기 사용이 능숙하지 않은 중, 장년층 사용자가 쉽게 이용할 수 있도록 접근성을 높이고, 정부 및 지자체에서 제공하는 다양한 혜택 및 정보의 불균형과 격차의 해소를 목적으로, 사용자가 선택한 지역에 따른 혜택·복지·소식 정보를 제공 및 추천한다. 이 과정을 통해 사용자는 자신이 원하는 분야의 정부 및 지자체의 적절한 복지 정보를 추천 받을 수 있다."
122,음표 임베딩과 마디 임베딩을 이용한 곡의 생성 및 정량적 평가 방법,"이영배 ( Young-bae Lee ),정성훈 ( Sung Hoon Jung )",한국정보처리학회,2021,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=75ad3f29cd4bd1e97f7a54760bb41745&keyword=자연어 처리,"인공신경망을 이용해서 기존 곡을 학습시키고 새로운 곡을 생성하기 위해서는 전처리 과정으로 곡을 신경망이 인식할 수 있는 숫자로 변환해야 하며, 지금까지는 원-핫 인코딩이 사용되어 왔다. 본 논문에서는 음표 임베딩과 마디 임베딩을 제안하고 기존의 원-핫 인코딩과 성능을 비교하였다. 성능비교는 어떤 방식이 작곡가가 작곡한 곡과 유사한 곡을 생성하는지를 정량적 평가에 근거해서 수행하였으며, 평가방법으로는 자연어 처리 분야에서 사용되는 정량적 평가 방법들을 이용하였다. 평가결과 마디 임베딩으로 생성한 곡이 가장 좋았으며 그 다음으로 음표 임베딩이 좋았다. 이는 본 논문에서 제안한 음표 임베딩과 마디 임베딩이 원-핫 인코딩보다 작곡가가 작곡한 곡과 유사한 곡을 생성한 것으로서 의의가 있다. In order to learn an existing song and create a new song using an artificial neural network, it is necessary to convert the song into numerical data that the neural network can recognize as a preprocessing process, and one-hot encoding has been used until now. In this paper, we proposed a note embedding method using notes as a basic unit and a bar embedding method that uses the bar as the basic unit, and compared the performance with the existing one-hot encoding. The performance comparison was conducted based on quantitative evaluation to determine which method produced a song more similar to the song composed by the composer, and quantitative evaluation methods used in the field of natural language processing were used as the evaluation method. As a result of the evaluation, the song created with bar embedding was the best, followed by note embedding. This is significant in that the note embedding and bar embedding proposed in this paper create a song that is more similar to the song composed by the composer than the existing one-hot encoding."
123,"Bi-LSTM과 토픽모델링을 활용한 카카오톡, 인터넷 가짜뉴스 판별 서비스","심국보 ( Kuk-bo Shim ),이승호 ( Seung-ho Lee ),정준호 ( Jun-ho Jeong ),이기영 ( Ki-young Lee )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=5b9664779e4c048c7f7a54760bb41745&keyword=자연어 처리,"현재 영어 기반의 기술 팩트체크 서비스는 다양하지만 한국 기반 팩트체크 서비스는 비기술적 (언론인 등 전문가의 교차 검증을 통한 팩트체크)이 주를 이루고 있으며, 기술 팩트체크 서비스가 많이 시행되지 않고 있다. . 본 논문에서는 기술적인 요소와 비기술적인 요소의 서비스를 함께 사용할 때 허위 정보를 가장 정확하게 식별할 수 있기 때문에 한국어 기반의 자연어 처리 기술을 이용한 팩트체킹 서비스를 제안한다."
124,BERT 의 웹 문서 질의 응답 성능 향상을 위한 HTML 태그 스택 및 HTML 임베딩 기법 설계,"목진왕 ( Jin-wang Mok ),이현섭 ( Hyun-seob Lee )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=92a8a040434323b27ecd42904f0c5d65&keyword=자연어 처리,최근 기술의 발전으로 인해 자연어 처리 모델의 성능이 증가하고 있다. 그에 따라 평문 지문이 아닌 KorQuAD 2.0 과 같은 웹 문서를 지문으로 하는 기계 독해 과제를 해결하려는 연구가 증가하고 있다. 최근 기계 독해 과제의 대부분의 모델은 트랜스포머를 기반으로 하는 추세를 보인다. 그 중 대표적인 모델인 BERT 는 문자열의 순서에 대한 정보를 임베딩 과정에서 전달받는다. 한편 웹 문서는 태그 구조가 존재하므로 문서를 이해하는데 위치 정보 외에도 태그 정보도 유용하게 사용될 수 있다. 그러나 BERT 의 기존 임베딩은 웹 문서의 태그 정보를 추가적으로 모델에 전달하지 않는다는 문제가 있었다. 본 논문에서는 BERT 에 웹 문서 태그 정보를 효과적으로 전달할 수 있는 HTML 임베딩 기법 및 이를 위한 전처리 기법으로 HTML 태그 스택을 소개한다. HTML 태그 스택은 HTML 태그의 정보들을 추출할 수 있고 HTML 임베딩 기법은 이 정보들을 BERT 의 임베딩 과정에 입력으로 추가함으로써 웹 문서 질의 응답 과제의 성능 향상을 기대할 수 있다.
125,군사용 지능형 영상 판독 시스템에서의 빔서치를 활용한 문장 추천,"나형선 ( Hyung-sun Na ),전태현 ( Tae-hyeon Jeon ),강형석 ( Hyung-seok Kang ),안진현 ( Jinhyun Ahn ),임동혁 ( Dong-hyuk Im )",한국정보처리학회,2021,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=14d6bbac1b45cc227ecd42904f0c5d65&keyword=자연어 처리,"군사 분야에서 사용 중인 기존 영상 판독 시스템은 판독관들이 직접 영상을 분석 및 식별하여 관련 내용을 보고서에 작성하고 전파하는 방식으로 진행되는데 이 과정에서 반복 작업이 빈번하여 업무 과부하가 발생한다. 본 논문에서는 이러한 문제를 해결하고자, 기존의 문장 단위로 동작하는 Seq2Seq 모델을 단어 단위로 동작할 수 있는 알고리즘을 제안하고, Attention 기법을 적용해 정확도를 향상시키고자 한다. 또한 Beam 탐색 기법을 응용하여 특정 지역의 과거 식별내용을 바탕으로 현재 식별 문장을 다양하게 추천하고자 한다. 실험을 통해 Beam 탐색 기법이 기존 Greedy 탐색 기법보다 효과적으로 문장을 추천하는 것을 확인하였고, Beam의 크기가 클 때 추천의 정확도가 높아지는 것을 확인하였다. Existing image analysis systems in use in the military field are carried out by readers analyzing and identifying images themselves, writing and disseminating related content, and in this process, repetitive tasks are frequent, resulting in workload. In this paper, to solve the previous problem, we proposed an algorithm that can operate the Seq2Seq model on a word basis, which operates on a sentence basis, and applied the Attention technique to improve accuracy. In addition, by applying the Beam Search technique, we would like to recommend various current identification sentences based on the past identification contents of a specific area. It was confirmed through experiments that the Beam Search technique recommends sentences more effectively than the existing greedy Search technique, and confirmed that the accuracy of recommendation increases when the size of Beam is large."
126,국방분야 빅데이터 분석을 위한 자연어 사전 구축,홍힘찬(Himchan Hong),육군사관학교 화랑대연구소,2021,한국군사학논집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=7f24d933d7cff7e5b36097776a77e665&keyword=자연어 처리,"Analysis of unstructured texts on the national defense is a useful tool for various occasions. However, using an open-source morphological analysis model for studying big data in the military area can result in an unintended bias because the model has no prior understanding of military terminology, leading to misinterpretation of terms related to the defense issue. Therefore this study suggests a natural language dictionary for the national defense field, which can be efficient in minimizing the bias during the analysis of natural language associated with the field. In this study, five online dictionaries related to military and associated terms were collected to set a new natural language dictionary of 20,875 words. After training an analysis model with the new dictionary, the identification rate of the model improves by about 73%. Moreover, when comparing the identification rate of the trained model and the five other models with no training, the rate of the trained model was 6%p ∼ 88%p higher than that of the other models. This result shows that establishing a natural language dictionary of the national defense and applying it to the analysis of unstructured text on the issue would lower the possibility of bias in the analysis result."
127,개체명 인식을 이용한 소셜 미디어에서의 약물 부작용 표현 추출 및 분류,"정현정 ( Hyeon-jeong Jeong ),김현희 ( Hyon Hee Kim )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=07bdf5ac345350697ecd42904f0c5d65&keyword=자연어 처리,"의약품에 대한 안전성 정보 수집과 관리는 온라인, 오프라인을 통해 약물 이상 사례를 보고받는 형태로 진행되고 있다. 하지만 소비자들의 자발적인 참여로 이루어지므로 실제 발생하는 약물 부작용보다 데이터가 현저히 적다는 단점이 존재한다. 본 논문에서는 약물 이상 데이터 희소성 문제를 해결 할 수 있도록 소셜 미디어에서 약물 부작용 표현을 찾을 수 있도록 하였다. 소셜 미디어의 경우에는 표준 약물 부작용 용어를 사용하기보다는 일반인들이 자연어로 표현한 경우가 많으므로 개체명인식 기법을 이용해 부작용을 추출할 수 있는 모델을 개발하였다. 또한 추출된 부작용 표현을 표준용어로 분류할 수 있는 모델을 제시하였다. 실험 결과 제안한 두 가지 모델은 0.9 이상의 정확도를 얻을 수 있었으며, 일반 사용자들이 자연어로 표현한 약물 부작용 표현을 효과적으로 찾아내고 표준부작용 용어로 매핑할 수 있음을 보여준다."
128,KoEPT: Transformer 기반 생성 모델을 사용한 한국어 수학 문장제 문제 자동 풀이,"임상규 ( Sang-kyu Rhim ),기경서 ( Kyung Seo Ki ),김부근 ( Bugeun Kim ),권가진 ( Gahgene Gweon )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=e17eba56427a8ca9c85d2949c297615a&keyword=자연어 처리,"이 논문에서는 자연어로 구성된 수학 문장제 문제를 자동으로 풀이하기 위한 Transformer 기반의 생성모델인 KoEPT를 제안한다. 수학 문장제 문제는 일상 상황을 수학적 형식으로 표현한 자연어 문제로, 문장제 문제 풀이 기술은 실생활에 응용 가능성이 많아 국내외에서 다양하게 연구된 바 있다. 한국어의 경우 지금까지의 연구는 문제를 유형으로 분류하여 풀이하는 기법들이 주로 시도되었으나, 이러한 기법은 다양한 수식을 포괄하여 분류 난도가 높은 데이터셋에 적용하기 어렵다는 한계가 있다. 본 논문은 이를 해결하기 위해 우선 현존하는 한국어 수학 문장제 문제 데이터셋인 CC, IL, ALG514의 분류 난도를 측정한 후 5겹교차 검증 기법을 사용하여 KoEPT의 성능을 평가하였다. 평가에 사용된 한국어 데이터셋들에 대하여, KoEPT는 CC에서는 기존 최고 성능과 대등한 99.1%, IL과 ALG514에서 각각 89.3%, 80.5%로 새로운 최고 성능을 얻었다. 뿐만 아니라 평가 결과 KoEPT는 분류 난도가 높은 데이터셋에 대해 상대적으로 개선된 성능을 보였다."
129,KoEPT 기반 한국어 수학 문장제 문제 데이터 분류 난도 분석,"임상규,기경서,김부근,권가진",한국정보처리학회,2022,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=048442359f9d51586aae8a972f9116fb&keyword=자연어 처리,"In this paper, we propose KoEPT, a Transformer-based generative model for automatic math word problems solving. A math wordproblem written in human language which describes everyday situations in a mathematical form. Math word problem solving requiresan artificial intelligence model to understand the implied logic within the problem. Therefore, it is being studied variously across theworld to improve the language understanding ability of artificial intelligence. In the case of the Korean language, studies so far havemainly attempted to solve problems by classifying them into templates, but there is a limitation in that these techniques are difficultto apply to datasets with high classification difficulty. To solve this problem, this paper used the KoEPT model which uses ‘expression’tokens and pointer networks. To measure the performance of this model, the classification difficulty scores of IL, CC, and ALG514, whichare existing Korean mathematical sentence problem datasets, were measured, and then the performance of KoEPT was evaluated using5-fold cross-validation. For the Korean datasets used for evaluation, KoEPT obtained the state-of-the-art(SOTA) performance with 99.1%in CC, which is comparable to the existing SOTA performance, and 89.3% and 80.5% in IL and ALG514, respectively. In addition, asa result of evaluation, KoEPT showed a relatively improved performance for datasets with high classification difficulty. Through an ablationstudy, we uncovered that the use of the ‘expression’ tokens and pointer networks contributed to KoEPT’s state of being less affectedby classification difficulty while obtaining good performance. 이 논문에서는 자연어로 구성된 수학 문장제 문제 자동 풀이하기 위한 Transformer 기반의 생성 모델인 KoEPT를 제안한다. 수학 문장제 문제는일상 상황을 수학적 형식으로 표현한 자연어 문제이다. 문장제 문제 풀이 기술은 함축된 논리를 인공지능이 파악해야 한다는 요구사항을 지녀최근 인공지능의 언어 이해 능력을 증진하기 위해 국내외에서 다양하게 연구되고 있다. 한국어의 경우 문제를 유형으로 분류하여 풀이하는 기법들이주로 시도되었으나, 이러한 기법은 다양한 수식을 포괄하여 분류 난도가 높은 데이터셋에 적용하기 어렵다는 한계가 있다. 본 논문은 이에 대해‘식’ 토큰과 포인터 네트워크를 사용하는 KoEPT 모델을 사용했다. 이 모델의 성능을 측정하기 위해 현존하는 한국어 수학 문장제 문제 데이터셋인IL, CC, ALG514의 분류 난도를 측정한 후 5겹 교차 검증 기법을 사용하여 KoEPT의 성능을 평가하였다. 평가에 사용된 한국어 데이터셋들에대하여, KoEPT는 CC에서는 기존 최고 성능과 대등한 99.1%, IL과 ALG514에서 각각 89.3%, 80.5%로 새로운 최고 성능을 얻었다. 뿐만 아니라평가 결과 KoEPT는 분류 난도가 높은 데이터셋에 대해 상대적으로 개선된 성능을 보였다. KoEPT가 분류 난도의 영향을 덜 받으며 좋은 성능을얻게 된 이유를 ‘식’ 토큰과 포인터 네트워크 때문이라는 것을 ablation study를 통해서 밝혔다."
130,주요 범죄사실 개요 분석을 통한 범죄사실 타임라인 자동 작성 시스템 연구,"정종진 ( Jong-jin Jung ),박종빈 ( Jong-bin Park ),박성주 ( Sung-ju Park )",한국정보처리학회,2021,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=69aa7de093dca45d4884a65323211ff0&keyword=자연어 처리,"본 논문에서 제안한 주요 범죄사실 개요 분석을 통한 범죄사실 타임라인 자동 작성 시스템은 범죄를 수사하는 현장 수사관들이 수사과정에서 취득한 수사문건 중 범죄사실 파트에 기재된 문장들을 자연어분석을 통해 주요 범죄사실을 파악하는데 필요한 요소들을 자동으로 알아내고, 이 요소들을 타임 라인 상에 시간 순으로 표시함으로써 주요범죄사실 개용을 쉽게 이해 할수 있도록 타임라인을 자동 만들어 내는 시스템에 관한 연구이다. 이를 위해 수사문건에 포함된 범죄사실 개요 범위를 자동으로 알아내고, 그 범위내 포함된 문장들 속에서 주요행위자, 관심을 둬야 하는 시각, 그 시각에 벌어진 주요 행위들을 자동으로 분석하는 연구를 소개한다."
131,쌍 선형 그래프 신경망을 이용한 지식 그래프 기반 질문 응답,"이상의 ( Sangui Lee ),김인철 ( Incheol Kim )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=3550474eac604a2cb7998d826d417196&keyword=자연어 처리,"지식 그래프 기반의 질문 응답 문제는 자연어 질문에 대한 이해뿐만 아니라, 기반이 되는 지식 그래프상에서 올바른 답변을 찾기 위한 효과적인 추론 능력을 요구한다. 본 논문에서는 다중 홉 추론을 요구하는 복잡한 자연어 질문에 대해 연관 지식 그래프 위에서 답변 추론을 효과적으로 수행할 수 있는 심층 신경망 모델을 제안한다. 제안 모델에서는 지식 그래프상의 추론 과정에서 추론 경로를 명확히 하기 위한 노드의 양방향 특징 전파와 이웃 노드들 간의 맥락 정보까지 각 노드의 특징값에 반영할 수 있는, 표현력이 풍부한 쌍 선형 그래프 신경망(BGNN)을 이용한다. 본 논문에서는 오픈 도메인의 지식 베이스 Freebase와 자연어 질문 응답 데이터 집합 WebQuestionsSP를 이용한 실험들을 통해, 제안 모델의 효과와 우수성을 확인하였다."
132,다중 홉 질문 응답을 위한 쌍 선형 그래프 신경망 기반 추론,"이상의,김인철",한국정보처리학회,2020,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=e1178c281b52819d47de9c1710b0298d&keyword=자연어 처리,"지식 그래프 기반의 질문 응답 문제는 자연어 질문들에 대한 깊은 이해뿐만 아니라, 대규모 지식 그래프 상에서 올바른 답변을 찾기 위한 효과적인 추론 능력을 필요로 한다. 본 논문에서는 다중 홉 추론을 요구하는 복잡한 자연어 질문에 대해 연관 지식 그래프 위에서 답변 추론을 효과적으로 수행할 수 있는 심층 신경망 모델을 제안한다. 제안 모델에서는 지식 그래프 상의 각 개체 노드와 이웃 노드 간의 양방향 특징 전파를 허용할 뿐만 아니라, 두 이웃 노드 쌍 간의 맥락 정보까지 활용할 수 있는, 표현력이 뛰어난 쌍 선형 그래프 신경망(BGNN)을 이용한다. 본 논문에서는 오픈 도메인의 지식 베이스인 Freebase, 자연어 질문 응답을 위한 벤치마크 데이터 집합들인 WebQuestionsSP와 MetaQA를 이용한 실험들을 통해, 제안 모델의 효과와 우수성을 확인하였다. Knowledge graph-based question answering not only requires deep understanding of the given natural language questions, but it also needs effective reasoning to find the correct answers on a large knowledge graph. In this paper, we propose a deep neural network model for effective reasoning on a knowledge graph, which can find correct answers to complex questions requiring multi-hop inference. The proposed model makes use of highly expressive bilinear graph neural network (BGNN), which can utilize context information between a pair of neighboring nodes, as well as allows bidirectional feature propagation between each entity node and one of its neighboring nodes on a knowledge graph. Performing experiments with an open-domain knowledge base (Freebase) and two natural-language question answering benchmark datasets(WebQuestionsSP and MetaQA), we demonstrate the effectiveness and performance of the proposed model."
133,"다중 작업, 다중 홉 질문 응답을 위한 그래프 추론 및 맥락 융합","이상의 ( Sangui Lee ),김인철 ( Incheol Kim )",한국정보처리학회,2021,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=9c3dee688fbd265fb7998d826d417196&keyword=자연어 처리,"최근 오픈 도메인 자연어 질문 응답 분야에서는 다중 작업, 다중 홉 질문 응답에 관한 연구들이 활발히 진행되어 오고 있다. 본 논문에서는 이러한 다중 작업, 다중 홉 질문들에 효과적으로 응답하기 위해, 계층적 그래프 기반의 새로운 심층 신경망 모델을 제안한다. 제안 모델에서는 계층적 그래프와 그래프 신경망을 이용해 여러 문단들로부터 서로 다른 수준의 맥락 정보를 얻어낸 후, 이들을 활용하여 답변 유형, 뒷받침 문장들과 답변 영역 등을 동시에 예측해낸다. 본 논문에서는 오픈 도메인 자연어 질문 응답 데이터 집합인 HotpotQA를 이용한 실험들을 통해, 제안 모델의 높은 성능과 긍정적 효과를 입증한다. Recently, in the field of open domain natural language question answering, multi-task, multi-hop question answering has been studied extensively. In this paper, we propose a novel deep neural network model using hierarchical graphs to answer effectively such multi-task, multi-hop questions. The proposed model extracts different levels of contextual information from multiple paragraphs using hierarchical graphs and graph neural networks, and then utilize them to predict answer type, supporting sentences and answer spans simultaneously. Conducting experiments with the HotpotQA benchmark dataset, we show high performance and positive effects of the proposed model."
134,다중 홉 다중 작업 질문 응답을 위한 계층적 그래프 추론,"이상의 ( Sangui Lee ),이기호 ( Giho Lee ),김인철 ( Incheol Kim )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=a2d12e96f5ae2b477f7a54760bb41745&keyword=자연어 처리,"최근 오픈 도메인 자연어 질문 응답 분야에서는 폭넓은 다중 문서들을 토대로 다중 홉 추론과 동시에 서로 다른 수준의 여러 문제들을 한꺼번에 해결해야 하는 다중 작업 질문 응답에 관한 관심이 높다. 본 논문에서는 이러한 다중 홉 추론과 다중 작업을 요구하는 복잡 질문들에 효과적으로 응답하기 위해, 계층적 그래프 기반의 새로운 심층 신경망 모델을 제안한다. 제안 모델에서는 계층적 그래프와 그래프 신경망을 이용해 다중 문서들로부터 서로 다른 수준의 맥락 정보를 얻어낸 후, 이들을 활용하여 뒷받침 문장들, 답변 영역, 응답 유형 등을 동시에 구해야 하는 다중 작업 문제에 관한 답들을 예측해낸다. 본 논문에서는 오픈 도메인 자연어 질문 응답 데이터 집합인 HotpotQA를 이용한 실험들을 통해, 제안 모델의 긍정적 효과를 입증한다."
135,KG_VCR: 지식 그래프를 이용하는 영상 기반 상식 추론 모델,"이재윤,김인철",한국정보처리학회,2020,정보처리학회논문지. 소프트웨어 및 데이터 공학,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=892922b396904d5b6aae8a972f9116fb&keyword=자연어 처리,"Unlike the existing Visual Question Answering(VQA) problems, the new Visual Commonsense Reasoning(VCR) problems require deep common sense reasoning for answering questions: recognizing specific relationship between two objects in the image, presenting the rationale of the answer. In this paper, we propose a novel deep neural network model, KG_VCR, for VCR problems. In addition to make use of visual relations and contextual information between objects extracted from input data (images, natural language questions, and response lists), the KG_VCR also utilizes commonsense knowledge embedding extracted from an external knowledge base called ConceptNet. Specifically the proposed model employs a Graph Convolutional Neural Network(GCN) module to obtain commonsense knowledge embedding from the retrieved ConceptNet knowledge graph. By conducting a series of experiments with the VCR benchmark dataset, we show that the proposed KG_VCR model outperforms both the state of the art(SOTA) VQA model and the R2C VCR model. 기존의 영상 기반 질문-응답(VQA) 문제들과는 달리, 새로운 영상 기반 상식 추론(VCR) 문제들은 영상에 포함된 사물들 간의 관계 파악과 답변 근거 제시 등과 같이 추가적인 심층 상식 추론을 요구한다. 본 논문에서는 영상 기반 상식 추론 문제들을 위한 새로운 심층 신경망 모델인 KG_VCR을 제안한다. KG_VCR 모델은 입력 데이터(영상, 자연어 질문, 응답 리스트 등)에서 추출하는 사물들 간의 관계와 맥락 정보들을 이용할 뿐만 아니라, 외부 지식 베이스인 ConceptNet으로부터 구해내는 상식 임베딩을 함께 활용한다. 특히 제안 모델은 ConceptNet으로부터 검색해낸 연관 지식 그래프를 효과적으로 임베딩하기 위해 그래프 합성곱 신경망(GCN) 모듈을 채용한다. VCR 벤치마크 데이터 집합을 이용한 다양한 실험들을 통해, 본 논문에서는 제안 모델인 KG_VCR이 기존의 VQA 최고 모델과 R2C VCR 모델보다 더 높은 성능을 보인다는 것을 입증한다."
136,반려동물 질병상담 챗봇 서비스 구현,"배주현 ( Ju-hyun Bae ),성예원 ( Yae-won Sung ),육예은 ( Ye-eun Yuk ),장윤희 ( Yun-hui Jang )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=384e7ab3e322e0f0d18150b21a227875&keyword=자연어 처리,"반려동물 시장 및 동물 의료분야의 성장, 동물병원 이용 과정 개선의 필요성으로 반려동물 질병의 시작부터 끝까지 전 과정을 함께하는 원스탑 모바일 애플리케이션을 개발하였다. 증상으로 예상 질병을 진단하는 머신러닝 모델과 자연어 문장을 인식하는 딥러닝 챗봇으로 사용자가 편리하게 반려동물 이상 증상에 대한 예상 질병을 챗봇으로 상담할 수 있도록 구현하였다. 챗봇 시스템을 기반으로 ‘예상 진단’, ‘질병백과’, ‘문진표’, ‘동물병원’ 기능을 추가하여 일관된 기능들로 유기적인 서비스를 구성하였다."
137,MOO(Mathematical Operation Organizer): 한국어 서술형 수학 문제 자동 풀이를 위한 데이터 증강 기법 연구,"안지수 ( Jisu An ),기경서 ( Kyung Seo Ki ),김지원 ( Jiwon Kim ),권가진 ( Gahgene Gweon )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=d5c2df3ea96a038bb36097776a77e665&keyword=자연어 처리,"본 논문에서는 서술형 수학 문제의 자동 풀이 기술 개발을 위한 데이터 증강 기법인 MOO 를 제안한다. 서술형 수학 문제는 일상에서의 상황을 수학적으로 기술한 자연어 문제로, 인공지능 모델로 이 문제를 풀이하는 기술은 활용 가능성이 높아 국내외에서 다양하게 연구되고 있으나 데이터의 부족으로 인해 성능 향상에서의 한계가 늘 존재해 왔다. 본 논문은 이를 해결하기 위해 시중의 수학 문제들을 수집하여 템플릿을 구축하고, 템플릿에 적합한 풀이계획을 생성할 수 있는 중간 언어인 MOOLang 을 통해 생성된 문제에 대응하는 Python 코드 형태의 풀이와 정답을 생성할 수 있는 데이터 증강 방법을 고안하였다. 이 기법을 통해 생성된 데이터로 기존의 최고 성능 모델인 KoEPT를 통해 학습을 시도해본 결과, 생성된 데이터셋을 통해 모델이 원활하게 데이터셋의 분포를 학습할 수 있다는 것을 확인하였다."
138,BERT 를 활용한 한국어 지속가능경영 보고서의 제로샷 가독성 평가,"손규진 ( Guijin Son ),윤나은 ( Naeun Yoon ),이가은 ( Kaeunlee )",한국정보처리학회,2022,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=5540246cdbbc1f967ecd42904f0c5d65&keyword=자연어 처리,"본 연구는 최근 자연어 인공지능 연구 동향에 발맞추어 사전 학습된 언어 인공지능을 활용한 의미론적 분석을 통해 국문 보고서의 가독성을 평가하는 방법론 두 가지를 제안한다. 연구진은 연구 과정에서 사전 학습된 언어 인공지능을 활용해 추가 학습 없이 문장을 임의의 벡터값으로 임베딩하고 이를 통해 1. 의미론적 복잡도 와 2. 내재적 감정 변동성 두 가지 지표를 추출한다. 나아가, 앞서 발견한 두 지표가 국문 보고서의 가독성과 정(+)의 상관관계에 있음을 확인하였다. 본 연구는 통사론적 분석과 레이블링 된 데이터에 크게 의존하던 기존의 가독성 평가 방법론으로부터 탈피해, 별도의 학습 없이 기존 가독성 지표에 근사한다는 점에서 의미가 있다."
139,시각-언어 이동 작업을 위한 장소 미리보기 메모리,"오선택 ( Suntaek Oh ),김인철 ( Incheol Kim )",한국정보처리학회,2020,한국정보처리학회 학술대회논문집,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=a2d12e96f5ae2b47d18150b21a227875&keyword=자연어 처리,시각-언어 이동 작업은 에이전트가 주어진 지시를 따라 특정 실내 공간 내에서 목적 위치로 이동하는 작업이다. 시각-언어 이동 작업의 특성상 자연어 지시 속에 등장하는 랜드마크인 장소 정보를 인지하는 것은 작업을 수행하는 데 큰 도움이 된다. 본 논문에서는 환경을 구성하는 주요 장소 정보를 저장하기 위한 장소 미리보기 메모리를 제안한다. 에이전트는 장소 미리보기 메모리에 저장된 장소 정보를 고려하여 작업을 수행하게 된다. 본 논문에서는 Matterport3D 시뮬레이션 환경에서의 실험을 통해 R2R 벤치마크 데이터 집합에서 가장 높은 성능을 보였다.
140,챗봇 기반 인공지능 교육 프로그램 개발과 적용,한민영,한국인공지능교육학회,2020,한국인공지능교육학회 학술대회,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=d71c7a2ea0ea01c27ecd42904f0c5d65&keyword=자연어 처리,"본 연구는 학생들의 인공지능 기술에 대한 태도 신장을 위한 컴퓨팅 사고력 기반 인공지능 교육 프로 그램을 개발하는 것을 목적으로 한다. 인공지능 교육 프로그램의 주제를 선정하기 위해 학생 설문과 AI 학습 요소에 따라 ‘챗봇’을 주제로 선정하였다. 관련 문헌과 소프트웨어 교육과정을 분석해 챗봇 기반 인 공지능 교육 프로그램의 개발 기준을 선정한 후 전문가 타당도 분석 결과로 검토를 실시하였다. 검토한 개발 기준에 따라 9차시의 교육 프로그램을 개발하였으며 학습 적합도 검사는 전문가 타당도 분석 결과 를 실시했으며 개방형 응답에 따라 프로그램을 수정·보완하였다. 최종 프로그램의 효과성을 검증하기 위 해 통제집단 사전사후 실험 설계에 따라 연구를 진행하여 인공지능 기술에 대한 태도의 변화를 살펴보았 다. 그 결과 인공지능 기술에 대한 전체 태도, 인공지능 기술의 성 역할, 인공지능 기술의 접근 용이성과 인공지능 기술 관련 진로 영역에서는 유의미한 향상을 보였다."
141,신경망기계번역 기술 진화와 번역품질 분석,"지인영,김희동",한국외국어대학교 통번역연구소,2020,통번역학연구,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=c8826533be0cdeadc85d2949c297615a&keyword=자연어 처리,"There was a big technical progress in the research field of machine translation: the main approach has switched from statistical machine translation (SMT) to neural machine translation (NMT), leading to dramatic improvements in translation quality. Recently, another progress has been taking place from recurrent neural network(RNN)-based NMT to transformer-based NMT (T-NMT). As the performance of NMT has evolved, a lot of research papers for machine translation have been published in the field of interpretation and translation. Their main focus is on whether machine translation can replace human translation, and analyzing the quality of translation results. In this paper, we briefly explain the history of the machine translation research and review the mechanism of NMT. NMT is basically composed of three parts: encoder, attention mechanism, and decoder. Further we discuss the new transformer structure based on the encoder-decoder model. We also discuss the challenges in NMT and explain the research direction or solutions to the problems. Particular attention is given to the mistranslation of NMT, quality of the translation, and robustness against the noises in the training dataset as well as in the testing sentences. In order to test the performance of transformer-based NMT, we used the Google NMT (GNMT) service for 4 languages – Korean, English, German, and Japanese. We confirmed the robustness against sentences with noises. However, we found unexpected volatility of NMT models where the input sentence is semantically and syntactically correct, resulting in critical degradation of translation quality."
142,UGC 분석을 통한 설계 파라미터 정량화에 관한 연구,"김남열(Nam Youl Kim),김종형(Jong Hyeong Kim),김성회(Sunghae Kim)",대한기계학회,2022,大韓機械學會論文集A,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=204810c0c31392526aae8a972f9116fb&keyword=자연어 처리,"Web 2.0의 성장이 제품과 서비스에서 얻은 의견과 경험을 공유 가능케 했으며, 더욱이 인공지능 기술의 발달로 이러한 UGC(user generated contents) 데이터에서 다양한 정보를 추출할 수 있게 됐다. 본 연구에서는 이러한 UGC 데이터를 자연어 처리하여 유용한 설계 파라미터를 추출하고자 했다. 따라서 분석하고자 하는 대상 제품의 정보 수집 방법과 정량화 모델을 제시했고, 자연어 처리 프로세스를 서술하였다. 또한 두 가지 사례 연구를 통해 모델을 검증했다. 해당 연구는 아직 활발한 분야는 아니지만, 설계의 복잡도를 줄이고 초보 설계자들에게 감각을 익히는 데 유용할 수 있음을 설명하였으며, 해외 사례를 통해 필요성과 의의를 시사했다. The growth of Web 2.0 has facilitated the sharing of opinions and experiences gained from products and services. Furthermore, the development of artificial-intelligence technology has enabled the extraction of various information from these user-generated content (UGC) data. This paper reports on the extraction of useful design parameters by processing UGC data written in natural language. The information collection method and quantification model of the target product to be analyzed are presented, and the natural-language-processing process is described. Although such quantifications have not been actively performed, they can help reduce the complexity of design and learning for novice designers. The necessity and significance of this method are illustrated using cases from outside Korea."
143,클러스터링 기법을 이용한 소프트웨어 요구사항 적합성 검증도구 개발,"박헌우,최재훈,황석근,박문식,노상욱,정기현,최경희",한국차세대컴퓨팅학회,2021,한국차세대컴퓨팅학회 논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=abb1a2a63216d0edd18150b21a227875&keyword=자연어 처리,"소프트웨어의 요구사항을 작성하면서 발생하는 모호성과 부적절성을 제거하기 위하여 요구사항에 대한 전문용어를 사용할 필요가 있다. 본 논문에서는 철도차량 시스템 소프트웨어 요구사항 분석을 통하여 요구사항 작성에 참조할 수 있는 전문용어를 정립하며, 이를 기반으로 올바르게 작성된 요구사항 문장들에 대한 템플릿을 도출한다. 다양한 템플릿 문장은 요구사항 적합성을 점검하기 위한 비지도 기계학습용 데이터로 사용된다. 군집화 모델을 활용하여 요 구사항 템플릿을 군집화 하며, 새로운 요구사항의 적합성 여부를 군집 기반으로 판별하는 요구사항 적합성 검증도구 를 개발한다. 특정한 요구사항이 군집화 모델에 의하여 생성된 군집의 템플릿과 정확하게 일치하면 적합한 요구사항 으로 판정한다. 반면에 요구사항 적합성에 실패하면, k-평균 군집화 알고리즘에 의하여 가장 유사한 템플릿을 자동 으로 추천한다. 클러스터링 기법에 의하여 군집화된 템플릿과 새로운 요구사항에 대한 적합성 여부를 검증하기 위한 실험을 수행하였다. 첫 번째는 군집화 기반의 요구사항 추천이 정상적으로 동작하는가에 대한 실험이었다. 새로운 요구사항이 입력되면 군집으로 분류되었으며, 특정한 군집내의 동일한 형태소의 배열을 가진 템플릿으로 정확하게 추천됨을 확인하였다. 두 번째 실험에서는 기존의 템플릿 데이터베이스에 없는 요구사항 문장을 입력한 경우에 입력 한 요구사항과 가장 유사한 템플릿을 추천하는 것을 확인하였다. It is necessary for users to utilize a set of standard technical jargon for the soundness of requirements specification, while reducing its ambiguity and improperness as much as possible. Through the analysis of requirements specification, a standard technical Korean(STK) has been established in the domain of the railway vehicle system. Based upon STK, this paper also derives a type of templates for the guideline of requirements specification. A variety of templates in the railway vehicle system domain are fed into the input of unsupervised machine learning algorithms as training instances. The clustering models in an unsupervised way classify the templates into a several clusters. Our system that verifies the soundness of requirements specification has been developed in the basis of clusters. The system we have developed makes a new sentence of specification belonged into one of groups, and then, if it finds the identical template in a specific cluster, it confirms the new specification as a sound one. Otherwise, it autonomically returns the most similar template recommended by k-means clustering algorithm. We have tested our system to verify both cases. In the experiment, no matter what a new sentence exists in the knowledge base of templates, it turns out that our robust system confirms whether or not the new sentence is correctly written, based upon the clusters, and further provides the most similar template as being updated for the correct specification."
144,심리학적 언어분석 프로그램 개발을 위한 융합연구 : 기존 프로그램의 비교와 관련 문헌의 동향 분석,"김영준,최원일,김태훈",한국융합학회,2021,한국융합학회논문지,https://www.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=2d884558638803abc85d2949c297615a&keyword=자연어 처리,"내용어 기반 빈도 분석은 의도적 기만이나 반어적 표현에 분명한 한계가 있지만, 많이 사용되는 한국어 분석 프로그램인 KLIWC 는 기능어 분석을, KrKwic는 동시출현빈도를 시각화하는 방법으로 발전했다. 하지만 개발된 지 십수 년이 지나 여러 문제점으로 개선이 필요한 상황이다. 그래서 KLIWC와 KrKwic를 분석하여 새 심리학적 언어분석 프로그램을 개발하고자 하였다. 첫째로 두 프로그램의 특징을 분석하였다. 특히, 기능어 분석기능 제고를 위해서 KLIWC와 한국어 형태소 분석기의 형태소 분류를 비교하였고, 심리적 분석의 강화를 위해 심리사전의 구조와 체계를 분석하였다. 분석 결과 한나눔 품사 분석기가 가장 세분화되었지만, 인칭대명사에서는 KLIWC가, 어미와 어말어미에서는 KKMA의 품사 분류가 더 세분화되어 있어, 기능어 분석 강화를 위해 여러 품사 분석기의 통합적 사용을 제안하였 다. 둘째로 이 프로그램들로 텍스트를 분석한 연구들의 연구동향을 분석하였다. 분석 결과 두 프로그램이 복합학 분야 등 다양한 학술분 야에서 사용되고 있었다. 특히 논문과 보고서의 분석에는 KrKwic가 많이 사용되었고, 글쓴이의 생각, 정서, 성격 비교 연구에는 KLIWC 가 많이 사용되었다. 이 결과를 바탕으로 새로운 심리학적 언어분석 프로그램의 필요성과 개발 방향에 대해 제언하였다. While content word-based frequency analysis has obvious limitations to intentional deception or irony, KLIWC has evolved into functional word analysis and KrKwic has evolved as a way to visualize co-occurrence frequencies. However, after more than 10 years of development, several issues still need improvement. Therefore, we tried to develop a new psychological language analysis program by analyzing KLIWC and KrKwic. First, the two programs were analyzed. In particular, the morpheme classification of KLIWC and the Korean morpheme analyzer was compared to enhance the functional word analysis function, and the psychological dictionary were analyzed to strengthen the psychological analysis. As a result of the analysis, the Hannanum part-of-speech analyzer was the most subdivided, but KLIWC for personal pronouns and KKMA for endings and endings were more subdivided, suggesting the integrated use of multiple part-of-speech analyzers to strengthen functional word analysis. Second, the research trends of studies that analyzed texts with these programs were analyzed. As a result of the analysis, the two programs were used in various academic fields, including the field of Interdisciplinary Studies. In particular, KrKwic was used a lot for the analysis of papers and reports, and KLIWC was used a lot for the comparative study of the writer's thoughts, emotions, and personality. Based on these results, the necessity and direction of development of a new psychological language analysis program were suggested."
